<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aditya Mahajan">
<meta name="dcterms.date" content="2025-11-20">
<meta name="description" content="Course Notes for ECSE 509 (McGill University)">

<title>10&nbsp; Markov chains – Probability and Random Signals II</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./gaussian-processes.html" rel="next">
<link href="./stochastic-processes.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-b68a706d8191437c2c46203d0393f4be.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-73f166bbf3be02be0128c0a6a57c36c7.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-b68a706d8191437c2c46203d0393f4be.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/nutshell-1.0.6/nutshell.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script>
// https://github.com/mathjax/MathJax/issues/2744#issuecomment-1658624747
// To fix the bug that uppercase unicode letters are shown in italic
window.MathJax = {
  startup: {
    ready() {
      const {RANGES} = MathJax._.core.MmlTree.OperatorDictionary;
      const {TEXCLASS} = MathJax._.core.MmlTree.MmlNode;
      RANGES.splice(4, 1,
        [0x0370, 0x0385, TEXCLASS.ORD, 'mi'],
        [0x0386, 0x3AB, TEXCLASS.ORD, 'mi', 'normal'],
        [0x03AC, 0x1A20, TEXCLASS.ORD, 'mi']
      );
      MathJax.startup.defaultReady();
    }
  },
  tex: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    tags: "ams",
    macros: {
      PR: "\\mathbb{P}",
      EXP: "\\mathbb{E}",
      LEXP: "\\mathbb{L}",
      "VAR": "\\operatorname{var}",
      COV: "\\operatorname{cov}",
      GP: "\\operatorname{GP}",
      IND: "\\mathbb{1}",
      ONES: "\\mathbf{1}",
      reals: "\\mathbb{R}",
      naturalnumbers: "\\mathbb{N}",
      integers: "\\mathbb{Z}",
      BLANK: "\\mathfrak{E}",
      TRANS: "\\intercal",
      // independent: "⫫", // Too short
      independent: "\\mathrel{\\perp \\mkern -10mu \\perp}",
      BELLMAN: "\\mathcal{B}",
      RICCATI: "\\mathcal{R}",
      GAIN: "\\mathcal{G}",
      GREEDY: "\\mathcal{G}",
      MISMATCH: "\\mathcal{D}",
      VEC: "\\operatorname{vec}",
      diag: "\\operatorname{diag}",
      ROWS: "\\operatorname{vec}",
      TR: "\\operatorname{Tr}",   
      SPAN: "\\operatorname{sp}",   
      DRE: "\\operatorname{DRE}",   
      DARE: "\\operatorname{DARE}",   
      LQR: "\\operatorname{LQR}",   
      ALPHABET: ["\\mathcal{#1}", 1],
      MATRIX: ["\\begin{bmatrix} #1 \\end{bmatrix}", 1],
      DET: ["\\begin{vmatrix} #1 \\end{vmatrix}", 1],
      NORM: ["\\lVert #1 \\rVert", 1],
      NORMSCALE: ["\\left\\lVert \\mathstrut #1 \\right\\rVert", 1],
      ABS: ["\\left\\lvert \\mathstrut #1 \\right\\rvert", 1],
      GRAD: "\\nabla",
      IP: ["\\langle #1, #2 \\rangle", 2],
      IPSCALE: ["\\left\\langle #1, #2 \\right\\rangle", 2]
    },
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
};
</script>
<script async="" data-id="101261731" src="//static.getclicky.com/js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Probability and Random Signals II</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/adityam/probability-and-random-signals" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./markov-chains.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Markov chains</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Outline</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability-spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Probability spaces</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./random-variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Random variables</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./random-vectors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Random vectors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conditional-expectation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Conditional probability and conditional expectation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conditional-expectation-gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Conditional expectation for Gaussians</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./moment-generating-functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Moment Generating Functions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inequalities.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Probability inequalities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./convergence-of-random-variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Convergence of random variables</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stochastic-processes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Stochastic processes</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./markov-chains.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Markov chains</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gaussian-processes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Gaussian processes</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#time-homogeneous-markov-chains" id="toc-time-homogeneous-markov-chains" class="nav-link active" data-scroll-target="#time-homogeneous-markov-chains"><span class="header-section-number">10.1</span> Time-homogeneous Markov chains</a>
  <ul class="collapse">
  <li><a href="#properties-of-interest" id="toc-properties-of-interest" class="nav-link" data-scroll-target="#properties-of-interest"><span class="header-section-number">10.1.1</span> Properties of interest</a></li>
  </ul></li>
  <li><a href="#state-occupancy-probabilities" id="toc-state-occupancy-probabilities" class="nav-link" data-scroll-target="#state-occupancy-probabilities"><span class="header-section-number">10.2</span> State occupancy probabilities</a></li>
  <li><a href="#class-structure" id="toc-class-structure" class="nav-link" data-scroll-target="#class-structure"><span class="header-section-number">10.3</span> Class structure</a></li>
  <li><a href="#hitting-times-and-absorption-probabilities" id="toc-hitting-times-and-absorption-probabilities" class="nav-link" data-scroll-target="#hitting-times-and-absorption-probabilities"><span class="header-section-number">10.4</span> Hitting times and absorption probabilities</a></li>
  <li><a href="#invariant-distribution" id="toc-invariant-distribution" class="nav-link" data-scroll-target="#invariant-distribution"><span class="header-section-number">10.5</span> Invariant Distribution</a></li>
  <li><a href="#limiting-distribution" id="toc-limiting-distribution" class="nav-link" data-scroll-target="#limiting-distribution"><span class="header-section-number">10.6</span> Limiting Distribution</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading">Further Reading</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/adityam/probability-and-random-signals/edit/quarto/markov-chains.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Markov chains</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://adityam.github.io">Aditya Mahajan</a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="http://www.mcgill.ca/ece">
            McGill University
            </a>
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Updated</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 20, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>Let <span class="math inline">\(\ALPHABET X\)</span> be a finite set. A stochastic process <span class="math inline">\(\{X_n\}_{n \ge 0}\)</span>, <span class="math inline">\(X_n \in \ALPHABET X\)</span>, is called a <strong>Markov chain</strong> if it satisfies the <em>Markov property</em>: for any <span class="math inline">\(n \in \integers_{\ge 0}\)</span> and any <span class="math inline">\(x_{1:n+1} \in \ALPHABET X^{n+1}\)</span>, we have <span class="math display">\[\begin{equation}\tag{Markov property}\label{eq:Markov}
  \PR(X_{n+1} = x_{n+1} \mid X_{1:n} = x_{1:n})
  = \PR(X_{n+1} = x_{n+1} \mid X_n = x_n).
\end{equation}\]</span></p>
<p>The variable <span class="math inline">\(X_n\)</span> is called the <strong>state</strong> of the Markov chain at time <span class="math inline">\(n\)</span>; the set <span class="math inline">\(\ALPHABET X\)</span> is called <strong>state space</strong>. The <span class="math inline">\(\eqref{eq:Markov}\)</span> implies that the current state captures all the information from the past that is relevant for the future. Stated differently, <strong>conditioned on the present, the past is independent of the future</strong>.</p>
<p>Independence is a symmetric relationship. Thus, we expect the Markov property to also hold if time is reversed! <a href="#exr-time-reversal" class="quarto-xref">Exercise&nbsp;<span>10.1</span></a> asks you to formally prove that.</p>
<p>We now present some examples of Markov chains arising in different applications.</p>
<div id="exm-Gilbert-Elliot-channel" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.1 (Gilbert Elliot channel model for burst erasures)</strong></span> The Gilbert-Elliot channel model is used to model communication channels with burst errors. The channel can be in one of two states: a “good” state (state 0) with low error probability, or a “bad” state (state 1) with high error probability. The channel state evolves as a Markov chain, and the error probability depends on the current state. This is essentially the same as the on-off Markov chain described in <a href="#exm-on-off" class="quarto-xref">Example&nbsp;<span>10.4</span></a>.</p>
</div>
<div id="exm-Ehrenfest-diffusion" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.2 (Ehrenfest model of diffusion)</strong></span> The following simplified model of diffusion through a porous membrane was proposed by <span class="citation" data-cites="Ehrenfest1907">@Ehrenfest1907</span> to describe the exchange of heat between two systems at different temperatures.</p>
<p>There are <span class="math inline">\(K\)</span> particles that can either be in compartment <span class="math inline">\(A\)</span> or compartment <span class="math inline">\(B\)</span>. At each time, a particle is picked at random and moved from its compartment to the other. Thus, if there are <span class="math inline">\(X_n = i\)</span> particles in compartment <span class="math inline">\(A\)</span> at time <span class="math inline">\(n\)</span>, then the next state <span class="math inline">\(X_{n+1}\)</span> is either <span class="math inline">\(i-1\)</span> (a particle was displaced from compartment <span class="math inline">\(A\)</span> to <span class="math inline">\(B\)</span>) with probability <span class="math inline">\(i/K\)</span>, or <span class="math inline">\(i+1\)</span> (a particle was displaced from compartment <span class="math inline">\(B\)</span> to <span class="math inline">\(A\)</span>) with probability <span class="math inline">\((K-i)/K\)</span>.</p>
</div>
<div id="exm-gamblers-ruin" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.3 (Gambler’s ruin)</strong></span> Consider a gambler who is playing in a casino. The gambler starts with an initial fortune of $<span class="math inline">\(x_0\)</span>. At each time, the gambler places a bet where he wins $<span class="math inline">\(1\)</span> with probability <span class="math inline">\(p\)</span> and loses $<span class="math inline">\(1\)</span> with probability <span class="math inline">\(1-p\)</span>. Thus, his fortune evolves as <span class="math display">\[
  X_{n+1} = X_n + Z_n
\]</span> where <span class="math inline">\(\{Z_n\}_{n \ge 0}\)</span> is an i.i.d.&nbsp;sequence which takes values <span class="math inline">\(+1\)</span> with probability <span class="math inline">\(p\)</span> and <span class="math inline">\(-1\)</span> with probability <span class="math inline">\(1-p\)</span>.</p>
<p>The gambler stops when his fortune is ruined, i.e., <span class="math inline">\(X_n = 0\)</span>. In some variations, the gambler may also stop when his fortune reaches a pre-specified amount of $<span class="math inline">\(K\)</span>.</p>
</div>
<p>See the following video from <a href="https://www.youtube.com/@veritasium">Veritasium</a> for an excellent history of Markov chains and its applications</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KZeIEiBrT_w" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="time-homogeneous-markov-chains" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="time-homogeneous-markov-chains"><span class="header-section-number">10.1</span> Time-homogeneous Markov chains</h2>
<p>In this course, we will focus on time-homogeneous Markov chains. The Markov chain is called <strong>time-homogeneous</strong> if the right hand side of <span class="math inline">\(\eqref{eq:Markov}\)</span> does not depend on <span class="math inline">\(n\)</span>. In this case, we describe the Markov chain by a <strong>state transition matrix</strong> <span class="math inline">\(P\)</span>, where <span class="math inline">\(P_{ij} = \PR(X_{n+1} = j | X_n = i)\)</span>. Such Markov chains can also be visualized using <strong>state transition diagrams</strong> as we illustrate in the examples below.</p>
<div id="exm-on-off" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.4 (On-Off Markov chain)</strong></span> The On-Off Markov chain discussed earlier can be modelled with <span class="math inline">\(\ALPHABET X = \{0, 1\}\)</span> and a general transition probability matrix of the form. <span class="math display">\[
  P = \MATRIX{ 1 - a &amp; a \\ b &amp; 1 - b }.
\]</span> The transition matrix can be visualized as follows.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/markov-examples1.svg" class="img-fluid figure-img"></p>
<figcaption>On-Off Markov chain</figcaption>
</figure>
</div>
</div>
<p>In spite of its simplicity, such simple on-off Markov chains are used in various applications including telecommunication systems, network traffic modeling, machine failure-repair models, gene activation, and others. Some properties of the on-off Markov chain are as follows:</p>
<ul>
<li><p>If <span class="math inline">\(a + b = 1\)</span>, then both rows of the transition matrix are identical. Therefore, the Markov chain <em>has no memory</em> and is equivalent to a Bernoulli process with success probability <span class="math inline">\(a = 1-b\)</span>.</p></li>
<li><p>When <span class="math inline">\(a\)</span> or <span class="math inline">\(b\)</span> are small, the corresponding state is “sticky”, i.e., when the Markov chain enters a sticky state, it stays there for a long time.</p></li>
</ul>
<div id="exm-Ehrenfest-diffusion-model" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.5</strong></span> The Ehrenfest model of diffusion presented in <a href="#exm-Ehrenfest-diffusion" class="quarto-xref">Example&nbsp;<span>10.2</span></a> can be modelled as a Markov chain with state space <span class="math inline">\(\{0, 1, \dots, K\}\)</span> and transition probability <span class="math display">\[
  P_{ij} = \begin{cases}
    i/K     &amp; j = i-1 \\
    (K-i)/K &amp; j = i + 1 \\
    0 &amp; \text{otherwise}.
  \end{cases}
\]</span> The transition matrix can be visualized as follows.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/markov-examples2.svg" class="img-fluid figure-img"></p>
<figcaption>Ehrenfest model of diffusion</figcaption>
</figure>
</div>
</div>
<div id="exm-random-walk" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.6 (Random walk in one dimension)</strong></span> Imagine a particle which moves in a straight line in unit steps. Each step is one unit to the right with probability <span class="math inline">\(p\)</span> or one unit to the left with probability <span class="math inline">\(q = 1-p\)</span>. It moves until it reaches one of two extreme points, which are called <strong>boundary points</strong>. The behavior of the particle at the boundary determines several different possibilities.</p>
<p>We will consider the case where the state space is <span class="math inline">\(\ALPHABET X = \{-2, -1, 0, 1, 2\}\)</span> and the process starts in state <span class="math inline">\(0\)</span>.</p>
<ol type="1">
<li><p><strong>Absorbing random walk:</strong> Assume that when the particle reaches a boundary state, it stays there from that time on. We may visualize the Markov chain as follows.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/random-walk1.svg" class="img-fluid figure-img"></p>
<figcaption>Absorbing random walk</figcaption>
</figure>
</div>
<p>In this case, the transition matrix is given by <span class="math display">\[
   P = \MATRIX{ 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
                q &amp; 0 &amp; p &amp; 0 &amp; 0 \\
                0 &amp; q &amp; 0 &amp; p &amp; 0 \\
                0 &amp; 0 &amp; q &amp; 0 &amp; p \\
                0 &amp; 0 &amp; 0 &amp; 0 &amp; 1}.
\]</span></p></li>
<li><p><strong>Reflected random walk:</strong> Assume that when the particle reaches a boundary states, it is <em>reflected</em> and returns to the point it came from. We may visualize the Markov chain as follows.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/random-walk2.svg" class="img-fluid figure-img"></p>
<figcaption>Reflected random walk</figcaption>
</figure>
</div>
<p>In this case, the transition matrix is given by <span class="math display">\[
   P = \MATRIX{ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
                q &amp; 0 &amp; p &amp; 0 &amp; 0 \\
                0 &amp; q &amp; 0 &amp; p &amp; 0 \\
                0 &amp; 0 &amp; q &amp; 0 &amp; p \\
                0 &amp; 0 &amp; 0 &amp; 1 &amp; 0}.
\]</span></p></li>
<li><p><strong>Random walk with restart:</strong> Assume that when the particle reaches a boundary state, it restarts in the initial state. We may visualize the Markov chain as follows.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/random-walk3.svg" class="img-fluid figure-img"></p>
<figcaption>Random walk with restart</figcaption>
</figure>
</div>
<p>In this case, the transition matrix is given by <span class="math display">\[
   P = \MATRIX{ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
                q &amp; 0 &amp; p &amp; 0 &amp; 0 \\
                0 &amp; q &amp; 0 &amp; p &amp; 0 \\
                0 &amp; 0 &amp; q &amp; 0 &amp; p \\
                0 &amp; 0 &amp; 1 &amp; 0 &amp; 0}.
\]</span></p></li>
<li><p><strong>Random walk with periodic boundary:</strong> Assume that when the particle reaches a boundary state, it moves to the other boundary. We may visualize the Markov chain as follows.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/random-walk4.svg" class="img-fluid figure-img"></p>
<figcaption>Random walk with periodic boundary</figcaption>
</figure>
</div>
<p>In this case, the transition matrix is given by <span class="math display">\[
   P = \MATRIX{ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
                q &amp; 0 &amp; p &amp; 0 &amp; 0 \\
                0 &amp; q &amp; 0 &amp; p &amp; 0 \\
                0 &amp; 0 &amp; q &amp; 0 &amp; p \\
                1 &amp; 0 &amp; 0 &amp; 0 &amp; 0}.
\]</span></p></li>
</ol>
</div>
<p>Note that the gambler’s fortune in <a href="#exm-gamblers-ruin" class="quarto-xref">Example&nbsp;<span>10.3</span></a> is a random walk on non-negative integers <span class="math inline">\(\{0,1,2, \dots\}\)</span> with absorption at <span class="math inline">\(0\)</span>. In the variation where the gambler stops when his fortune reaches $<span class="math inline">\(K\)</span>, it is a random walk over <span class="math inline">\(\{0,1,\dots,K\}\)</span> with absorption at both ends: <span class="math inline">\(0\)</span> and <span class="math inline">\(K\)</span>.</p>
<section id="properties-of-interest" class="level3" data-number="10.1.1">
<h3 data-number="10.1.1" class="anchored" data-anchor-id="properties-of-interest"><span class="header-section-number">10.1.1</span> Properties of interest</h3>
<p>Depending on the application, we are typically interested in the following properties of a Markov chain:</p>
<ul>
<li><p>If the chain starts in state <span class="math inline">\(i\)</span>, what is the probability that after <span class="math inline">\(n\)</span> steps it is in state <span class="math inline">\(j\)</span>?</p></li>
<li><p>If the chain starts in state <span class="math inline">\(i\)</span>, what is the expected number of visits to state <span class="math inline">\(j\)</span> in <span class="math inline">\(n\)</span> steps?</p></li>
<li><p>What is the expected number of steps that it takes for a chain starting in state <span class="math inline">\(i\)</span> to visit state <span class="math inline">\(j\)</span> for the first time?</p></li>
<li><p>What is the average number of times that the chain is in state <span class="math inline">\(i\)</span>? How does this depend on the initial state?</p></li>
</ul>
<p>In the rest of this section, we will present results in Markov chain theory that answer the above questions.</p>
</section>
</section>
<section id="state-occupancy-probabilities" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="state-occupancy-probabilities"><span class="header-section-number">10.2</span> State occupancy probabilities</h2>
<ol type="1">
<li><p>Let <span class="math inline">\(μ^{(n)}\)</span> denote the PMF of the state of the Markov chain at time <span class="math inline">\(n\)</span>. This is also called the <strong>state occupancy probabilities</strong>. We will think of <span class="math inline">\(μ^{(n)}\)</span> as a row vector.</p></li>
<li><p>By the law of total probability, we have <span class="math display">\[
  \PR(X_n = j) = \sum_{i \in \ALPHABET X} \PR(X_{n-1} = i) \PR(X_n = j | X_{n-1} = i)
\]</span> or, equivalently, <span class="math display">\[
  μ^{(n)}_j = \sum_{i \in \ALPHABET X} μ^{(n-1)}_i P_{ij}
\]</span> which can be written in matrix form as <span class="math display">\[ μ^{(n)} = μ^{(n-1)} P \]</span> and, by recursively expanding the right hand side, we have <span class="math display">\[ μ^{(n)} = μ^{(0)} P^n. \]</span></p></li>
<li><p>We will abbreviate <span class="math inline">\([P^n]_{ij}\)</span> as <span class="math inline">\(P^{(n)}_{ij}\)</span>. Note that <span class="math display">\[
   P^{(n)}_{ij} = \PR(X_n = j \mid X_0 = i)
\]</span> denotes the <strong><span class="math inline">\(n\)</span>-step transition probability.</strong></p></li>
<li><p><strong>Chapman-Kolmogorov equations:</strong> The multi-step transition probabilities satisfy the following: for any positive integers <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span> and <span class="math inline">\(i,j \in \ALPHABET X\)</span>, we have <span class="math display">\[
   P^{(n+m)}_{ij} = \sum_{k \in \ALPHABET X} P^{(n)}_{ik} P^{(m)}_{kj}.
\]</span> Thus, the probability of going from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span> in <span class="math inline">\(n+m\)</span> steps equals the probability of going from <span class="math inline">\(i\)</span> to <em>somewhere</em> in <span class="math inline">\(n\)</span> steps and then from there to <span class="math inline">\(j\)</span> in <span class="math inline">\(m\)</span> steps.</p></li>
</ol>
<div id="exm-random-walk-occupancy" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.7</strong></span> Numerically compute the state occupancy probabilities for the different examples of random walk presented in <a href="gaussian-processes.html#exm-random-walk" class="quarto-xref">Example&nbsp;<span>11.3</span></a> when <span class="math inline">\(p = q = \tfrac 12\)</span> for <span class="math inline">\(n \in \{1, \dots, 8\}\)</span>. In all cases, the initial probability <span class="math display">\[
  μ^{(0)} = \MATRIX{0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 }.
\]</span></p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Absorbing random walk:</strong> In this case, we have</p>
<ul>
<li><span class="math inline">\(μ^{(0)} = \left[
\begin{array}{ccccc}
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(1)} = \left[
\begin{array}{ccccc}
0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(2)} = \left[
\begin{array}{ccccc}
\frac{1}{4} &amp; 0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{4} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(3)} = \left[
\begin{array}{ccccc}
\frac{1}{4} &amp; \frac{1}{4} &amp; 0 &amp; \frac{1}{4} &amp; \frac{1}{4} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(4)} = \left[
\begin{array}{ccccc}
\frac{3}{8} &amp; 0 &amp; \frac{1}{4} &amp; 0 &amp; \frac{3}{8} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(5)} = \left[
\begin{array}{ccccc}
\frac{3}{8} &amp; \frac{1}{8} &amp; 0 &amp; \frac{1}{8} &amp; \frac{3}{8} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(6)} = \left[
\begin{array}{ccccc}
\frac{7}{16} &amp; 0 &amp; \frac{1}{8} &amp; 0 &amp; \frac{7}{16} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(7)} = \left[
\begin{array}{ccccc}
\frac{7}{16} &amp; \frac{1}{16} &amp; 0 &amp; \frac{1}{16} &amp; \frac{7}{16} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(8)} = \left[
\begin{array}{ccccc}
\frac{15}{32} &amp; 0 &amp; \frac{1}{16} &amp; 0 &amp; \frac{15}{32} \\
\end{array}
\right]\)</span></li>
</ul></li>
<li><p><strong>Reflected random walk:</strong> In this case, we have</p>
<ul>
<li><span class="math inline">\(μ^{(0)} = \left[
\begin{array}{ccccc}
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(1)} = \left[
\begin{array}{ccccc}
0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(2)} = \left[
\begin{array}{ccccc}
\frac{1}{4} &amp; 0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{4} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(3)} = \left[
\begin{array}{ccccc}
0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(4)} = \left[
\begin{array}{ccccc}
\frac{1}{4} &amp; 0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{4} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(5)} = \left[
\begin{array}{ccccc}
0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(6)} = \left[
\begin{array}{ccccc}
\frac{1}{4} &amp; 0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{4} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(7)} = \left[
\begin{array}{ccccc}
0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(8)} = \left[
\begin{array}{ccccc}
\frac{1}{4} &amp; 0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{4} \\
\end{array}
\right]\)</span></li>
</ul></li>
<li><p><strong>Random walk with restart:</strong> In this case, we have</p>
<ul>
<li><span class="math inline">\(μ^{(0)} = \left[
\begin{array}{ccccc}
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(1)} = \left[
\begin{array}{ccccc}
0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(2)} = \left[
\begin{array}{ccccc}
\frac{1}{4} &amp; 0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{4} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(3)} = \left[
\begin{array}{ccccc}
0 &amp; \frac{1}{4} &amp; \frac{1}{2} &amp; \frac{1}{4} &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(4)} = \left[
\begin{array}{ccccc}
\frac{1}{8} &amp; \frac{1}{4} &amp; \frac{1}{4} &amp; \frac{1}{4} &amp; \frac{1}{8} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(5)} = \left[
\begin{array}{ccccc}
\frac{1}{8} &amp; \frac{1}{8} &amp; \frac{1}{2} &amp; \frac{1}{8} &amp; \frac{1}{8} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(6)} = \left[
\begin{array}{ccccc}
\frac{1}{16} &amp; \frac{1}{4} &amp; \frac{3}{8} &amp; \frac{1}{4} &amp; \frac{1}{16} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(7)} = \left[
\begin{array}{ccccc}
\frac{1}{8} &amp; \frac{3}{16} &amp; \frac{3}{8} &amp; \frac{3}{16} &amp; \frac{1}{8} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(8)} = \left[
\begin{array}{ccccc}
\frac{3}{32} &amp; \frac{3}{16} &amp; \frac{7}{16} &amp; \frac{3}{16} &amp; \frac{3}{32} \\
\end{array}
\right]\)</span></li>
</ul></li>
<li><p><strong>Random walk with periodic boundary:</strong> In this case, we have</p>
<ul>
<li><span class="math inline">\(μ^{(0)} = \left[
\begin{array}{ccccc}
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(1)} = \left[
\begin{array}{ccccc}
0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(2)} = \left[
\begin{array}{ccccc}
\frac{1}{4} &amp; 0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{4} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(3)} = \left[
\begin{array}{ccccc}
\frac{1}{4} &amp; \frac{1}{4} &amp; 0 &amp; \frac{1}{4} &amp; \frac{1}{4} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(4)} = \left[
\begin{array}{ccccc}
\frac{3}{8} &amp; 0 &amp; \frac{1}{4} &amp; 0 &amp; \frac{3}{8} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(5)} = \left[
\begin{array}{ccccc}
\frac{3}{8} &amp; \frac{1}{8} &amp; 0 &amp; \frac{1}{8} &amp; \frac{3}{8} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(6)} = \left[
\begin{array}{ccccc}
\frac{7}{16} &amp; 0 &amp; \frac{1}{8} &amp; 0 &amp; \frac{7}{16} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(7)} = \left[
\begin{array}{ccccc}
\frac{7}{16} &amp; \frac{1}{16} &amp; 0 &amp; \frac{1}{16} &amp; \frac{7}{16} \\
\end{array}
\right]\)</span></li>
<li><span class="math inline">\(μ^{(8)} = \left[
\begin{array}{ccccc}
\frac{15}{32} &amp; 0 &amp; \frac{1}{16} &amp; 0 &amp; \frac{15}{32} \\
\end{array}
\right]\)</span></li>
</ul></li>
</ol>
</div>
</div>
</div>
<div id="exm-on-off-occupancy" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.8</strong></span> Analytically compute the state occupancy probabilities for the on-off Markov chain of <a href="#exm-on-off" class="quarto-xref">Example&nbsp;<span>10.4</span></a> when it starts from the initial probability distribution <span class="math inline">\(μ^{(0)}\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Since <span class="math inline">\(μ^{(n+1)} = μ^{(n)} P\)</span>, we have <span class="math display">\[\begin{align*}
  μ^{(n+1)}_0 &amp;= μ^{(n)}_0 (1-a) + μ^{(n)}_1 b
  \\
  &amp;= μ^{(n)}_0 (1-a) + (1 - μ^{(n)}_0) b
  \\
  &amp;= μ^{(n)}_0 (1-a-b) + b.
\end{align*}\]</span> If <span class="math inline">\(a = b = 0\)</span>, then <span class="math inline">\(μ^{(n+1)}_0 = μ^{(n)}_0 = \cdots = μ^{(0)}_0\)</span>. If not, we exploit the fact that <span class="math display">\[
  b = \frac{b}{a+b} - \frac{b}{a+b}(1-a-b)  
\]</span> to recursively write <span class="math display">\[\begin{align*}
  μ^{(1)}_0 &amp;= μ^{(0)}_0 (1-a-b) + b \\
  &amp;= \left(μ^{(0)}_0 - \frac{b}{a+b}\right)(1-a-b) + \frac{b}{a+b}
\end{align*}\]</span> and <span class="math display">\[\begin{align*}
  μ^{(2)}_0 &amp;= μ^{(1)}_0 (1-a-b) + b \\
  &amp;= \left(μ^{(0)}_0 - \frac{b}{a+b}\right)(1-a-b)^2 + \frac{b}{a+b}(1-a-b) + b \\
  &amp;= \left(μ^{(0)}_0 - \frac{b}{a+b}\right)(1-a-b)^2 + \frac{b}{a+b}
\end{align*}\]</span> and, so on, to get <span class="math display">\[\begin{align*}
  μ^{(n)}_0 &amp;= μ^{(n-1)}_0 (1-a-b) + b \\
  &amp;= \left(μ^{(0)}_0 - \frac{b}{a+b}\right)(1-a-b)^n + \frac{b}{a+b}(1-a-b) + b \\
  &amp;= \left(μ^{(0)}_0 - \frac{b}{a+b}\right)(1-a-b)^n + \frac{b}{a+b}.
\end{align*}\]</span> Therefore, <span class="math display">\[
  μ^{(n)}_1 = 1 - μ^{(n)}_0
  = \left(μ^{(0)}_1 - \frac{a}{a+b}\right)(1-a-b)^n + \frac{a}{a+b}.
\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>How did we figure out the above calculation?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The above analysis appears to be a bit of black magic. To understand what is going on, note that we are interested in computing <span class="math inline">\(μ^{(0)} P^n\)</span>. What is an efficient way to compute <span class="math inline">\(P^n\)</span>? <strong>Eigen decomposition!</strong>. Since <span class="math inline">\(P\)</span> is a row stochastic matrix, we have <span class="math inline">\(P \mathbf{1} = \mathbf{1}\)</span>, where <span class="math inline">\(\mathbf{1}\)</span> is the all-ones vector. Thus, <span class="math inline">\(λ_1 = 1\)</span> is always an eigenvalue of <em>any</em> transition matrix, with corresponding eigenvector <span class="math inline">\(\mathbf{1}\)</span>.</p>
<p>For <a href="#exm-on-off" class="quarto-xref">Example&nbsp;<span>10.4</span></a>, we can explicitly compute all eigenvalues by finding the roots of the characteristic equation <span class="math display">\[\begin{align*}
\det(λI - P) &amp;= \DET{λ - 1 + a &amp; - a \\ -b &amp; λ - 1 + b} \\
&amp;= (λ-1 +a)(λ-1+b) - ab \\
&amp;= (λ-1)^2 + (a+b)(λ-1) = (λ-1)(λ-1 + a + b).
\end{align*}\]</span> Thus, the eigenvalues are <span class="math inline">\(λ_1 = 1\)</span> and <span class="math inline">\(λ_2 = 1 - a - b\)</span>.</p>
<p><span class="text-secondary">For the special case of <span class="math inline">\(2 × 2\)</span> transition matrices, we can find the second eigenvalue by observing that <span class="math inline">\(λ_1 = 1\)</span> is always an eigenvalue and <span class="math inline">\(\TR(P) = λ_1 + λ_2 = 1 + λ_2\)</span> or <span class="math inline">\(\det(P) = λ_1 λ_2 = λ_2\)</span>.</span></p>
<p>To find the eigenvector, we find a vector <span class="math inline">\(v\)</span> such that <span class="math inline">\((λI - P)v = 0\)</span>.</p>
<ul>
<li>For <span class="math inline">\(λ_1 = 1\)</span>, we already know that <span class="math inline">\(v_1 = [1; 1]\)</span> is an eigenvector.</li>
<li>For <span class="math inline">\(λ_2 = (1-a-b)\)</span>, we have <span class="math display">\[ λ_2I - P = \MATRIX{-b &amp; -a \\ -b &amp; -a}. \]</span> Therefore, one possible eigenvector is <span class="math inline">\([a; -b]\)</span>.</li>
</ul>
<p>Then, from spectral decomposition, we know that <span class="math display">\[
  P = V Λ V^{-1}
\]</span> where <span class="math inline">\(V = [v_1 v_2] = [1, a; 1, -b]\)</span> and <span class="math inline">\(Λ = \diag(1, 1-a-b)\)</span>. Therefore, <span class="math display">\[\begin{align*}
  μ^{(n)} &amp;= μ^{(0)} P^n = μ^{(0)} V Λ^n V^{-1} \\
  &amp;= \MATRIX{ μ^{(0)}_0 &amp; 1 - μ^{(0)}_0 }
     \MATRIX{1 &amp; a \\ 1 &amp; -b }
     \MATRIX{1 &amp; 0 \\ 0 &amp; 1 - a -b}
     \frac{1}{a+b}
     \MATRIX{b &amp; a \\ 1 &amp; -1 }
  \\[5pt]
  &amp;= \MATRIX{\dfrac{1}{a+b} &amp; μ^{(0)}_0 - \dfrac{b}{a+b} }
     \MATRIX{1 &amp; 0 \\ 0 &amp; 1 - a -b}
     \MATRIX{b &amp; a \\ 1 &amp; -1 }
  \\[5pt]
  &amp;=\MATRIX{\dfrac{1}{a+b} &amp; 0 \\ 0 &amp; \left(μ^{(0)}_0 - \dfrac{b}{a+b}\right)(1-a-b)^n }
   \MATRIX{b &amp; a \\ 1 &amp; -1 }
  \\[5pt]
  &amp;= \frac{b}{a+b} + \left(μ^{(0)}_0 - \dfrac{b}{a+b}\right)(1-a-b)^n
\end{align*}\]</span></p>
</div>
</div>
</div>
<p><strong>TODO:</strong> Add more examples!</p>
</section>
<section id="class-structure" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="class-structure"><span class="header-section-number">10.3</span> Class structure</h2>
<ol type="1">
<li><p>We say that a state <span class="math inline">\(j\)</span> is <strong>accessible from</strong> state <span class="math inline">\(i\)</span> (abbreviated as <span class="math inline">\(i \rightsquigarrow j\)</span>) if there exists an <span class="math inline">\(m \in \integers_{\ge 0}\)</span> (which may depend on <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>) such that <span class="math inline">\([P^m]_{ij} &gt; 0\)</span>. The fact that <span class="math inline">\(P^{(m)}_{ij} &gt; 0\)</span> implies that there exists an ordered sequence of states <span class="math inline">\((i_0, \dots, i_m)\)</span> such that <span class="math inline">\(i_0 = i\)</span> and <span class="math inline">\(i_m = j\)</span> such that <span class="math inline">\(P_{i_k i_{k+1}} &gt; 0\)</span>; thus, there is a path of positive probability from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span>.</p>
<p>Accessibility is a transitive relationship, i.e., if <span class="math inline">\(i \rightsquigarrow j\)</span> and <span class="math inline">\(j \rightsquigarrow k\)</span>, then <span class="math inline">\(i \rightsquigarrow k\)</span>.</p>
<div id="exm-accessible" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.9</strong></span> Consider the Markov chain shown below.</p>
<p><img src="figures/svg/markov-examples3.svg" class="img-fluid"></p>
<ol type="a">
<li>Identify all states that are accessible from state <span class="math inline">\(1\)</span>.</li>
<li>Identify all states from which state <span class="math inline">\(1\)</span> is accessible.</li>
</ol>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="a">
<li>States accessible from state <span class="math inline">\(1\)</span> are <span class="math inline">\(\{1,2,3\}\)</span>.</li>
<li>States from which state <span class="math inline">\(1\)</span> is accessible are <span class="math inline">\(\{1,2,3,4,5,6\}\)</span>.</li>
</ol>
</div>
</div>
</div></li>
<li><p>Two distinct states <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are said to <strong>communicate</strong> (abbreviated to <span class="math inline">\(i \leftrightsquigarrow j\)</span>) if <span class="math inline">\(i\)</span> is accessible from <span class="math inline">\(j\)</span> (i.e., <span class="math inline">\(j \rightsquigarrow i\)</span>) and <span class="math inline">\(j\)</span> is accessible from <span class="math inline">\(i\)</span> (<span class="math inline">\(i \rightsquigarrow j\)</span>). Alternatively, we say that <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> communicate if there exist <span class="math inline">\(m, m' \in \integers_{\ge 0}\)</span> such that <span class="math inline">\(P^{(m)}_{ij} &gt; 0\)</span> and <span class="math inline">\(P^{(m')}_{ji} &gt; 0\)</span>.</p>
<p>For instance, in <a href="#exm-accessible" class="quarto-xref">Example&nbsp;<span>10.9</span></a>, state <span class="math inline">\(1\)</span> communicates with state <span class="math inline">\(2\)</span> but does not communicate with state <span class="math inline">\(5\)</span>.</p>
<p>Communication is an equivalence relationship, i.e., it is reflexive (<span class="math inline">\(i \leftrightsquigarrow i\)</span>), symmetric (<span class="math inline">\(i \leftrightsquigarrow j\)</span> if and only if <span class="math inline">\(j \leftrightsquigarrow i\)</span>), and transitive (<span class="math inline">\(i \leftrightsquigarrow j\)</span> and <span class="math inline">\(j \leftrightsquigarrow k\)</span> implies <span class="math inline">\(i \leftrightsquigarrow k\)</span>).</p></li>
<li><p>The states in a finite-state Markov chain can be partitioned into two sets: <strong>recurrent states</strong> and <strong>transient states</strong>. A state is recurrent if it is accessible from all states that are accessible from it (i.e., <span class="math inline">\(i\)</span> is recurrent if <span class="math inline">\(i \rightsquigarrow j\)</span> implies that <span class="math inline">\(j \rightsquigarrow i\)</span>). States that are not recurrent are <strong>transient</strong>.</p></li>
<li><p>It can be shown that a state <span class="math inline">\(i\)</span> is recurrent if and only if <span class="math display">\[\sum_{m=1}^{\infty} P^{(m)}_{ii} = \infty.\]</span> This is a consequence of the second Borel-Cantelli lemma (<a href="convergence-of-random-variables.html#lem-Borel-Cantelli-2" class="quarto-xref">Lemma&nbsp;<span>8.2</span></a>) and <strong>strong Markov property</strong> (to be discussed later).</p></li>
<li><p>States <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are said to belong to the same <strong>communicating class</strong> if <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> communicate. Communicating classes form a partition of the state space. Within a communicating class, all states are of the same type, i.e., either all states are recurrent (in which case the class is called a recurrent class) or all states are transient (in which case the class is called a transient class).</p>
<p>For example, in <a href="#exm-accessible" class="quarto-xref">Example&nbsp;<span>10.9</span></a>, there are two communication classes: <span class="math inline">\(\{1,2,3\}\)</span> and <span class="math inline">\(\{4,5,6\}\)</span>. The communication class <span class="math inline">\(\{4,5,6\}\)</span> is transient while the communication class <span class="math inline">\(\{1,2,3\}\)</span> is recurrent.</p></li>
<li><p>A communicating class <span class="math inline">\(C\)</span> is said to be <strong>closed</strong> if <span class="math display">\[
    i \in C \text{ and } i \rightsquigarrow j \implies j \in C.
\]</span> Thus, there is no escape from a closed class. For finite state spaces, a recurrent class is always closed and a transient class is never closed. But this is not the case for countable state Markov chains.</p></li>
<li><p>A state <span class="math inline">\(i\)</span> is called <strong>absorbing</strong> if <span class="math inline">\(\{i\}\)</span> is a closed class, i.e., if <span class="math inline">\(P_{ii} = 1\)</span>.</p></li>
<li><p>A Markov chain with a single communicating class (thus, all states communicate with each other and are, therefore, recurrent) is called <strong>irreducible</strong>.</p></li>
<li><p>If <span class="math inline">\(C\)</span> is a finite irreducible closed set of states, then every state in <span class="math inline">\(C\)</span> is recurrent. This is an important result for finite-state Markov chains: any finite closed communicating class must be recurrent.</p></li>
<li><p>The <strong>period</strong> of a state <span class="math inline">\(i\)</span>, denoted by <span class="math inline">\(d(i)\)</span>, is defined as <span class="math display">\[d(i) = \gcd\{ t \in \integers_{\ge 1} : [P^t]_{ii} &gt; 0 \}.\]</span> If the period is <span class="math inline">\(1\)</span>, the state is <strong>aperiodic</strong>, and if the period is <span class="math inline">\(2\)</span> or more, the state is <strong>periodic</strong>. It can be shown that all states in the same class have the same period.</p></li>
<li><p>A Markov chain is <strong>aperiodic</strong>, if all states are aperiodic. A simple sufficient (but not necessary) condition for an irreducible Markov chain to be aperiodic is that there exists a state <span class="math inline">\(i\)</span> such that <span class="math inline">\(P_{ii} &gt; 0\)</span>. In general, for a finite and aperiodic Markov chain, there exists a positive integer <span class="math inline">\(M\)</span> such that <span class="math display">\[ P^{(m)}_{ii} &gt; 0,
       \quad \forall m \ge M, i \in \ALPHABET X.\]</span></p></li>
</ol>
</section>
<section id="hitting-times-and-absorption-probabilities" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="hitting-times-and-absorption-probabilities"><span class="header-section-number">10.4</span> Hitting times and absorption probabilities</h2>
<ol type="1">
<li><p>We use the following notation:</p>
<ul>
<li>For any event <span class="math inline">\(E\)</span>, <span class="math inline">\(\PR_i(E)\)</span> denotes <span class="math inline">\(\PR(E \mid X_0 = i)\)</span></li>
<li>For any random variable <span class="math inline">\(Y\)</span>, <span class="math inline">\(\EXP_i[Y]\)</span> denotes <span class="math inline">\(\EXP[Y \mid X_0 = i]\)</span>.</li>
</ul></li>
<li><p>Let <span class="math inline">\(A\)</span> be a subset of <span class="math inline">\(\ALPHABET X\)</span>. The <strong>hitting time</strong> <span class="math inline">\(H^A\)</span> of <span class="math inline">\(A\)</span> is a random variable <span class="math inline">\(H^A \colon \ALPHABET X \to \{0, 1, \dots \} \cup \{∞\}\)</span> given by <span class="math display">\[
  H^A(ω) = \min\{n \ge 0 : X_n(ω) \in A\}.
\]</span> The standard convention is that <span class="math inline">\(H^A\)</span> is taken to be <span class="math inline">\(∞\)</span> if <span class="math inline">\(X_n \neq A\)</span> for any <span class="math inline">\(n &gt; 0\)</span>. For a state <span class="math inline">\(j \in \ALPHABET X\)</span>, we use the short-hand <span class="math inline">\(H^j\)</span> to denote <span class="math inline">\(H^{\{j\}}\)</span>.</p></li>
<li><p>The probability that starting from state <span class="math inline">\(i\)</span> the Markov chain ever hits <span class="math inline">\(A\)</span> is then given by <span class="math display">\[
   h^A_i = \PR_i(H^A &lt; ∞).
\]</span> This is called <strong>hitting probability</strong>. When <span class="math inline">\(A\)</span> is a closed class, <span class="math inline">\(h^A_i\)</span> is called the <strong>absorption probability</strong>.</p></li>
<li><p>The mean-time taken for the Markov chain to reach <span class="math inline">\(A\)</span> is given by <span class="math display">\[
  m^A_i = \EXP_i[H^A] = \sum_{n=0}^{∞} n \PR_i(H^A = n).
\]</span> This is called the <strong>mean hitting time</strong>.</p></li>
<li><p>A remarkable property of Markov chain is that these quantities can be computed by solving a system of linear equations associated with the transition probability matrix <span class="math inline">\(P\)</span>. We start with some examples to illustrate the main idea.</p>
<div id="exm-coin-toss-head-before-tail" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.10</strong></span> Suppose we toss a coin multiple times. What is the probability of getting a head before getting a tail?</p>
We model this using a Markov chain where the state represents the outcome we’re waiting for. Let <span class="math inline">\(p\)</span> denote the probability of heads and <span class="math inline">\(q = 1-p\)</span> denote the probability of tails. The Markov chain has three states:
<ul>
<li>State <span class="math inline">\(-1\)</span>: tail has occurred (absorbing state, we lose)</li>
<li>State <span class="math inline">\(0\)</span>: initial state (no outcome yet)</li>
<li>State <span class="math inline">\(1\)</span>: head has occurred (absorbing state, we win)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/markov-examples4.svg" class="img-fluid figure-img"></p>
<figcaption>Markov chain for coin tossing until head or tail</figcaption>
</figure>
</div>
<p>Let <span class="math inline">\(h^1_i\)</span> denote the probability of hitting state <span class="math inline">\(1\)</span> (i.e., getting a head) when starting at state <span class="math inline">\(i\)</span>. Then, we have <span class="math display">\[\begin{align*}
  h^1_{-1} &amp;= 0, \\
  h^1_0 &amp;= p h^1_1 + q h^1_{-1} = p \cdot 1 + q \cdot 0 = p, \\
  h^1_1 &amp;= 1.
\end{align*}\]</span> Therefore, starting from state <span class="math inline">\(0\)</span>, the probability of getting a head before a tail is <span class="math inline">\(h^1_0 = p\)</span>.</p>
</div></li>
<li><div id="exm-two-heads-before-two-tails" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.11</strong></span> Two players are playing a game. They repeatedly toss a coin. Player 1 wins if two consecutive heads occur before two consecutive tails. Player 2 wins if two consecutive tails occur before two consecutive heads. What is the probability that Player 1 wins?</p>
We model this using a Markov chain where the state tracks the pattern of recent coin tosses. Let <span class="math inline">\(p\)</span> denote the probability of heads and <span class="math inline">\(q = 1-p\)</span> denote the probability of tails. The Markov chain has five states:
<ul>
<li>State <span class="math inline">\(-2\)</span>: two consecutive tails (Player 2 wins, absorbing state)</li>
<li>State <span class="math inline">\(-1\)</span>: one tail (last toss was a tail)</li>
<li>State <span class="math inline">\(0\)</span>: initial state (or after alternating outcomes like HT or TH)</li>
<li>State <span class="math inline">\(1\)</span>: one head (last toss was a head)</li>
<li>State <span class="math inline">\(2\)</span>: two consecutive heads (Player 1 wins, absorbing state)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/markov-examples5.svg" class="img-fluid figure-img"></p>
<figcaption>Markov chain for two heads before two tails</figcaption>
</figure>
</div>
<p>Let <span class="math inline">\(h^2_i\)</span> denote the probability of hitting state <span class="math inline">\(2\)</span> (i.e., Player 1 wins) when starting at state <span class="math inline">\(i\)</span>. Then, we have <span class="math display">\[\begin{align*}
  h^2_{-2} &amp;= 0, \\
  h^2_{-1} &amp;= p h^2_0 + q h^2_{-2} = p h^2_0 + q \cdot 0 = p h^2_0, \\
  h^2_0 &amp;= p h^2_1 + q h^2_{-1}, \\
  h^2_1 &amp;= p h^2_2 + q h^2_0 = p \cdot 1 + q h^2_0 = p + q h^2_0, \\
  h^2_2 &amp;= 1.
\end{align*}\]</span> From the second equation, we get <span class="math inline">\(h^2_{-1} = p h^2_0\)</span>. From the fourth equation, we get <span class="math inline">\(h^2_1 = p + q h^2_0\)</span>. Substituting into the third equation: <span class="math display">\[
  h^2_0 = p h^2_1 + q h^2_{-1} = p(p + q h^2_0) + q(p h^2_0) = p^2 + pq h^2_0 + pq h^2_0 = p^2 + 2pq h^2_0.
\]</span> Solving for <span class="math inline">\(h^2_0\)</span>, we get <span class="math inline">\(h^2_0(1 - 2pq) = p^2\)</span>, so <span class="math display">\[
  h^2_0 = \frac{p^2}{1 - 2pq} = \frac{p^2}{1 - 2p(1-p)} = \frac{p^2}{1 - 2p + 2p^2} = \frac{p^2}{2p^2 - 2p + 1}.
\]</span> For a fair coin (<span class="math inline">\(p = q = \frac{1}{2}\)</span>), we get <span class="math inline">\(h^2_0 = \frac{(1/2)^2}{1 - 2(1/2)(1/2)} = \frac{1/4}{1 - 1/2} = \frac{1/4}{1/2} = \frac{1}{2}\)</span>.</p>
</div></li>
<li><p>We now provide a general formula for computing hitting probabilities.</p>
<div id="thm-hitting-probabilities" class="theorem">
<p><span class="theorem-title"><strong>Theorem 10.1 (Hitting probabilities)</strong></span> The hitting probabilities <span class="math inline">\(\{h^A_i\}_{i \in \ALPHABET X}\)</span> satisfies the following system of linear equations: <span class="math display">\[
  h^A_i = \begin{cases}
    1, &amp; i \in A \\
    \sum_{j \in \ALPHABET X} P_{ij} h^A_j, &amp; i \not\in A
  \end{cases}
\]</span> When <span class="math inline">\(\ALPHABET X\)</span> is finite, the above system has a unique solution; when <span class="math inline">\(\ALPHABET X\)</span> is countable, the above system may have multiple solutions and the hitting probabilities correspond to the <em>minimal</em> non-negative solution.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>When <span class="math inline">\(X_0 = i \in A\)</span>, the hitting time <span class="math inline">\(H^A = 0\)</span>, so <span class="math inline">\(h^A_i = 1\)</span>. This proves the first part of the formula.</p>
<p>For the second part, consider <span class="math inline">\(X_0 = i \not\in A\)</span>. Then <span class="math inline">\(H^A_i \ge 1\)</span>. By the Markov property, we have <span class="math display">\[
\PR_i(H^A &lt; ∞ \mid X_1 = j) = \PR_j(H^A &lt; ∞) = h^A_j.
\]</span> Moreover, by the law of total probability, we have <span class="math display">\[\begin{align*}
h^A_i &amp;= \PR_i(H^A &lt; ∞) = \sum_{j \in \ALPHABET X} \PR_i(H^A &lt; ∞, X_1 = j) \\
&amp;= \sum_{j \in \ALPHABET X} \PR_i(H^A &lt; ∞ \mid X_1 = j) \PR_i(X_1 = j) \\
&amp;= \sum_{j \in \ALPHABET X} P_{ij} h^A_j.
\end{align*}\]</span></p>
</div>
</div>
</div></li>
<li><div id="exm-gambler-ruin-instance" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.12</strong></span> Consider a gambler’s ruin problem, where the gambler starts with $<span class="math inline">\(1\)</span> and stops either when he is ruined or when his fortune reaches $<span class="math inline">\(K\)</span>.</p>
<p>Find the probability of ruin (i.e., the fortune gets absorbed in state <span class="math inline">\(0\)</span> rather than state <span class="math inline">\(K\)</span>).</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For the ease of notation, we use <span class="math inline">\(h_i\)</span> as a short-form for <span class="math inline">\(h^{\{0\}}_i\)</span>. The hitting probabilities satisy the linear system of equations:</p>
<p><span class="math display">\[\begin{align*}
  h_0 &amp;= 1 \\
  h_i &amp;= ph_{i+1} + q h_{i-1}, \quad i \in \{1,\dots,K-1\} \\
  h_K &amp;= 0,
\end{align*}\]</span> where <span class="math inline">\(q = 1-p\)</span>.</p>
<p>The characteristic equation associated with the linear recurrence relationship is <span class="math display">\[
  λ = p λ^2 + q
\]</span> which has two distinct roots, <span class="math inline">\(λ_1 = 1\)</span> and <span class="math inline">\(λ_2 = q/p\)</span> if <span class="math inline">\(p \neq q\)</span> and a double root at <span class="math inline">\(λ_1 = 1\)</span> if <span class="math inline">\(p = q = \frac 12\)</span>. Therefore, the general solution is of the form <span class="math display">\[
  h_i = a λ_1^i + b λ_2^i = a + b\Bigl(\tfrac {q}{p} \Bigr)^i
\]</span> where we determine the coefficients <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> from the boundary conditions <span class="math inline">\(h_0 = 1\)</span> and <span class="math inline">\(h_K = 0\)</span>. Solving for <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, we get that for <span class="math inline">\(p \neq q\)</span>, we have <span class="math display">\[
  h_i = \frac{1 - \Bigl(\frac qp\Bigr)^i}{1 - \Bigl(\frac qp\Bigr)^K}
\]</span> and for <span class="math inline">\(p = q = \frac 12\)</span>, we have <span class="math display">\[
  h_i = \frac{i}{K}.
\]</span></p>
</div>
</div>
</div></li>
<li><p>Similarly as above, we can derive a formula for computing mean hitting times. We start with a couple of examples to illustrate the main idea.</p>
<div id="exm-no-of-tosses-1" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.13</strong></span> Suppose we toss a coin multiple times and stop at the first head. What is the expected number of coin tosses until stopping?</p>
<p>From elementary probability we know that the number of tosses until stopping is a geometric random variable. However, we will model this using a Markov chain where the state denotes the number of consecutive heads so far. Let <span class="math inline">\(p\)</span> denote the probability of heads and <span class="math inline">\(q = 1-p\)</span> denote the probability of tails. Then, the Markov chain model is as follows.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/markov-examples6.svg" class="img-fluid figure-img"></p>
<figcaption>Markov chain for coin tossing until one head</figcaption>
</figure>
</div>
<p>Let <span class="math inline">\(m^1_i\)</span> denote the expected number of tosses until stopping (i.e., hitting state <span class="math inline">\(1\)</span>) when starting at state <span class="math inline">\(i\)</span>. Then, we have <span class="math display">\[\begin{align*}
  m^1_0 &amp;= 1 + q m^1_0 + p m^1_1, \\
  m^1_1 &amp;= 0.
\end{align*}\]</span> Solving this system of equations, we get <span class="math inline">\(m^1_0 = 1/(1-q) = 1/p\)</span>.</p>
</div></li>
<li><div id="exm-no-of-tosses-2" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.14</strong></span> Suppose we toss a coin multiple times and stop at two consecutive heads. What is the expected number of coin tosses until stopping?</p>
<p>We can model this in the same manner as before, where the state denotes the number of consecutive heads so far. The Markov chain is as follows:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/markov-examples7.svg" class="img-fluid figure-img"></p>
<figcaption>Markov chain for coin tossing until two heads</figcaption>
</figure>
</div>
<p>Let <span class="math inline">\(m^2_i\)</span> denote the expected number of tosses until stopping (i.e., hitting state <span class="math inline">\(2\)</span>) when starting at state <span class="math inline">\(i\)</span>. Then, we have <span class="math display">\[\begin{align*}
  m^2_0 &amp;= 1 + q m^2_0 + p m^2_1, \\
  m^2_1 &amp;= 1 + q m^2_0 + p m^2_2, \\
  m^2_2 &amp;= 0.
\end{align*}\]</span> Solving this system of equations, we get <span class="math inline">\(m^2_0 = 1/(1-p)\)</span>.</p>
</div></li>
<li><p>We now provide a general formula for computing mean hitting times.</p>
<div id="thm-mean-hitting-times" class="theorem">
<p><span class="theorem-title"><strong>Theorem 10.2 (Mean hitting times)</strong></span> The mean hitting times <span class="math inline">\(\{m^A_i\}_{i \in \ALPHABET X}\)</span> satisfies the following system of linear equations: <span class="math display">\[
  m^A_i = \begin{cases}
    0, &amp; i \in A \\
    1 + \sum_{j \not\in A} P_{ij} m^A_j, &amp; i \not\in A
  \end{cases}
\]</span> When <span class="math inline">\(\ALPHABET X\)</span> is finite, the above system has a unique solution; when <span class="math inline">\(\ALPHABET X\)</span> is countable, the above system may have multiple solutions and the mean hitting times correspond to the <em>minimal</em> non-negative solution.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The proof is similar to the proof of <a href="#thm-hitting-probabilities" class="quarto-xref">Theorem&nbsp;<span>10.1</span></a>. When <span class="math inline">\(X_0 = i \in A\)</span>, the hitting time <span class="math inline">\(H^A = 0\)</span>, so <span class="math inline">\(m^A_i = 0\)</span>. This proves the first part of the formula.</p>
<p>For the second part, consider <span class="math inline">\(X_0 = i \not\in A\)</span>. Then <span class="math inline">\(H^A_i \ge 1\)</span>. By the Markov property, we have <span class="math display">\[
  \EXP_i[ H^A \mid X_1 = j] = 1 + \EXP_j[ H^A ] = 1 + m^A_j.
\]</span> Moreover, by the law of total probability, we have <span class="math display">\[\begin{align*}
  m^A_i &amp;= \EXP_i[ H^A ]
  = \sum_{j \in \ALPHABET X} \EXP_i[ H^A \mid X_1 = j ] \PR_i(X_1 = j) \\
  &amp;= \sum_{j \in \ALPHABET X} \EXP_i[ H^A \mid X_1 = j ] \PR_i(X_1 = j) \\
  &amp;= \sum_{j \in \ALPHABET X} P_{ij} \bigl[ 1 + m^A_j \bigr]
  \\
  &amp;= 1 + \sum_{j \not\in A} P_{ij} m^A_j.
\end{align*}\]</span></p>
</div>
</div>
</div></li>
<li><p>For absorbing Markov chains, we can use matrix methods to efficiently compute hitting probabilities and mean hitting times. The key idea is to rearrange the transition matrix into a <strong>canonical form</strong> where absorbing states are grouped together.</p>
<p>Suppose the state space <span class="math inline">\(\ALPHABET X\)</span> can be partitioned into transient states <span class="math inline">\(\ALPHABET T\)</span> and absorbing states <span class="math inline">\(\ALPHABET C\)</span>. By reordering the states so that all transient states come first, followed by all absorbing states, the transition matrix <span class="math inline">\(P\)</span> can be written in the <strong>canonical form</strong>: <span class="math display">\[
  P = \MATRIX{ Q &amp; R \\ 0 &amp; I}.
\]</span> where:</p>
<ul>
<li><span class="math inline">\(Q\)</span> is a <span class="math inline">\(|\ALPHABET T| \times |\ALPHABET T|\)</span> matrix containing transition probabilities between transient states,</li>
<li><span class="math inline">\(R\)</span> is a <span class="math inline">\(|\ALPHABET T| \times |\ALPHABET C|\)</span> matrix containing transition probabilities from transient states to absorbing states,</li>
<li><span class="math inline">\(0\)</span> is a <span class="math inline">\(|\ALPHABET C| \times |\ALPHABET T|\)</span> zero matrix (since absorbing states cannot transition to transient states),</li>
<li><span class="math inline">\(I\)</span> is a <span class="math inline">\(|\ALPHABET C| \times |\ALPHABET C|\)</span> identity matrix (since absorbing states stay in themselves).</li>
</ul></li>
<li><p><strong>Multi-step transitions:</strong> For the canonical form, we can show by induction that <span class="math display">\[
P^n = \MATRIX{ Q^n &amp; (I + Q + Q^2 + \cdots + Q^{n-1}) R \\ 0 &amp; I}.
  \]</span> This follows from the fact that matrix multiplication preserves the block structure, and the lower-left block remains zero while the lower-right block remains <span class="math inline">\(I\)</span> for all powers.</p></li>
<li><p><strong>Fundamental Matrix:</strong> The <strong>fundamental matrix</strong> <span class="math inline">\(N\)</span> is defined as <span class="math display">\[
  N = (I - Q)^{-1} = I + Q + Q^2 + Q^3 + \cdots.
\]</span> The series expansion is valid because for transient states, the spectral radius of <span class="math inline">\(Q\)</span> is less than 1, ensuring convergence. The fundamental matrix exists and is well-defined for any Markov chain with at least one absorbing state.</p></li>
<li><p><strong>Interpretation of <span class="math inline">\(N_{ij}\)</span>:</strong> The entry <span class="math inline">\(N_{ij}\)</span> represents the <strong>expected number of visits to transient state <span class="math inline">\(j\)</span></strong> before absorption, starting from transient state <span class="math inline">\(i\)</span>. This can be seen from the series expansion: <span class="math display">\[
N_{ij} = \sum_{n=0}^∞ [Q^n]_{ij} = \sum_{n=0}^∞ \PR_i(X_n = j, \text{ chain hasn't been absorbed by time } n).
  \]</span></p></li>
<li><p><strong>Mean hitting times:</strong> Let <span class="math inline">\(\ONES\)</span> denote a column vector of ones with dimension <span class="math inline">\(|\ALPHABET T|\)</span>. Then the mean hitting times (expected time until absorption) starting from each transient state are given by <span class="math display">\[
  m = N \ONES,
\]</span> where <span class="math inline">\(m_i\)</span> is the mean time until absorption starting from transient state <span class="math inline">\(i\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The mean hitting time <span class="math inline">\(m_i\)</span> equals the expected number of steps spent in transient states before absorption. Since <span class="math inline">\(N_{ij}\)</span> represents the expected number of visits to transient state <span class="math inline">\(j\)</span> starting from transient state <span class="math inline">\(i\)</span>, we have <span class="math display">\[
  m_i = \sum_{j \in \ALPHABET T} N_{ij} = [N \ONES]_i,
\]</span> which gives the desired result in matrix form.</p>
</div>
</div>
</div></li>
<li><p><strong>Hitting probabilities:</strong> The hitting probabilities (absorption probabilities) are given by <span class="math display">\[
  h = N R,
\]</span> where <span class="math inline">\(h_{ij}\)</span> is the probability of being absorbed in absorbing state <span class="math inline">\(j\)</span> when starting from transient state <span class="math inline">\(i\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Starting from transient state <span class="math inline">\(i\)</span>, the chain is absorbed in absorbing state <span class="math inline">\(j\)</span> if and only if it takes some number <span class="math inline">\(n \ge 0\)</span> of steps within transient states, and then transitions to <span class="math inline">\(j\)</span> in step <span class="math inline">\(n+1\)</span>. The probability of being in transient state <span class="math inline">\(k\)</span> after <span class="math inline">\(n\)</span> steps (without being absorbed) is <span class="math inline">\([Q^n]_{ik}\)</span>, and the probability of transitioning from <span class="math inline">\(k\)</span> to <span class="math inline">\(j\)</span> is <span class="math inline">\(R_{kj}\)</span>. Therefore, <span class="math display">\[
  h_{ij} = \sum_{n=0}^∞ \sum_{k \in \ALPHABET T} [Q^n]_{ik} R_{kj} = \sum_{n=0}^∞ [Q^n R]_{ij} = [N R]_{ij},
\]</span> where the last equality follows from <span class="math inline">\(N = I + Q + Q^2 + \cdots\)</span>.</p>
</div>
</div>
</div></li>
<li><div id="exm-matrix-formulas-gamblers-ruin" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.15</strong></span> Consider the gambler’s ruin problem from <a href="#exm-gambler-ruin-instance" class="quarto-xref">Example&nbsp;<span>10.12</span></a> with <span class="math inline">\(K = 3\)</span> (i.e., the gambler starts with $<span class="math inline">\(1\)</span> and stops at either $<span class="math inline">\(0\)</span> or $<span class="math inline">\(3\)</span>). Write the transition matrix in canonical form and use the fundamental matrix to compute the probability of ruin and the expected duration of play.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The state space is <span class="math inline">\(\{0, 1, 2, 3\}\)</span> where states <span class="math inline">\(0\)</span> and <span class="math inline">\(3\)</span> are absorbing. In the natural ordering <span class="math inline">\((0, 1, 2, 3)\)</span>, the transition matrix is: <span class="math display">\[
P = \MATRIX{
  1 &amp; 0 &amp; 0 &amp; 0 \\
  q &amp; 0 &amp; p &amp; 0 \\
  0 &amp; q &amp; 0 &amp; p \\
  0 &amp; 0 &amp; 0 &amp; 1
}
\]</span> where <span class="math inline">\(q = 1-p\)</span>. Reordering to put transient states first, we use the ordering <span class="math inline">\((1, 2, 0, 3)\)</span>: <span class="math display">\[
P = \MATRIX{
  0 &amp; p &amp; q &amp; 0 \\
  q &amp; 0 &amp; 0 &amp; p \\
  0 &amp; 0 &amp; 1 &amp; 0 \\
  0 &amp; 0 &amp; 0 &amp; 1
}
= \MATRIX{ Q &amp; R \\ 0 &amp; I }
\]</span> where <span class="math display">\[
Q = \MATRIX{ 0 &amp; p \\ q &amp; 0 }, \quad
R = \MATRIX{ q &amp; 0 \\ 0 &amp; p }.
\]</span></p>
<p>The fundamental matrix is: <span class="math display">\[
N = (I - Q)^{-1} = \MATRIX{ 1 &amp; -p \\ -q &amp; 1 }^{-1}
= \frac{1}{1-pq} \MATRIX{ 1 &amp; p \\ q &amp; 1 }.
\]</span></p>
<p>The hitting probabilities are: <span class="math display">\[
h = N R = \frac{1}{1-pq} \MATRIX{ 1 &amp; p \\ q &amp; 1 } \MATRIX{ q &amp; 0 \\ 0 &amp; p }
= \frac{1}{1-pq} \MATRIX{ q &amp; p^2 \\ q^2 &amp; p }.
\]</span></p>
<p>Thus, starting from state <span class="math inline">\(1\)</span>, the probability of ruin (absorption in state <span class="math inline">\(0\)</span>) is <span class="math inline">\(h_{1,0} = q/(1-pq)\)</span> and the probability of winning (absorption in state <span class="math inline">\(3\)</span>) is <span class="math inline">\(h_{1,3} = p^2/(1-pq)\)</span>.</p>
<p>The mean hitting times are: <span class="math display">\[
m = N \ONES = \frac{1}{1-pq} \MATRIX{ 1 &amp; p \\ q &amp; 1 } \MATRIX{ 1 \\ 1 }
= \frac{1}{1-pq} \MATRIX{ 1+p \\ q+1 }.
\]</span></p>
<p>Thus, starting from state <span class="math inline">\(1\)</span>, the expected duration is <span class="math inline">\(m_1 = (1+p)/(1-pq)\)</span>.</p>
</div>
</div>
</div></li>
</ol>
</section>
<section id="invariant-distribution" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="invariant-distribution"><span class="header-section-number">10.5</span> Invariant Distribution</h2>
<ol type="1">
<li><p>A probability distribution <span class="math inline">\(π\)</span> on the state space <span class="math inline">\(\ALPHABET X\)</span> is called an <strong>invariant distribution</strong> if it satisfies the equation <span class="math display">\[
  π = π P.
\]</span></p></li>
<li><p>An invariant distribution is also called a <strong>stationary distribution</strong>. If the initial distribution of the Markov chain is <span class="math inline">\(π\)</span>, then the distribution remains <span class="math inline">\(π\)</span> at all future times. In other words, if <span class="math inline">\(μ^{(0)} = π\)</span> then <span class="math inline">\(μ^{(n)} = π\)</span> for all <span class="math inline">\(n \ge 0\)</span>.</p></li>
<li><p>Consider the on-off Markov chain from <a href="#exm-on-off" class="quarto-xref">Example&nbsp;<span>10.4</span></a> with transition matrix <span class="math display">\[
  P = \MATRIX{ 1 - a &amp; a \\ b &amp; 1 - b }.
\]</span> This chain has an invariant distribution given by <span class="math inline">\(π = [b/(a+b), a/(a+b)]\)</span> (assuming <span class="math inline">\(a+b &gt; 0\)</span>). One can verify that <span class="math inline">\(π = π P\)</span>, which shows that an invariant distribution exists for this chain.</p></li>
<li><p>A finite Markov chain with only one communication class has a <strong>unique</strong> invariant distribution. Thus, irreducible Markov chains have a unique invariant distribution. Note that aperiodicity is not required. For instance, consider on-off Markov chain from <a href="#exm-on-off" class="quarto-xref">Example&nbsp;<span>10.4</span></a> with <span class="math inline">\(a = b = 1\)</span>. This chain is periodic, but has a unique invariant distribution <span class="math inline">\(π = [\frac 12, \frac 12]\)</span>.</p></li>
<li><p>A Markov chain with more than one closed communicating class has multiple invariant distributions. For example, consider a Markov chain with two absorbing states <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>. The transition matrix is <span class="math display">\[
  P = \MATRIX{ 1 &amp; 0 \\ 0 &amp; 1 }.
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/markov-examples8.svg" class="img-fluid figure-img"></p>
<figcaption>Markov chain with two absorbing states</figcaption>
</figure>
</div>
<p>In this case, any distribution of the form <span class="math inline">\(π = [α, 1-α]\)</span> with <span class="math inline">\(α \in [0,1]\)</span> is an invariant distribution, since <span class="math display">\[
π P = [α, 1-α]
\MATRIX{ 1 &amp; 0 \\ 0 &amp; 1 }
= [α, 1-α] = π.
\]</span> Thus, there are uncountably many invariant distributions. This happens because the chain consists of two disjoint recurrent classes (the absorbing states <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>), and any probability mass can be put on either class and be preserved.</p>
<p>More generally, if a Markov chain has multiple irreducible communicating (closed) classes, each class can have its own invariant distribution (supported only on that class). Any convex combination of these distributions is also an invariant distribution for the whole chain.</p></li>
<li><p>A Markov chain that is irreducible and <strong>aperiodic</strong> has a special prorperty: for any initial distribution <span class="math inline">\(μ^{(0)}\)</span>, we have <span class="math display">\[\lim_{n \to ∞} μ^{(n)}_j = π_j, \quad \forall j \in \ALPHABET X.\]</span></p>
<p>Irreducible and aperiodic Markov chains are also called <strong>ergodic</strong>. Thus, an ergodic Markov chain converges to its invariant distribution. For this reason, the invariant distribution is also called the <strong>limiting distribution</strong> or the <strong>steady-state</strong> distribution.</p></li>
<li><p><strong>Computing invariant distributions.</strong> The equation <span class="math inline">\(π = π P\)</span> can be written component-wise as <span class="math display">\[
  π_j = \sum_{i \in \ALPHABET X} π_i P_{ij}, \quad \forall j \in \ALPHABET X.
\]</span> These equations are called <strong>balance equations</strong> and can be used to find invariant distributions. Together with the constraint that <span class="math inline">\(π\)</span> is a probability distribution (i.e., <span class="math inline">\(\sum_{j \in \ALPHABET X} π_j = 1\)</span> and <span class="math inline">\(π_j \ge 0\)</span> for all <span class="math inline">\(j\)</span>), they form a system of linear equations that can be solved to determine the invariant distribution.</p></li>
<li><p>As an example, let’s compute the invariant distribution of the on-off Markov chain from <a href="#exm-on-off" class="quarto-xref">Example&nbsp;<span>10.4</span></a>. The transition matrix is <span class="math display">\[
  P = \MATRIX{ 1 - a &amp; a \\ b &amp; 1 - b }.
\]</span> To find the invariant distribution <span class="math inline">\(π = [π_0, π_1]\)</span>, we solve the balance equations <span class="math inline">\(π = π P\)</span>: <span class="math display">\[\begin{align*}
  π_0 &amp;= π_0 (1-a) + π_1 b, \\
  π_1 &amp;= π_0 a + π_1 (1-b).
\end{align*}\]</span> From the first equation, we get <span class="math inline">\(π_0 = π_0 (1-a) + π_1 b\)</span>, which simplifies to <span class="math inline">\(π_0 a = π_1 b\)</span>, or equivalently <span class="math inline">\(π_1 = (a/b) π_0\)</span> (assuming <span class="math inline">\(b &gt; 0\)</span>). Using the normalization constraint <span class="math inline">\(π_0 + π_1 = 1\)</span>, we have <span class="math display">\[
  π_0 + \frac{a}{b} π_0 = 1 \quad \Rightarrow \quad π_0 \left(1 + \frac{a}{b}\right) = 1 \quad \Rightarrow \quad π_0 = \frac{b}{a+b}.
\]</span> Therefore, <span class="math inline">\(π_1 = 1 - π_0 = \frac{a}{a+b}\)</span>. The invariant distribution is <span class="math inline">\(π = [b/(a+b), a/(a+b)]\)</span>, which matches the result mentioned in point 3.</p></li>
<li><p>We can write balance equations directly from the state transition diagram. For each state <span class="math inline">\(j\)</span>, the balance equation states that the probability flow into state <span class="math inline">\(j\)</span> equals the probability flow out of state <span class="math inline">\(j\)</span>. Consider the three-state Markov chain with transition matrix <span class="math display">\[
  P = \MATRIX{ 0.3 &amp; 0.7 &amp; 0 \\
               0 &amp; 0.3 &amp; 0.7 \\
               0.7 &amp; 0 &amp; 0.3 }.
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/markov-examples9.svg" class="img-fluid figure-img"></p>
<figcaption>Three-state aperiodic Markov chain</figcaption>
</figure>
</div>
<p>The balance equations, equating the flow into and out of each state, can be written as:</p>
<ul>
<li><p><strong>State 0:</strong><br>
<span class="math display">\[\begin{align*}
\text{Inflow} &amp;= \pi_2 \cdot 0.7 \\
\text{Outflow} &amp;= \pi_0 \cdot 0.7
\end{align*}\]</span></p></li>
<li><p><strong>State 1:</strong><br>
<span class="math display">\[\begin{align*}
\text{Inflow} &amp;= \pi_0 \cdot 0.7 \\
\text{Outflow} &amp;= \pi_1 \cdot 0.7
\end{align*}\]</span></p></li>
<li><p><strong>State 2:</strong><br>
<span class="math display">\[\begin{align*}
\text{Inflow} &amp;= \pi_1 \cdot 0.7 \\
\text{Outflow} &amp;= \pi_2 \cdot 0.7
\end{align*}\]</span></p></li>
</ul>
<p>Thus, the balance equations are given by <span class="math display">\[\begin{align*}
  \pi_0 \cdot 0.7 = \pi_2 \cdot 0.7 \\
  \pi_1 \cdot 0.7 = \pi_0 \cdot 0.7 \\
  \pi_2 \cdot 0.7 = \pi_1 \cdot 0.7
\end{align*}\]</span> Together with the normalization constraint <span class="math inline">\(π_0 + π_1 + π_2 = 1\)</span>, we get <span class="math inline">\(π_0 = π_1 = π_2 = 1/3\)</span>. This illustrates how balance equations can be derived directly from the state diagram by considering probability flows.</p></li>
<li><p>The above example is an illustration of a more general principle. If <span class="math inline">\(P\)</span> is doubly stochastic (i.e., both row sum and column sums are <span class="math inline">\(1\)</span>), then the invariant distribution is a uniform distribution.</p></li>
<li><p><strong>Exercises: Computing Invariant Distributions</strong></p>
<div id="exm-invariant-transient-closed" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.16</strong></span> Consider the Markov chain with transition matrix<br>
<span class="math display">\[
  P = \MATRIX{ 0.6 &amp; 0.4 &amp; 0 &amp; 0 \\
               0.3 &amp; 0.7 &amp; 0 &amp; 0 \\
               0.2 &amp; 0.3 &amp; 0.3 &amp; 0.2 \\
               0.1 &amp; 0.4 &amp; 0.1 &amp; 0.4 }.
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/markov-examples10.svg" class="img-fluid figure-img"></p>
<figcaption>Markov chain with transient states and closed class</figcaption>
</figure>
</div>
<p>This chain has states <span class="math inline">\(\{0, 1, 2, 3\}\)</span> where states <span class="math inline">\(\{0, 1\}\)</span> form a closed communicating class and states <span class="math inline">\(\{2, 3\}\)</span> are transient. Find all invariant distributions for this chain.</p>
</div>
<div id="exm-invariant-absorbing" class="theorem example">
<p><span class="theorem-title"><strong>Example 10.17</strong></span> Consider the Markov chain with transition matrix<br>
<span class="math display">\[
  P = \MATRIX{ 1 &amp; 0 &amp; 0 \\
               0.2 &amp; 0.4 &amp; 0.4 \\
               0 &amp; 0 &amp; 1 }.
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/svg/markov-examples11.svg" class="img-fluid figure-img"></p>
<figcaption>Markov chain with absorbing states</figcaption>
</figure>
</div>
<p>Note that this chain is not irreducible (it has two absorbing states). Compute all possible invariant distributions.</p>
</div></li>
</ol>
</section>
<section id="limiting-distribution" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="limiting-distribution"><span class="header-section-number">10.6</span> Limiting Distribution</h2>
<ol type="1">
<li><p>Suppose a finite Markov chain has the property that starting from any initial distribution, the distribution of <span class="math inline">\(X_n\)</span> converges to some distribution <span class="math inline">\(\pi\)</span> as <span class="math inline">\(n \to \infty\)</span>: <span class="math display">\[
\lim_{n \to \infty} P^{(n)}_{i, j} = \pi_j \qquad \text{for all } i, j \in \ALPHABET X.
\]</span> Then, <span class="math inline">\(\pi\)</span> is an invariant distribution.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We start by showing that <span class="math inline">\(π\)</span> must be a valid probability distribution. In particular, <span class="math display">\[
\sum_{j \in \ALPHABET X} π_j =
\sum_{j \in \ALPHABET X} \lim_{n \to ∞} P^{(n)}_{ij} =
\lim_{n \to ∞} \sum_{j \in \ALPHABET X} P^{(n)}_{ij} = 1
\]</span></p>
<p>We now show that <span class="math inline">\(π\)</span> is an invariant distribution. <span class="math display">\[
π_j = \lim_{n \to ∞} P^{(n)}_{ij}
= \lim_{n \to ∞} \sum_{k \in \ALPHABET X} P^{(n-1)}_{ik} P_{kj}
= \sum_{k \in \ALPHABET X} \lim_{n \to ∞} P^{(n-1)}_{ik} P_{kj}
= \sum_{k \in \ALPHABET X} π_k P_{kj}
\]</span> Thus, <span class="math inline">\(π\)</span> is an invariant distribution.</p>
</div>
</div>
</div></li>
<li><p>As discussed above, limiting distributions exist for ergodic Markov chains (i.e., irreducible and aperiodic Markov chains): for any initial distribution <span class="math inline">\(μ^{(0)}\)</span>, we have <span class="math display">\[\lim_{n \to ∞} μ^{(n)}_j = π_j, \quad \forall j \in \ALPHABET X.\]</span></p>
<p>This is equivalent to the statement that for all <span class="math inline">\(i, j \in \ALPHABET X\)</span>, <span class="math display">\[\lim_{n \to \infty} P^{(n)}_{ij} = π_j.\]</span> This is an consequence of <a href="https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem">:Perron Frobenius Theorem</a>. In matrix form, we have <span class="math display">\[
\lim_{n \to \infty} P^n =
\MATRIX{
   \pi \\
   \pi \\
   \vdots \\
   \pi
}
\]</span> where each row of the limiting matrix is the invariant distribution <span class="math inline">\(π\)</span>. That is, for large <span class="math inline">\(n\)</span>, every row of <span class="math inline">\(P^n\)</span> approaches <span class="math inline">\(π\)</span>.</p></li>
<li><p>In fact, we have a stronger result: the <strong>Strong Law of Large Numbers (SLLN) for (finite) Markov chains.</strong> Let <span class="math inline">\(\{X_n\}_{n \ge 0}\)</span> be an irreducible and aperiodic (i.e., ergodic) Markov chain. Then, for any initial distribution, <span class="math display">\[
\lim_{N \to \infty} \frac{1}{N} \sum_{n=1}^N \IND\{X_n = j\} \xrightarrow{a.s.} \pi_j, \quad \forall j \in \ALPHABET X.
\]</span> This is known as <strong>ergodic property</strong>: sample average equals ensemble average.</p></li>
<li><p>An immediate consequence of the ergodic property is that given an ergodic Markov chain <span class="math inline">\(\{X_n\}_{n \ge 0}\)</span> and any function <span class="math inline">\(f \colon \ALPHABET X \to \reals\)</span>, we have <span class="math display">\[
\lim_{N \to \infty} \frac{1}{N} \sum_{n=1}^N f(X_n) \xrightarrow{a.s.} \sum_{j\in \ALPHABET X} \pi_j f(j).
\]</span></p></li>
<li><p>If the chain is periodic with period <span class="math inline">\(d &gt; 1\)</span> (i.e., not aperiodic), the limiting distribution <span class="math inline">\(\lim_{n \to \infty} P^n\)</span> does not exist in the usual sense, as the transition probabilities continue to oscillate. However, if the chain is irreducible, it still possesses a unique invariant distribution <span class="math inline">\(π\)</span>. In the periodic case, results like ergodicity and the law of large numbers still hold if we consider time averages over subsequences that are integer multiples of the period <span class="math inline">\(d\)</span>, i.e., convergence happens along these subsequences, not along every <span class="math inline">\(n\)</span>.</p></li>
</ol>
</section>
<section id="exercises" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<div id="exr-time-reversal" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 10.1 (Time reversal of Markov chains)</strong></span> Let <span class="math inline">\(\{X_n\}_{n \ge 0}\)</span> be a Markov chain. Show that for any <span class="math inline">\(N &gt; n\)</span>, <span class="math display">\[
  \PR(X_n = x_n \mid X_{n+1:N} = x_{n+1:N})
  = \PR(X_n = x_n \mid X_{n+1} = x_{n+1}).
\]</span> Thus, a time reversed Markov chain is also Markov.</p>
</div>
<div id="exr-k-step-Markov" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 10.2</strong></span> Suppose <span class="math inline">\(\{X_n\}_{n \ge 0}\)</span> is a Markov chain with transition matrix <span class="math inline">\(P\)</span>. For a fixed positive integer <span class="math inline">\(k\)</span>, define <span class="math inline">\(Y_n = X_{kn}\)</span>. Show that <span class="math inline">\(\{Y_n\}_{n \ge 0}\)</span> is a Markov chain with transition matrix <span class="math inline">\(P^k\)</span>.</p>
</div>
<div id="exr-biased-die" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 10.3</strong></span> Suppose a (6-sided) die is ‘fixed’ so that two consecutive rolls cannot have the same outcome. In particular, if the outcome of a roll is <span class="math inline">\(i\)</span>, then the next roll cannot be <span class="math inline">\(i\)</span>; all <span class="math inline">\(5\)</span> other outcomes are equally likely.</p>
<ol type="a">
<li>Model the above as a Markov chain.</li>
<li>If the outcome of the first roll is <span class="math inline">\(1\)</span>, what is the probability that the outcome of the <span class="math inline">\(n\)</span>th roll is also <span class="math inline">\(1\)</span>?</li>
</ol>
</div>
</section>
<section id="further-reading" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><p><a href="https://stats.libretexts.org/Bookshelves/Probability_Theory/Introductory_Probability_(Grinstead_and_Snell)/11%3A_Markov_Chains/11.01%3A_Introduction">Grinstead and Snell, Introduction to Probability</a>, Chapter 11 has an excellent treatment of finite Markov chains. Has interesting exercises.</p></li>
<li><p><a href="https://catalog.hathitrust.org/api/volumes/oclc/528648.html">Kemeny and Snell, Finite Markov Chains</a>, Chapter 2–4.</p></li>
<li><p><a href="https://archive.org/details/springer_10.1007-978-1-4684-9455-6">Kemeny, Snell, and Knapp, Denumerable Markov Chains</a>, a slightly advanced version of the previous book.</p></li>
<li><p><a href="https://doi.org/10.5948/UPO9781614440222">Doyle and Snell, Random Walks and Electrical Networks</a> shows a facinating relationship between random walks and circuits!</p></li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/adityam\.github\.io\/probability-and-random-signals\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./stochastic-processes.html" class="pagination-link" aria-label="Stochastic processes">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Stochastic processes</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./gaussian-processes.html" class="pagination-link" aria-label="Gaussian processes">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Gaussian processes</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/adityam/probability-and-random-signals/edit/quarto/markov-chains.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer><script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>