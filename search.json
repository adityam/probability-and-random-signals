[
  {
    "objectID": "random-variables.html",
    "href": "random-variables.html",
    "title": "Random variables and random vectors",
    "section": "",
    "text": "In many situations, we are not directly interested in the outcome of a random experiment, but a consequence of the outcome. Such consequences may be thought of as a function of the outcome. When they are real-valued, such functions of the outcome are called random variables.\nThe random variable \\(X \\colon Ω \\to \\reals\\) induces a probability measure on \\(\\reals\\). Formally, to define such a probability measure, we need an associated \\(σ\\)-algebra on \\(\\reals\\). As discussed in last lecture, the commonly used \\(σ\\)-algebra on reals is the Borel \\(σ\\)-algebra, \\(\\mathscr{B}(\\reals)\\). For everything to be consistent, we require the function \\(X\\) to satisfy a property known as measurability.\nFor instance, for Example 1, the CDF is given by \\[\nF_X(x) = \\begin{cases}\n0, & \\hbox{if } x &lt; 0,  \\\\\n\\frac 14, & \\hbox{if } 0 \\le x &lt; 1, \\\\\n\\tfrac 34, & \\hbox{if } 1 \\le x &lt; 2,\\\\\n1, &\\hbox{if } 2 \\le x.\n\\end{cases}\\]"
  },
  {
    "objectID": "random-variables.html#classification-of-random-variables",
    "href": "random-variables.html#classification-of-random-variables",
    "title": "Random variables and random vectors",
    "section": "1 Classification of random variables",
    "text": "1 Classification of random variables\nThere are three types of random variables\n\nA random variable \\(X\\) is said to be discrete if it takes values in a finite or countable subset \\(\\text{range}(X) \\coloneqq \\{x_1, x_2, \\dots\\}\\) of \\(\\reals\\). A discrete random variable has a probability mass function (PMF) \\(p \\colon \\reals \\to [0,1]\\) which satisfies the following properties:\n\n\\(p(x) = \\PR(X = x) = F(x) - F(x^{-})\\).\n\\(F(x) = \\sum_{x_n : x_n \\le x} p(x_n).\\)\n\nThus, for a discrete random variable, the CDF is a piecewise constant function\n\nA random variable \\(X\\) is called continuous if there exists an integrable function \\(f \\colon \\reals \\to [0, ∞)\\) called the probability denisity function such that the CDF can be written as \\[\nF(x) = \\int_{-∞}^x f(x) dx.\n\\]\nThus, for a continuous random variable, the CDF is a continuous function\n\nA random variable is called mixed if it is neither discrete nor continuous. For a mixed random variable, the CDF has has jumps at a finite or countable infinite number of points and it is continuous over one or many intervals.\nAs an example, consider the following random experiment. A fair coin is tossed: if the outcome is heads, then \\(X \\sim \\text{Bernoulli}(0.5)\\); if the outcome is tails; then \\(X \\sim \\text{Uniform}[0,1]\\). Thus (from the law of total probability), the CDF of \\(X\\) is \\[\n   F_X(x) = \\begin{cases}\n   0, & \\hbox{if } x &lt; 0 \\\\\n   \\frac 14 & \\hbox{if } x = 0 \\\\\n   \\frac 14 + \\frac x2 & \\hbox{if } 0 &lt; x &lt; 1 \\\\\n   1 & \\hbox{if } x \\ge 1.\n   \\end{cases}.\n   \\]\n\n\n\n\n\n\n\n\\(σ\\)-algebra generated by random variables\n\n\n\nA discrete random variable creates a partition of the sample space. In particular, suppose \\(X\\) is a random variable and \\(\\{x_1, x_2, \\dots\\}\\) is the range of \\(X\\). Define \\[A_n = \\{ω \\in Ω : X(ω) = x_n \\} = X^{-1}(x_n)\\] Then, \\(\\{A_1, A_2, \\dots \\}\\) is a partition of \\(Ω\\).\n\n\n\n\n\n\nProof that it is a partition\n\n\n\n\n\nTo show that \\(\\{A_1, A_2, \\dots \\}\\) forms a partition, we need to establish two properties:\n\n\\(A_i \\cap A_j = \\emptyset\\).\n\\(\\bigcup_{i=1}^∞ A_i = Ω\\).\n\nThe details are left as an exercise.\n\n\n\nThe power-set of \\(\\{A_1, A_2, \\dots\\}\\) is called the \\(σ\\)-algebra generated by \\(X\\) and denoted by \\(σ(X)\\). This \\(σ\\)-algebra captures the crux of measurability. As an illustration, let’s reconsider Example 1. In this case, the range of \\(X\\) is \\(\\{0, 1, 2\\}\\). The partition corresponding to \\(σ(X)\\) is shown in Figure 1.\n\n\n\n\n\n\nFigure 1: Illustration of \\(σ(X)\\) for Example 1\n\n\n\n\n\n\nLemma 2 (Properties of PMFs and PDFs)  \n\nProperties of PMFs\n\nFor a discrete random variable, \\(\\sum_{x \\in \\text{range}(X)}p(x) = 1\\).\nFor any event \\(A \\in \\ALPHABET F\\), \\(\\PR(X \\in A) = \\sum_{x \\in \\text{range}(X) \\cap A} p(x)\\).\n\nProperties of PDFs\n\nFor a continuous random variable, \\(\\int_{-∞}^{∞} f(x)\\, dx = 1\\).\nFor any event \\(A \\in \\ALPHABET F\\), \\(\\PR(X \\in A) = \\int_{x \\in A} f(x)\\,dx\\).\nThe PDF is the derivative of CDF: \\[\nf_X(x) = \\frac{d}{dx} F_X(x).\n\\]\n\n\n\n\n1.1 Some examples of discrete random variables\nWe now consider some other examples of discrete random variables\n\nExample 5 (Binomial random variable) A Binomial random variable is the sum of intendant and identically Bernoulli random variables (we will prove this fact later). For example, if a biased coin (with \\(\\PR(H) = p\\)) is tossed \\(n\\) times, then the number of heads is a binomial random variable with parameters \\(n\\) and \\(p\\), which is denoted by \\(\\text{Binomial}(n,p)\\). For such a random variable, \\[\np_X(k) = \\binom n k p^k (1-p)^{n-k}, \\quad 0 \\le k \\le n.\n\\]\n\n\nExample 6 (Geometric random variable) A geometric random variable is the number of trails in i.i.d. Bernoulli random variables. For example, if a biased coin (with \\(\\PR(H) = p\\)) is tossed repeated, the number of tosses needed for the first head is a geometric random variable with parameter \\(p \\in (0,1)\\)_, which is denoted by \\(\\text{Geo}(p)\\). For such a random variable, \\[\np_X(k) = (1-p)^{k-1} p, \\quad k \\in \\integers_{&gt; 0}.\n\\]\n\n\nExample 7 (Poisson random variable) Poisson random variables model many different phenomenon ranging from photoelectric effect in photonics to inter-packet arrival times in computer networks. A random variable is said to Poisson random variable with parameter \\(λ &gt; 0\\), which is denoted by \\(\\text{Poisson}(λ)\\), if \\[\np_X(k) = \\frac{λ^k}{k!} e^{-λ}, \\quad k \\in \\integers_{\\ge 0}.\n\\]\n\n\nExample 8 (Uniform random variable) A random variable is said to have a (discrete) uniform distribution over a discrete set \\(\\ALPHABET S\\) if \\[p_X(k) = \\frac 1{\\ABS{\\ALPHABET S}}, \\quad k \\in \\ALPHABET S.\\]\n\n\n\n1.2 Some examples of continuous random variables\n\nExample 9 (Uniform random variable) A random variable is said to have a (continuous) uniform distribution over an interval \\([a, b]\\), where \\(a &lt; b\\) if \\[f(x) = \\frac 1{b - a}, \\quad x \\in [a,b].\\]\n\n\nExample 10 (Exponential random variable) A random variable is said to have an exponential distribution with parameter \\(λ &gt; 0\\), which is denoted by \\(\\text{exp}(λ)\\) if \\[f(x) = λ e^{-λ x}, \\quad x \\ge 0.\\]\n\n\nExample 11 (Gaussian random variable) A random variable is said to have a Gaussian distribution with mean \\(μ\\) and standard deviation \\(σ &gt; 0\\), which is denoted by \\(\\mathcal N(μ, σ^2)\\) if \\[f(x) = \\frac 1{\\sqrt{2 π}\\, σ}\n\\exp\\left( -\\frac {(x-μ)^2}{2 σ^2} \\right),\n\\quad x \\in \\reals.\\]"
  },
  {
    "objectID": "random-variables.html#expectation-of-random-variables",
    "href": "random-variables.html#expectation-of-random-variables",
    "title": "Random variables and random vectors",
    "section": "2 Expectation of random variables",
    "text": "2 Expectation of random variables\nSuppose we generate \\(N\\) i.i.d. (independent and identically distributed) samples \\(\\{s_1, s_2, \\dots, s_N\\}\\) of a random variable \\(X\\) and compute the average: \\[ m = \\frac 1N \\sum_{n=1}^N s_n. \\] When \\(X\\) is discrete and takes values \\(\\{x_1, x_2, \\dots, x_n\\}\\), we expect that the number of times we obtain a value \\(x_i\\) is approximately \\(Np(x_i)\\) when \\(N\\) is large. Thus, \\[ m \\approx \\frac 1N \\sum_{i=1}^n x_i \\, N p(x_i)  = \\sum_{i=1}^n x_i p(x_i). \\]\nThis quantity is called the expectation or the expected value or the mean value of the random variable \\(X\\) and denoted by \\(\\EXP[X]\\).\n\nDefinition 2 The expectation of a random variable \\(X\\) is defined as follows:\n\nwhen \\(X\\) is discrete and takes values \\(\\{x_1, x_2, \\dots, x_n \\}\\), then \\[\\EXP[X] = \\sum_{i=1}^n x_i p(x_i).\\]\nwhen \\(X\\) is continuous, then \\[\\EXP[X] = \\int_{-∞}^{∞} x f(x)\\, dx. \\]\nThus, we can think of the expected value as the center of mass of the PDF.\n\n\n\n\n\n\n\n\nDoes the summation or integration exist?\n\n\n\nWhen \\(X\\) takes countably or uncountably infinite values, we need to be a bit more precise by what we mean by the summation (or the integration) formula above. In particular, we do not want the answer to depend on the order in which we do the summation or the integration (i.e., we do not want \\(∞ - ∞\\) situation). This means that the sum or the integral should be :absolutely convergent. Such random variables are called integrable random variables.\nFormally, expectation is defined only for integrable random variables.\nTo illustrate why this is important, consider a discrete random variable defined over \\(\\integers\\setminus\\{0\\}\\) where \\[\np(n) = p(-n) = \\frac {1}{2C n^2}, \\quad n \\in \\naturalnumbers\n\\] where \\(C\\) is a normalizing constant given by \\[\nC = \\sum_{n=1}^∞ \\frac 1{n^2} = \\frac{π^2}{6}.\n\\] Then, observe that \\[\\begin{align*}\n\\EXP[X] &= \\sum_{n=1}^∞ \\frac{n}{2 C n^2}\n+ \\sum_{n=-∞}^{-1} \\frac{n}{2 C n^2} \\\\\n&= \\frac 1{2C} \\sum_{n=1}^∞ \\frac{1}{n}\n+ \\frac 1{2C} \\sum_{n=-∞}^{-1} \\frac{1}{n} \\\\\n&= \\frac{∞}{2C} - \\frac{∞}{2C}\n\\end{align*}\\] which is undefined.\nThe concern here is that the summation is undefined. Mathematically, we are okay when the summation is infinity. For example, consider another random variable \\(Y\\) defined over \\(\\naturalnumbers\\) for which \\[\np(n) = \\frac {1}{C n^2}, \\quad n \\in \\naturalnumbers\n\\] where \\(C\\) is as defined above. This is called the Zipf distribution. By following an argument same as above, we see that \\[\\EXP[Y] = ∞.\\]\n\n\n\nExercise 2 Find the expected value of the random variables with the following distributions:\n\n\\(\\text{Bernoulli}(p)\\).\n\\(\\text{Binomial}(n,p)\\).\n\\(\\text{Geo}(p)\\).\n\\(\\text{Poisson}(λ)\\).\n\\(\\text{Uniform}[a,b]\\).\n\\(\\text{Exp}(λ)\\).\n\n\n\nLemma 3 For any (measurable) function \\(g \\colon \\reals \\to \\reals\\), we have\n\nwhen \\(X\\) is discrete and takes values \\(\\{x_1, x_2, \\dots, x_n \\}\\), then \\[\\EXP[g(X)] = \\sum_{i=1}^n g(x_i) p(x_i).\\]\nwhen \\(X\\) is continuous, then \\[\\EXP[g(X)] = \\int_{-∞}^{∞} g(x) f(x)\\, dx. \\]\n\nBoth expressions are defined only when the sum/integral is absolutely convergent.\n\n\n\n\n\n\n\nHow to avoid a proof\n\n\n\n\n\nThis result is sometimes called *the law of the unconscious statistician (LOTUS). One typically shows this result by defining a new random variable \\(Y = g(X)\\), computing its PMF/PDF \\(f_Y\\) and then using the definition in Definition 2.\nA simpler proof is to define expectation by Lemma 3 for any (measurable) function \\(g\\). Then the definition of Definition 2 falls off as a special case for \\(g(x) = x\\). No proofs needed!\n\n\n\n\nExercise 3 Suppose \\(X \\sim \\text{Unif}[-1,1]\\). Compute \\(\\EXP[X^2]\\).\n\n\nLemma 4 (Properties of expectation)  \n\nLinearity. For any (measurable) functions \\(g\\) and \\(h\\) \\[\\EXP[g(X) + h(X)] = \\EXP[ g(X)] + \\EXP[ h(X) ]. \\] As a special case, for a constant \\(c\\), \\[\\EXP[X + c] = \\EXP[X] + c.\\]\nScaling. For any constant \\(c\\), \\[\\EXP[cX] = c\\EXP[X].\\]\nBounds. If \\(a \\le X(ω) \\le b\\) for all \\(ω \\in Ω\\), then \\[ a \\le \\EXP[X] \\le b. \\]\nIndicator of events. For any (Borel) subset \\(B\\) of \\(\\reals\\), we have \\[\\EXP[ \\IND_{\\{ X \\in B \\}}] = \\PR(X \\in B). \\]\n\n\n\nA continuous random variable is said to be symmetric if \\(f_X(-x) = f_X(x)\\) for all \\(x \\in \\reals\\). A symmetric random variable has mean \\(0\\).\nA continuous random variable is said to be symmetric around \\(m\\) if \\(f(m - x) = f(m + x)\\), for all \\(x \\in \\reals\\). The mean of such a random variable is \\(m\\).\n\n\n2.1 Higher moments\n\nThe \\(m\\)-th moment, \\(m \\ge 1\\) of a random variable \\(X\\) is defined as \\(\\EXP[X^m]\\).\nThe \\(m\\)-th central moment is defined as \\(\\EXP[(X - μ)^m]\\), where \\(μ = \\EXP[X]\\).\nFor second central moment (i.e., \\(m=2\\)) is called variance. The variance satisfies the following: \\[\\VAR(X) = \\EXP[X^2] - (\\EXP[X])^2.\\]\nThe positive square root of variance is called the standard deviation. Variance is often denoted by \\(σ^2\\) and the standard deviation by \\(σ\\).\n\n\nLemma 5 (Properties of variance)  \n\nScaling. For any constant \\(c\\), \\[\\VAR(cX) = c^2 \\VAR(X).\\]\nShift invariance. For any constant \\(c\\), \\[\\VAR(X + c) = \\VAR(X).\\]\n\n\nThe mean and variance of common random variables is show in Table 1\n\n\n\nTable 1: Mean and variance of common random variables\n\n\n\n\n\n\n\n\n\n\n\nRandom variable\nParameter(s)\nMean\nVariance\n\n\n\n\nBernoulli\n\\(p\\)\n\\(p\\)\n\\(p(1-p)\\)\n\n\nBinomial\n\\((n,p)\\)\n\\(np\\)\n\\(np(1-p)\\)\n\n\nGeometric\n\\(p\\)\n\\(\\dfrac 1p\\)\n\\(\\dfrac{1-p}{p}\\)\n\n\nPoisson\n\\(λ\\)\n\\(λ\\)\n\\(λ\\)\n\n\nUniform\n\\((a,b)\\)\n\\(\\frac 12 (a+b)\\)\n\\(\\frac 1{12}(b-a)^2\\)\n\n\nExponential\n\\(λ\\)\n\\(\\dfrac 1 λ\\)\n\\(\\dfrac 1{λ^2}\\)\n\n\nGaussian\n\\((μ,σ)\\)\n\\(μ\\)\n\\(σ^2\\)"
  },
  {
    "objectID": "random-variables.html#random-vectors-and-joint-distributions.",
    "href": "random-variables.html#random-vectors-and-joint-distributions.",
    "title": "Random variables and random vectors",
    "section": "3 Random vectors and joint distributions.",
    "text": "3 Random vectors and joint distributions.\nSuppose \\(X\\) and \\(Y\\) are two random variables defined on the same probability space. The CDFs \\(F_X\\) and \\(F_Y\\) provide information about their individual probabilities. To understand how they behave together, we need to think of the random vector \\((X,Y)\\) taking values in \\(\\reals^2\\). The natural way to do so is to think of the joint CDF \\[\nF_{X,Y}(x,y) = \\PR(\\{ ω \\in Ω : X(ω) \\le x, Y(ω) \\le y \\})\n\\] where we may write the right hand side as \\(\\PR(X \\le x, Y \\le y)\\) for short.\n\nLemma 6 (Properties of CDFs)  \n\nRegularity properties\n\n\\(\\lim_{x \\to -∞} F_{X,Y}(x,y) = 0\\), \\(\\lim_{y \\to -∞} F_{X,Y}(x,y)\\) and \\(\\lim_{x,y \\to +∞} F(x,y) = 1\\).\nJoint CDFs are non-decreasing, i.e., if \\((x_1,y_1) &lt; (x_2, y_2)\\), then \\(F_{X,Y}(x_1,y_1) \\le F_{X,Y}(x_2,y_2)\\).\nJoint CDFs are continuous from above, i.e., \\[\\lim_{u,v \\downarrow 0}F_{X,Y}(x+u,y+v) = F_{X,Y}(x,y).\\]\n\\(\\PR(X = x, Y = y) = F(x,y) - F(x^{-},y^{-})\\).\n\nMarginalization of joint CDFs\n\n\\(\\lim_{y \\to ∞} F_{X,Y}(x,y) = F_X(x)\\)\n\\(\\lim_{x \\to ∞} F_{X,Y}(x,y) = F_Y(y)\\)\n\n\n\n\nExercise 4 Consider random variables \\(X\\) and \\(Y\\) with joint CDF \\(F\\). Show that \\[\n\\PR(a &lt; X \\le b, c &lt; Y \\le d) = F(b,d) - F(a,d) - F(b,c) + F(a,c).\n\\]\n\n\n3.1 Classification of random vectors\nAs was the case for random variables, we can also classify random vectors as discrete, continuous, and mixed.\n\nA random vector \\((X,Y)\\) is called jointly discrete if it takes values in a countable subset of \\(\\reals^2\\) (we denote this subset by \\(\\text{range}(X,Y)\\)). The jointly discrete random variables have a joint PMF \\(f \\colon \\reals \\to [0,1]\\) given by \\[ \\PR(X = x, Y = y) = p(x,y). \\]\nA random vector \\((X, Y)\\) is called jointly continuous if its CDF can be expressed as \\[ F(x,y) = \\int_{-∞}^x \\int_{-∞}^{y} f(u,v)\\, du dv, \\quad\nx,y \\in \\reals \\] for some integrable function \\(f \\colon \\reals^2 \\to [0, ∞)\\) which is called the joint PDF.\nA random vector \\((X,Y)\\) is called jointly mixed if it is neither jointly discrete nor jointly continuous.\n\n\nLemma 7 (Properties of PMFs and PDFs)  \n\nProperties of PMFs\n\nNormalization. For a jointly discrete random vector \\((X,Y)\\), \\[\\sum_{x,y \\in \\text{range}(X,Y)}p_{X,Y}(x,y) = 1.\\]\nFor any event \\(A \\in \\ALPHABET F\\), \\[\\PR((X,Y) \\in A) = \\sum_{(x,y) \\in \\text{range}(X,Y) \\cap A} p_{X,Y}(x,y).\\]\nMarginalization.\n\n\\(\\displaystyle \\sum_{x \\in \\text{range(X)}} p_{X,Y}(x,y) = p_Y(y)\\).\n\\(\\displaystyle \\sum_{y \\in \\text{range(Y)}} p_{X,Y}(x,y) = p_X(x)\\).\n\n\nProperties of PDFs\n\nNormalization. For a jointly continuous random vector \\((X,Y)\\), \\[\\int_{-∞}^{∞} \\int_{-∞}^{∞} f_{X,Y}(x,y)\\, dxdy = 1.\\]\nFor any event \\(A \\in \\ALPHABET F\\), \\[\\PR((X,Y) \\in A) = \\iint_{(x,y) \\in A} f_{X,Y}(x,y)\\,dxdy.\\]\nMarginalization.\n\n\\(\\displaystyle \\int_{-∞}^{∞} f_{X,Y}(x,y) dx = f_Y(y)\\).\n\\(\\displaystyle \\int_{-∞}^{∞} f_{X,Y}(x,y) dy = f_X(x)\\).\n\n\n\n\nThe above discussion generalizes in the obvious manner to more than two random variables as well. Thus, we can talk about random vectors \\(X = (X_1, \\dots, X_n) \\in \\reals^n\\). In practice, we often do not make a distinction between random variables and random vectors and refer both of them simply as random variables."
  },
  {
    "objectID": "random-variables.html#independence-of-random-vectors",
    "href": "random-variables.html#independence-of-random-vectors",
    "title": "Random variables and random vectors",
    "section": "4 Independence of random vectors",
    "text": "4 Independence of random vectors\n\nDefinition 3 Two random variables \\(X\\) and \\(Y\\) defined on a common probability space \\((Ω, \\ALPHABET F, \\PR)\\) are said to be independent if the sigma algebras \\(σ(X)\\) and \\(σ(Y)\\) are independent.\n\nThe above definition means that if we take any (Borel) subsets \\(B_1\\) and \\(B_2\\) of \\(\\reals\\), then the events \\(\\{X \\in B_1\\}\\) and \\(\\{X \\in B_2\\}\\) are independent, i.e., \\[\n\\PR(X \\in B_1, Y \\in B_2) = \\PR(X \\in B_1) \\PR(Y \\in B_2).\n\\]\nUsing this, we can show that following:\n\n\\(X\\) and \\(Y\\) are independent if and only if \\[\n   F_{X,Y}(x,y) = F_X(x) F_Y(y), \\quad \\forall x, y \\in \\reals.\n\\]\nTwo jointly continuous random variables \\(X\\) and \\(Y\\) are independent if and only if \\[\n   f_{X,Y}(x,y) = f_X(x) f_Y(y), \\quad \\forall x, y \\in \\reals.\n\\]\nTwo jointly discrete random variables \\(X\\) and \\(Y\\) are independent if and only if \\[\n   p_{X,Y}(x,y) = p_X(x) p_Y(y), \\quad \\forall x, y \\in \\reals.\n\\]\n\nAn immediate implication of the above definition is the following.\n\nProposition 1 Let \\(X\\) and \\(Y\\) be independent random variables defined on a common probability space. Consider \\(U = g(X)\\) and \\(V = h(Y)\\) for some (measurable) functions \\(g\\) and \\(h\\). Then, \\(U\\) and \\(V\\) are independent.\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nConsider any (Borel) subsets \\(B_1\\) and \\(B_2\\) of \\(\\reals\\) and consider the events \\(\\{ U \\in B_1 \\}\\) and \\(\\{ V \\in B_2 \\}\\). Note that\n\n\\(\\{ U \\in B_1 \\} = \\{ X \\in g^{-1}(B_1) \\}\\).\n\\(\\{ V \\in B_2 \\} = \\{ Y \\in h^{-1}(B_2) \\}\\).\n\nSince the random variables \\(X\\) and \\(Y\\) are independent, the events \\(\\{ X \\in g^{-1}(B_1) \\}\\) and \\(\\{ Y \\in h^{-1}(B_2) \\}\\). Which implies that the events \\(\\{ U \\in B_1 \\}\\) and \\(\\{ V \\in B_2 \\}\\) are independent. Consequently, the random variables \\(U\\) and \\(V\\) are independent.\n\n\n\n\nProposition 2 Let \\(X\\) and \\(Y\\) be independent random variables defined on a common probability space. Then \\(X\\) and \\(Y\\) are independent if and only if \\[\\begin{equation}\\label{eq:expectation-product}\n  \\EXP[ g(X) h(Y) ] = \\EXP[ g(X) ] \\EXP[ h(Y) ]\n\\end{equation}\\] for all (measurable) functions \\(g\\) and \\(h\\).\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThere are two claims here.\n\nIf \\(X\\) and \\(Y\\) are independent then \\(\\eqref{eq:expectation-product}\\) holds.\nIf \\(\\eqref{eq:expectation-product}\\) holds, then \\(X\\) and \\(Y\\) are independent.\n\nWe will prove the first claim assuming that \\(X\\) and \\(Y\\) are continuous. Similar argument works for the discrete case as well. \\[\\begin{align*}\n  \\EXP[ g(X) h(Y) ]\n  &= \\int_{-∞}^∞ \\int_{-∞}^∞ g(x) h(y) f_{X,Y}(x,y)\\, dx dy \\\\\n  &\\stackrel{(a)}= \\int_{-∞}^∞ \\int_{-∞}^∞ g(x) h(y) f_{X}(x) f_{Y}(y)\\, dy dx \\\\\n  &\\stackrel{(b)}= \\int_{-∞}^∞ \\left[ \\int_{-∞}^∞ g(x)f_{X}(x)\\, dx \\right]h(y) f_{Y}(y)  \\, dy \\\\\n  &\\stackrel{(c)}= \\left[ \\int_{-∞}^∞ g(x)f_{X}(x)\\, dx \\right]\n  \\left[\\int_{-∞}^∞  h(y) f_{Y}(y)  \\, dy \\right] \\\\\n  &= \\EXP[ g(X) ] \\EXP [ h(Y) ]\n\\end{align*}\\] where \\((a)\\) follows from the fact that \\(X \\independent Y\\), \\((b)\\) and \\((c)\\) are simple algebra, and the last step uses the definition of expectation.\nTo prove the second claim, pick any (Borel) subsets \\(B_1\\) and \\(B_2\\) of \\(\\reals\\) and consider the functions \\(g(x) = \\IND_{B_1}(x)\\) and \\(h(y) = \\IND_{B_2}(y)\\). Observe that \\[\\begin{align*}\n  \\PR(X \\in B_1, Y \\in B_2)\n  &= \\EXP[\\IND_{ \\{ X \\in B_1, Y \\in B_2 \\}}] \\\\\n  &\\stackrel{(d)}= \\EXP[\\IND_{ \\{ X \\in B_1 \\}} \\IND_{\\{ Y \\in B_2 \\}}] \\\\\n  &\\stackrel{(e)}=\\EXP[\\IND_{ \\{ X \\in B_1 \\}}\\ \\EXP[ \\IND_{\\{ Y \\in B_2 \\}}] \\\\\n  &\\stackrel{(f)}= \\PR(X \\in B_1) \\PR(Y \\in B_2)\n\\end{align*}\\] where \\((d)\\) follows from basic algebra, \\((e)\\) follows from \\(\\eqref{eq:expectation-product}\\), and \\((f)\\) follows from expectation of an indicator.\nThe above equation shows that for any arbitrary (Borel) subsets \\(B_1\\) and \\(B_2\\) of \\(\\reals\\), \\(\\PR(X \\in B_1, Y \\in B_2) = \\PR(X \\in B_1) \\PR(Y \\in B_2)\\). Hence, \\(\\{X \\in B_1\\} \\independent \\{Y \\in B_2 \\}\\). Since \\(B_1\\) and \\(B_2\\) were arbitrary, we have \\(X \\independent Y\\)."
  },
  {
    "objectID": "random-variables.html#correlation-and-covariance",
    "href": "random-variables.html#correlation-and-covariance",
    "title": "Random variables and random vectors",
    "section": "5 Correlation and covariance",
    "text": "5 Correlation and covariance\nLet \\(X\\) and \\(Y\\) be random variables defined on the same probability space.\n\nCorrelation between \\(X\\) and \\(Y\\) is defined as \\(\\EXP[XY]\\).\nCovariance between \\(X\\) and \\(Y\\) is defined as \\(\\COV(X,Y) = \\EXP[(X - μ_X) (Y - μ_Y)]\\). The covariance satisfies the following: \\[\n\\COV(X,Y) = \\EXP[XY] - \\EXP[X] \\EXP[Y].\n\\]\nCorrelation coefficient between \\(X\\) and \\(Y\\) is defined as \\[ρ_{XY} = \\frac{\\COV(X,Y)}{\\sqrt{\\VAR(X) \\VAR(Y)}}.\\]\nThe correlation coefficeint satisfies \\(\\ABS{ρ_{XY}} \\le 1\\) with equality if and only if \\(\\PR(aX + bY = c) = 1\\) for some \\(a,b,c \\in \\reals\\). [The proof follows from Cauchy-Schwartz inequality, which we will study later]\n\\(X\\) and \\(Y\\) are said to be uncorrelated if \\(ρ_{XY} = 0\\), which is equivalent to \\(\\EXP[XY] = \\EXP[X] \\EXP[Y]\\).\nIndepdent random variables are uncorrelated but the reverse in not true.\n\n\nExample 12 Consider the probability space \\((Ω, \\ALPHABET F, \\PR)\\) where \\(Ω = [0, 2 π)\\), \\(\\ALPHABET F\\) is the Borel \\(σ\\)-algebra on \\([0, 2 π)\\) and \\(\\PR\\) is the uniform distribution on \\(Ω\\). Define \\(X(ω) = \\cos ω\\) and \\(Y(ω) = \\sin ω\\). Show that \\(X\\) and \\(Y\\) are uncorrelated but not independent.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe event \\(\\{X = 1\\}\\) corresponds to \\(ω = 0\\) and therefore \\(\\{Y = 0\\}\\). Thus, \\(X\\) and \\(Y\\) are not independent.\nObserve that\n\n\\(\\displaystyle \\EXP[X] = \\int_{0}^{2 π} \\cos ω \\frac{1}{2 π}\\, d ω = 0\\).\n\\(\\displaystyle \\EXP[Y] = \\int_{0}^{2 π} \\sin ω \\frac{1}{2 π}\\, d ω = 0\\).\n\\(\\displaystyle \\EXP[XY] = \\int_{0}^{2 π} \\cos ω \\sin ω \\frac{1}{2 π}\\, d ω =\n\\frac{1}{4{π}} \\int_0^{2 π} \\cos 2 ω\\, d ω = 0\\).\n\nThus, \\[\\EXP[XY] = \\EXP[X]\\EXP[Y].\\]\n\n\n\n\n5.1 Correlation and covariance for random vectors\nSome of these concepts also generalize to random vectors. First, we define expected value for random vectors and random matrices.\n\nIf \\(X = [X_1, \\dots, X_n] \\in \\reals^n\\), then \\[ \\EXP[X] = \\MATRIX{ \\EXP[X_1] & \\cdots & \\EXP[X_n] }. \\]\nIf \\(X = \\MATRIX{ X_{1,1} & \\cdots & X_{1,n} \\\\ X_{2,1} & \\cdots & X_{2,n} \\\\\n\\vdots & \\vdots & \\vdots \\\\\nX_{m,1} & \\cdots & X_{m,n} } \\in \\reals^{m \\times n}\\) is a ranom matrix, then \\[ \\EXP[X] = \\MATRIX{ \\EXP[X_{1,1}] & \\cdots & \\EXP[X_{1,n}] \\\\ \\EXP[X_{2,1}] & \\cdots & \\EXP[X_{2,n}] \\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\EXP[X_{m,1}] & \\cdots & \\EXP[X_{m,n}] }.\n\\]\n\nWe the above notation, we can define the following:\n\nThe correlation matrix of a random vector \\(X \\in \\reals^n\\) is defined as \\[ R = \\EXP[X X^\\TRANS],\\] where \\(X^\\TRANS\\) denotes the transpose of \\(X\\).\nThe correlation matrix is symmetric, i.e., \\(R = R^\\TRANS\\)\nThe covariance matrix of a random vector \\(X \\in \\reals^n\\) is defined as \\[\\COV(X) = \\EXP[ (X - μ_X) (X - μ_X)^\\TRANS].\\]\nThe covariance matrix is symmetric. Moreover, \\([\\COV(X)]_{i,j} = \\COV(X_i,X_j)\\).\nThe cross correlation matrix of random vectors \\(X \\in \\reals^n\\) and \\(Y \\in \\reals^m\\) is a \\(n × p\\) matrix given by \\[\n  R_{XY} = \\EXP[X Y^\\TRANS].\n\\]\nThe cross covariance matrix of random vectors \\(X \\in \\reals^n\\) and \\(Y \\in \\reals^m\\) is a \\(n × p\\) matrix given by \\[\n  \\COV(X,Y) = \\EXP[ (X - μ_X) (Y - μ_Y)^\\TRANS ].\n\\]\nTwo random vectors \\(X\\) and \\(Y\\) are called uncorrelated if \\[\\EXP[ (X - μ_X) (Y - μ_Y)^\\TRANS ] = 0 \\]\nTwo random vectors \\(X\\) and \\(Y\\) are called orthogonal if \\[\\EXP[X Y^\\TRANS] = 0 \\]\nBoth the correlation and covariance matrices are positive semidefinite. Thus, their eigenvalues are real and non-negative."
  },
  {
    "objectID": "random-variables.html#functions-of-random-variables",
    "href": "random-variables.html#functions-of-random-variables",
    "title": "Random variables and random vectors",
    "section": "6 Functions of random variables",
    "text": "6 Functions of random variables\nIn an interconnected systems, the output of one system is used as input to another system. To analyze such systems, it is important to understand how to analyze functions of random variables.\nIn particular, let \\(X\\) be a random variable defined on \\((Ω, \\ALPHABET F, \\PR)\\). Suppose \\(g \\colon \\reals \\to \\reals\\) is a (measurable) function. Define \\(Y = g(X)\\).\n\nSince \\(g\\) is measurable, for any (Borel) subset of \\(\\reals\\), we have that \\(C = g^{-1}(B) \\in \\mathscr B(\\reals)\\). Therefore, \\(X^{-1}(C) \\in \\ALPHABET F\\). Thus, we can think of \\(Y\\) as a random variable.\nSince \\(Y\\) is a random variable, it is possible to compute its CDF and PMF/PDF as appropriate. We illustrate this concept via some examples.\n\n\nExample 13 Suppose \\(X \\sim \\text{Uniform}[0,2]\\). Consider a function \\(g\\) given by \\[\ng(x) = \\begin{cases}\n  x & x \\in (0,1] \\\\\n  1- x & x \\in (1,2] \\\\\n  0 & \\hbox{otherwise}\n\\end{cases}\n\\] Define \\(Y = g(X)\\). Find \\(F_Y(y)\\) and \\(f_Y(y)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFrom the definition of \\(g\\), we know that the rannge of \\(g\\) is \\([0,1]\\). Thus, we know that the support of \\(Y\\) is \\([0,1]\\).\n\nFor any \\(y &lt; 0\\), the event \\(\\{Y \\le y\\} = \\emptyset\\). Therefore, \\(F_Y(y) = 0\\).\nFor any \\(y &gt; 1\\), the event \\(\\{Y \\le y\\} = Ω\\). Therefore, \\(F_Y(y) = 1\\).\nNow consider a \\(y \\in (0,1)\\). We have \\[\n\\{Y \\le y \\} = \\{ X \\le y \\} \\cup \\{X \\ge 2 - y \\}.\n\\] Thus, \\[\nF_Y(y) = F_X(y) + F_X(2-y) = \\frac {y}{2} + 1 - \\frac{2-y}{2} = y.\n\\] Thus, \\[\n   f_Y(y) = \\dfrac{d}{dy} F_Y(y) = 1, \\quad y \\in [0,1].\n\\] Thus, \\(Y\\) is \\(\\text{Uniform}[0,1]\\).\n\n\n\n\n\nExample 14 Suppose \\(X \\sim \\text{Uniform}[0,4]\\). Consider a function \\(g\\) given by \\[\ng(x) = \\begin{cases}\n  x & x \\in (0,1] \\\\\n  1 & x \\in (1, 3) \\\\\n  4- x & x \\in (3,4] \\\\\n  0 & \\hbox{otherwise}\n\\end{cases}\n\\] Define \\(Y = g(X)\\). Find \\(F_Y(y)\\) and \\(f_Y(y)\\).\n\nThe same idea can be used for functions of multiple random variables as we illustrate via the following examples.\n\nExample 15 Suppose \\(X \\sim \\mathcal{N}(μ,σ^2)\\). Show that \\(Z = (X - μ)/σ\\) is a standard normal random variable, i.e., \\(Z \\sim \\mathcal{N}(0,1)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can write the CDF \\(F_Z(z)\\) as \\[\\begin{align*}\nF_Z(z) &= \\PR(Z \\le z) = \\PR\\left( \\frac{X - μ}{σ} \\le z \\right)\n= \\PR(X \\le σ z + μ)\n\\\\\n&= \\int_{-∞}^{σ z + μ} \\frac{1}{\\sqrt{2 π}\\, σ} \\exp\\left(\n- \\frac{(x-μ)^2}{2 σ^2}\\, dx \\right)\n\\\\\n&= \\int_{-∞}^{z} \\frac{1}{\\sqrt{2 π}} \\exp\\left(\n- \\frac{y^2}{2}\\, dy \\right)\n\\end{align*}\\] where the last step uses the change of variables \\(y = (x-μ)/σ\\).\nThus, \\[f_Z(z) = \\frac{d F_Z(z)}{dz} = \\frac{1}{\\sqrt{2 π}} e^{-z^2/2}.\\] Thus, \\(Z \\sim \\mathcal{N}(0,1)\\).\n\n\n\n\nExample 16 Suppose \\(X \\sim \\text{Uniform}[0,1]\\), and \\(F \\colon \\reals \\to [0,1]\\) is a function that satisfies the following properties: there exist a pair \\((a,b)\\) with \\(a &lt; b\\) (we allow \\(a\\) to be \\(-∞\\) and \\(b\\) to be \\(∞\\)) such that\n\n\\(F(y) = 0\\) for \\(y \\le a\\)\n\\(F(y) = 1\\) for \\(y \\ge b\\)\n\\(F(y)\\) is strctly increasing in \\((a,b)\\).\n\nThus, \\(F\\) satisifies the properties of the CDF of a continuous random variable and \\(F\\) is invertible in the interval \\((a,b)\\).\nDefine \\(Y = F^{-1}(X)\\). Show that \\(F_Y(y) = F(y)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can write the CDF \\(F_Y(y)\\) as \\[\nF_Y(y) = \\PR(Y \\le y) = \\PR(F^{-1}(X) \\le y)\n\\]\nSince \\(F\\) is strictly increasing, \\(F^{-1}(X) \\le y\\) is equivalent to \\(X \\le F(y)\\). Thus, \\[\nF_Y(y) = \\PR(X \\le F(y)) = F_X(F(y)) = F(y)\n\\] where the last step uses the fact tht \\(X\\) is uniform over \\([0,1]\\).\n\n\n\n\nExample 17 Suppose \\(X_1\\) and \\(X_2\\) are continuous random variables and \\(Y = X_1 + X_2\\). Find the PDF \\(f_Y(y)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can write the CDF \\(F_Y(y)\\) as follows: \\[\nF_Y(y)\n= \\int_{-∞}^∞ \\int_{-∞}^{y - x_1} f_{X_1,X_2}(x_1, x_2)\\, d x_2 d x_1 \\\\\n\\] Therefore, \\[\\begin{align*}\nf_Y(y) &= \\frac{d F_Y(y)}{dy} \\\\\n&= \\int_{-∞}^∞ \\frac{d}{dy} \\int_{-∞}^{y-x_1} f_{X_1, X_2}(x_1, x_2) \\, dx_2\\, dx_1 \\\\\n&= \\int_{-∞}^∞ f_{X_1, X_2}(x_1, y - x_1)\\, dx_1.\n\\end{align*}\\]\n\n\n\n\nExample 18 Repeat Example 17 when \\(X_1\\) and \\(X_2\\) are independent.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIn this case, \\(f_{X_1, X_2}(x_1, x_2) = f_{X_1}(x_1) f_{X_2}(x_2)\\). Therefore, we get \\[f_Y(y) = \\int_{-∞}^{∞} f_{X_1}(x_1) f_{X_2}(y - x_2) d x_1 = (f_{X_1} * f_{X_2})(y)\\] where \\(*\\) denotes convolution.\n\n\n\n\nExample 19 Repeat Example 18 when \\(X_1 \\sim \\text{Poisson}(λ_1)\\) and \\(X_2 \\sim \\text{Poisson}(λ_2)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRecall that for a Poisson random variable \\(X\\) with parameter \\(λ\\) \\[\np_X(k) = e^{-λ} \\frac{λ^k}{k!}, \\quad k \\ge 0\n\\]\nThus, \\[\\begin{align*}\np_Y(n) &= (p_{X_1} * P_{X_2})(n)\n= \\sum_{k=-∞}^{∞} p_{X_1}(k) p_{X_2}(n-k)\n\\\\\n&=\\sum_{k=0}^{n} p_{X_1}(k) p_{X_2}(n-k)  \n\\\\\n&= \\sum_{k=0}^n e^{-λ_1 - λ_2} \\frac{ λ_1^k λ_2^{n-k} }{ k! (n-k)! }\n\\\\\n&= e^{-(λ_1 + λ_2)} \\frac{1}{n!}\n\\sum_{k=0}^n \\frac{n!}{k!(n-k)!} λ_1^k λ_2^{n-k}\n\\\\\n&= e^{-(λ_1 + λ_2)} \\frac{(λ_1 + λ_2)^n}{n!}\n\\end{align*}\\]\nThus, \\(Y \\sim \\text{Poisson}(λ_1 + λ_2)\\).\n\n\n\n\nExample 20 Let \\(X\\) and \\(Y\\) be random variables defined on a common probability space. Define \\[\nU = \\max(X,Y)\n\\quad\nV = \\min(X,Y).\n\\] Find \\(F_U\\) and \\(F_V\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nWe first look at \\(F_U\\). By definition \\[ F_U(u) = \\PR(X \\le u, Y \\le u) = F_{X,Y}(u,u).\\]\nNow consider \\(F_V\\). The event \\(\\{V \\le v\\}\\) can be expressed as \\[ \\{ V \\le v \\} = \\{ X \\le v \\} \\cup \\{Y \\le v \\} \\cap \\{X \\le v \\} \\cap \\{Y \\le v\\}.\\] Thus, \\[F_V(v) = F_X(v) + F_Y(v) - F_{X,Y}(v,v). \\]\n\n\n\n\n\n6.1 Change of variables formulas\nFor continuous random variables, it is possible to obtain a general change of variable formula to obtain the PDF of functions of random variable in terms of their joint PDF. My personal view is that it is simpler to reason about such change of variables from first principles, but nonetheless it is good to know the results.\n\nSuppose \\(X\\) is a continuous random variable with PDF \\(f_X\\) and \\(Y = g(X)\\), where \\(g\\) is a continuous and one-to-one function (from \\(\\text{Range}(X)\\) to \\(\\text{Range}{Y}\\)). Thus, \\(g\\) must be either strictly increasing or strictly decreasing, and in both cases the inverse \\(g^{-}\\) is well defined.\n\nIf \\(g^{-1}\\) is strictly increasing, we have \\[ F_Y(y) = \\PR(Y \\le y) = \\PR(X \\le g^{-1}(y) = F_X(g^{-1}(y))\\] Therefore, \\[ f_Y(y) = \\frac{d F_X(g^{-1}(y))}{dy} = f_X(g^{-1}(y)) \\frac{d g^{-1}(y)}{dy}. \\]\nIf \\(g^{-1}\\) is strictly decreasing, we have \\[ F_Y(y) = \\PR(Y \\le y) = \\PR(X \\ge g^{-1}(y)) = 1 - F_X(g^{-1}(y)).\\] Therefore, \\[ f_Y(y) = - \\frac{d F_X(g^{-1}(y))}{dy} = - f_X(g^{-1}(y)) \\frac{d g^{-1}(y)}{dy}. \\]\nThe above two formulas can be combined as \\[ \\bbox[5pt,border: 1px solid]{f_Y(y) = f_X(g^{-1}(y)) \\left| \\frac{d g^{-1}(y)}{dy} \\right|} \\]\n\nFrom calculus, we know that if \\(h(y) = g^{-1}(y)\\), then \\(h'(y) = 1/g'(h(y))\\). Thus, the above expression can be simplified as \\[ \\bbox[5pt, border: 1px solid]{f_Y(y) = \\frac{f_X(x)}{\\ABS{g'(x)}}, \\quad \\text{where } x = g^{-1}(y).} \\]\nResolve Example 15 using the above formula.\nIf the transform \\(g(x)\\) is not one-to-one (as in Example 13), we can obtain \\(f_Y(y)\\) as follows. Suppose \\(y = g(x)\\) has finite roots, denoted by \\(\\{x^{(k)}\\}_{k=1}^m\\). Then, \\[ f_Y(y) = \\sum_{k=1}^m \\frac{f_X(x^{(k)})}{\\ABS{g'(x^{(k)})}}. \\]\nResolve Example 13 using the above formula.\nNow suppose \\(\\{X_1, \\dots, X_n\\}\\) are jointly continuous random variables with joint PDF \\(f\\). Consider \\(n\\) random variables: \\[\\begin{align*}\n   Y_1 &= g_1(X_1, \\dots, X_n) \\\\\n   Y_2 &= g_2(X_1, \\dots, X_n) \\\\\n   \\vdots &= \\vdots \\\\\n   Y_n &= g_n(X_1, \\dots, X_n).\n\\end{align*}\\] We can view this as an equation between two \\(n\\)-dimensional vectors \\(Y = \\VEC(Y_1, \\dots, Y_n)\\) and \\(X = \\VEC(X_1, \\dots, X_n)\\) written as \\[ Y = g(X) \\]\nAs was the case for the scalar system, for a given \\(y \\in \\reals^n\\), the vector equation \\(y = g(x)\\) may have zero, one, or multiple solutions.\n\nIf \\(y = g(x)\\), \\(y \\in \\reals^n\\) has no solution, then \\[ f_Y(y) = 0. \\]\nIf \\(y = g(x)\\), \\(y \\in \\reals^n\\) has one solution \\(x \\in \\reals^n\\), then \\[ f_Y(y) = \\frac{f_X(x)}{\\ABS{J(x)}}, \\quad \\text{where } y = g(x)\\] and \\(J(x)\\) denotes the Jacobian on \\(g(x)\\) evaluated at \\(x = (x_1, \\dots, x_n)\\), i.e., \\[\n\\def\\1#1#2{\\dfrac{∂ g_{#1}}{∂ x_{#2}}}\nJ(x_1, \\dots, x_n) =\n\\DET{ \\1 11 & \\cdots & \\1 1n \\\\\n      \\vdots & \\vdots & \\vdots \\\\\n      \\1 n1 & \\cdots & \\1 nn }\n\\]\nIf \\(y = g(x)\\), \\(y \\in \\reals^n\\) has multiple solutions given by \\(\\{x^{(1)}, \\dots, x^{(m)}\\}\\), then \\[ f_Y(y) =\n\\sum_{k=1}^m \\frac{f_X(x^{(k)})}{\\ABS{J(x^{(k)})}}.\\]\n\n\n\nExample 21 Resolve Example 20 using the change of variables formula.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet \\(g_1(x,y) = \\max\\{x, y\\}\\) and \\(g_2(x,y) = \\min\\{x,y\\}\\). Define \\[ U = g_1(X,Y) \\quad\\text{and}\\quad V = g_2(X,Y).\\]\nDefine \\(g(x,y) = \\VEC(g_1(x,y), g_2(x,y))\\). Note that \\(g\\) is not differentiable at \\(x=y\\).\n\nWhen \\(x &gt; y\\), we have \\(g_1(x,y) = x\\) and \\(g_2(x,y) = y\\). Thus, \\[\nJ(x,y) = \\DET{\\1 11 & \\1 12 \\\\ \\1 21 & \\1 22}\n= \\DET{1 & 0 \\\\ 0 & 1} = 1. \\]\nWhen \\(x &lt; y\\), we have \\(g_1(x,y) = y\\) and \\(g_2(x,y) = x\\). Thus, \\[\nJ(x,y) = \\DET{\\1 11 & \\1 12 \\\\ \\1 21 & \\1 22}\n= \\DET{0 & 1 \\\\ 1 & 0} = -1. \\]\n\nWe now compute \\(f_{U,V}(u,v)\\).\n\nIf \\(u &lt; v\\), then the equation \\((u,v) = g(x,y)\\) has no solution. So we set \\[ f_{U,V}(u,v) = 0. \\]\nIf \\(u &gt; v\\), then the equation \\((u,v) = g(x,y)\\) has two solutions: \\(\\{ (u,v), (v,u) \\}\\). Thus, \\[\nf_{U,V}(u,v) = \\frac{f_{X,Y}(u,v)}{\\ABS{1}} + \\frac{f_{X,Y}(v,u)}{\\ABS{-1}}\n= f_{X,Y}(u,v) + f_{X,Y}(v,u). \\]\nIf \\(u = v\\), then the equation \\((u,u) = g(x,y)\\) has one solution \\((u,u)\\). Thus, \\[ f_{U,V}(u,u) = f_{X,Y}(u,u). \\] Note that \\(u = v\\) is a line in two-dimensional space. (Formally, it is a set of measure zero.) Hence, the choice of \\(f_{U,V}\\) at \\(u = v\\) will not affect any probability computations. So we can also set \\[ f_{U,V}(u,u) = 0. \\]\n\nFrom the joint PDF \\(f_{U,V}\\), we can compute the marginals as follows:\n\nFor \\(U\\), we have \\[\nf_U(u) = \\int_{-∞}^{∞} f_{U,V}(u,v) dv\n= \\int_{-∞}^{u} \\bigl[ f_{X,Y}(u,v) + f_{X,Y}(v,u) \\bigr] dv.\n\\] Therefore, \\[\nF_U(u) = \\int_{-∞}^{u} f_U(\\tilde u) d\\tilde u\n= \\int_{-∞}^u \\int_{-∞}^{\\tilde u} \\bigl[ f_{X,Y}(\\tilde u,v) + f_{X,Y}(v,\\tilde u) \\bigr] dv d\\tilde u.\n\\] Note that \\[ \\int_{-∞}^u \\int_{-∞}^{\\tilde u} f_{X,Y}(\\tilde u, v) dv d\\tilde u\n= \\int_{-∞}^u \\int_{-∞}^{x} f_{X,Y}(x, y) dy dx\n\\] and \\[\\begin{align*}\n\\int_{-∞}^u \\int_{-∞}^{\\tilde u} f_{X,Y}(v, \\tilde u) dv d\\tilde u\n&= \\int_{-∞}^u \\int_{-∞}^y f_{X,Y}(x,y) dx dy\n\\\\\n&= \\int_{-∞}^u \\int_{x}^u f_{X,Y}(x,y) dy dx\n\\end{align*}\\] where the last step follows from changing the order of integration.\nSubstituting these back in the expression for \\(F_U(u)\\), we get \\[\nF_U(u)\n= \\int_{-∞}^u \\int_{-∞}^{x} f_{X,Y}(x, y) dy dx\n+ \\int_{-∞}^u \\int_{x}^u f_{X,Y}(x,y) dy dx\n= \\int_{-∞}^u \\int_{-∞}^u f_{X,Y}(x,y) dy dx = F_{X,Y}(u,u). \\]\nFor \\(V\\), we can follow similar algebra as above.\n\n\n\n\n\nExample 22 Let \\(X\\) and \\(Y\\) be random variables defined on a common probability space. Define \\[\n  U = X^2 \\quad\\text{and}\\quad V = X + Y.\n\\] Find \\(F_{U,V}\\)?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet’s consider the system of equations \\[\n  u = x^2 \\quad\\text{and}\\quad v = x + y\n\\] for a given value of \\((u,v)\\). First observe that \\[\n  J(x,y) = \\DET{ 2x & 0 \\\\ 1 & 1 } = 2x.\n\\]\n\nIf \\(u &lt; 0\\), then the system of equations has no solutions. Therefore, \\[\n   F_{U,V}(u,v) = 0, \\quad u &lt; 0.\n\\]\nIf \\(u = 0\\), then the system of equations has one solution: \\[\n   x^{(1)} = 0 \\quad\\text{and}\\quad y^{(1)} = v.\n\\] However, \\(J(0,v) = 0\\). So, \\[\n   f_{U,V}(0,v) = \\frac{f_{X,Y}(0,v)}{J(0,v)}\n\\] is undefined. However, since \\(u = 0\\) is a line in two-dimensions (i.e., a set of measure zero), the choice of \\(f_{U,V}\\) at \\(u = 0\\) will not affect any probability computations. So, we set \\[\n   f_{U,V}(0,v) = 0.\n\\]\nIf \\(u &gt; 0\\), then the system of equations has two solutions: \\[\n   (x^{(1)}, y^{(1)}) = (+\\sqrt{u}, v - \\sqrt{u})\n   \\quad\\text{and}\\quad\n   (x^{(2)}, y^{(2)}) = (-\\sqrt{u}, v + \\sqrt{u})\n\\] Therefore, \\[\n   f_{U,V}(u,v) = \\frac{f_{X,Y}(\\sqrt{u}, v - \\sqrt{u})}{2 \\sqrt{u}}\n   + \\frac{f_{X,Y}(-\\sqrt{u}, v + \\sqrt{u})}{2 \\sqrt{u}}.\n\\]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Outline",
    "section": "",
    "text": "Instructor\n\n\nAditya Mahajan\nOffice Hours: TBD\n\n\nTeaching Assistants\n\n\nAlexander Fernandes\n\n\nLectures\n\n\n2:35pm–3:55pm Monday, Wednesday (ENGTR 2100)\n\n\nTutorials\n\n\n12:35am–1:25am Friday, (ENGTR 2100)\n\n\nPrerequisites\n\n\nECSE 205 (Probability and Random Signals I)\nECSE 206 or ECSE 316 (Signals and Systems)\n\n\nCommunication\n\nUse the discussion board on myCourses for all questions related to the course. Only personal emails related to medical exceptions for missing a deliverable will be answered.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nMaterial Covered\n\n\n\n\n1\nProbability spaces, algebra of events, axioms of probability\n\n\n2\nRandom variables and random vectors\n\n\n3\nRandom variables and random vectors (continued)\n\n\n4\nConditional probability and conditional expectation\n\n\n5\nMoment generating functions and sums of random variables\n\n\n6\nProbability inequalities\n\n\n7\nReview and Mid-Term\n\n\n8\nConvergence in probability and the weak law of large numbers\n\n\n9\nAlmost sure convergence and the strong law of large numbers\n\n\n10\nMaximum likelihood estimation and minimum mean squared error estimation\n\n\n11\nStochastic processes, Bernoulli process, Poisson process, and Gaussian process\n\n\n12\nMarkov chains\n\n\n13\nWide sense stationary processes\n\n\n\nThe material for the lecture notes is taken from various sources including the textbook and the reference book, as well as the lecture notes of Prof. Ioannis Psaromiglikos (McGill) and Prof. Ashutosh Nayyar (USC).\n\n\n\n\nTextbook\n\n\nGrimmett and Stirzaker, Probability and Random Processes, 4th edition, Oxford University Press, 2020.\n\n\n“Engineering” Graduate Probability textbooks\n\n\nJ.A. Gubner, Probability and Random Processes for Electrical and Computer Engineers, Cambridge University Press, 2006.\nS.H. Chan, Introduction to Probability for Data Science, Michigan Publishing, 2021.\nH. Hsu, Probability, Random Variables, and Random Processes, McGraw Hill, 1997.\n\n\nExercise books\n\n\nF. Mosteller, Fifty challenging problems in probability with solutions, Courier Corporation, 1987. Available online\nGrimmett and Stirzaker, One Thousand Exercises in Probability, Oxford University Press, 2000.\n\n\n\n\n\n\n\nAssignments (25%) Weekly homework assignments. Typically, each assignment will consist of four questions, out of which one or two randomly selected questions will be grader. The lowest two homework assignments will be dropped.\nMid Term (25%) Closed book in-class exam. Oct 9 (during class time)\nFinal Exam (50%) Closed book, in-person exam. Will be scheduled by the exam office and the dates will be announced later.\nThe final exam will cover all the material seen in the class during the term.\n\n\n\n\n\nAssignments must be submitted electronically on myCourses as a PDF. You may write the assignments on paper and then scan them as a PDF (there are several such apps available for all phone platforms), or write on a tablet and convert to PDF, or type using a word processor.\nThere will no make-up examination for students who miss a mid-term.\n\nStudent who miss the exam due to a valid reason (see Faculty of Engineering policy) should notify the instructor within a week of the exam and provide necessary documentation.\nIf, and only if, proper documentation for a missed exam is presented, the marks for the missed exam will be shifted to the final exam.\nStudents who miss the mid-term exam for any other reason (e.g., no medical note, going to the exam at the wrong time, or on the wrong day, etc.) will get zero marks on the exam.\n\nAny request for reevaluation of a mid-term or an assignment must be made in writing within a week of its return. Note that requesting a re-grade will mean that you WHOLE assignment or exam will be re-graded.\nDue to paucity of grading hours, only one or two randomly selected questions will be graded in each assignment.\nThe lowest two assignments and labs will be dropped. There will be no make-up for missed assignments and labs, even if it is for a valid reason. The whole point of dropping the lowest two assignments/labs is to reduce the administrative overhead of keeping track of such missed assignments/labs.\n\n\nRight to submit in English or French written work that is to be graded.\n\nIn accord with McGill University’s Charter of Students’ Rights, students in this course have the right to submit in English or in French any written work that is to be graded.\n\nAcademic Integrity\n\nMcGill University values academic integrity. Therefore all students must understand the meaning and consequences of cheating, plagiarism and other academic offences under the Code of Student Conduct and Disciplinary Procedures (see McGill’s guide to academic honesty for more information).\nL’université McGill attache une haute importance à l’honnêteté académique. Il incombe par conséquent à tous les étudiants de comprendre ce que l’on entend par tricherie, plagiat et autres infractions académiques, ainsi que les conséquences que peuvent avoir de telles actions, selon le Code de conduite de l’étudiant et des procédures disciplinaires (pour de plus amples renseignements, veuillez consulter le guide pour l’honnêteté académique de McGill.)\n\n\n\n\n\nThe course is taught in a “chalk and board” style; there will be no power point presentations. All students are expected to attend lectures and take notes. Partial notes on some of the material will be provided, but are not a substitute for the material covered in class.\n© Instructor-generated course materials (e.g., handouts, notes, summaries, exam questions) are protected by law and may not be copied or distributed in any form or in any medium without explicit permission of the instructor. Note that infringements of copyright can be subject to follow up by the University under the Code of Student Conduct and Disciplinary Procedures.\n\n\n\n\nAs the instructor of this course I endeavor to provide an inclusive learning environment. However, if you experience barriers to learning in this course, do not hesitate to discuss them with me or contact the office of Student Accessibility and Achievement.\nEnd-of-course evaluations are one of the ways that McGill works towards maintaining and improving the quality of courses and the student’s learning experience. You will be notified by e-mail when the evaluations are available. Please note that a minimum number of responses must be received for results to be available to students."
  },
  {
    "objectID": "index.html#general-information",
    "href": "index.html#general-information",
    "title": "Course Outline",
    "section": "",
    "text": "Instructor\n\n\nAditya Mahajan\nOffice Hours: TBD\n\n\nTeaching Assistants\n\n\nAlexander Fernandes\n\n\nLectures\n\n\n2:35pm–3:55pm Monday, Wednesday (ENGTR 2100)\n\n\nTutorials\n\n\n12:35am–1:25am Friday, (ENGTR 2100)\n\n\nPrerequisites\n\n\nECSE 205 (Probability and Random Signals I)\nECSE 206 or ECSE 316 (Signals and Systems)\n\n\nCommunication\n\nUse the discussion board on myCourses for all questions related to the course. Only personal emails related to medical exceptions for missing a deliverable will be answered."
  },
  {
    "objectID": "index.html#course-content",
    "href": "index.html#course-content",
    "title": "Course Outline",
    "section": "",
    "text": "Week\nMaterial Covered\n\n\n\n\n1\nProbability spaces, algebra of events, axioms of probability\n\n\n2\nRandom variables and random vectors\n\n\n3\nRandom variables and random vectors (continued)\n\n\n4\nConditional probability and conditional expectation\n\n\n5\nMoment generating functions and sums of random variables\n\n\n6\nProbability inequalities\n\n\n7\nReview and Mid-Term\n\n\n8\nConvergence in probability and the weak law of large numbers\n\n\n9\nAlmost sure convergence and the strong law of large numbers\n\n\n10\nMaximum likelihood estimation and minimum mean squared error estimation\n\n\n11\nStochastic processes, Bernoulli process, Poisson process, and Gaussian process\n\n\n12\nMarkov chains\n\n\n13\nWide sense stationary processes\n\n\n\nThe material for the lecture notes is taken from various sources including the textbook and the reference book, as well as the lecture notes of Prof. Ioannis Psaromiglikos (McGill) and Prof. Ashutosh Nayyar (USC)."
  },
  {
    "objectID": "index.html#course-material",
    "href": "index.html#course-material",
    "title": "Course Outline",
    "section": "",
    "text": "Textbook\n\n\nGrimmett and Stirzaker, Probability and Random Processes, 4th edition, Oxford University Press, 2020.\n\n\n“Engineering” Graduate Probability textbooks\n\n\nJ.A. Gubner, Probability and Random Processes for Electrical and Computer Engineers, Cambridge University Press, 2006.\nS.H. Chan, Introduction to Probability for Data Science, Michigan Publishing, 2021.\nH. Hsu, Probability, Random Variables, and Random Processes, McGraw Hill, 1997.\n\n\nExercise books\n\n\nF. Mosteller, Fifty challenging problems in probability with solutions, Courier Corporation, 1987. Available online\nGrimmett and Stirzaker, One Thousand Exercises in Probability, Oxford University Press, 2000."
  },
  {
    "objectID": "index.html#evaluation",
    "href": "index.html#evaluation",
    "title": "Course Outline",
    "section": "",
    "text": "Assignments (25%) Weekly homework assignments. Typically, each assignment will consist of four questions, out of which one or two randomly selected questions will be grader. The lowest two homework assignments will be dropped.\nMid Term (25%) Closed book in-class exam. Oct 9 (during class time)\nFinal Exam (50%) Closed book, in-person exam. Will be scheduled by the exam office and the dates will be announced later.\nThe final exam will cover all the material seen in the class during the term."
  },
  {
    "objectID": "index.html#marking-policy",
    "href": "index.html#marking-policy",
    "title": "Course Outline",
    "section": "",
    "text": "Assignments must be submitted electronically on myCourses as a PDF. You may write the assignments on paper and then scan them as a PDF (there are several such apps available for all phone platforms), or write on a tablet and convert to PDF, or type using a word processor.\nThere will no make-up examination for students who miss a mid-term.\n\nStudent who miss the exam due to a valid reason (see Faculty of Engineering policy) should notify the instructor within a week of the exam and provide necessary documentation.\nIf, and only if, proper documentation for a missed exam is presented, the marks for the missed exam will be shifted to the final exam.\nStudents who miss the mid-term exam for any other reason (e.g., no medical note, going to the exam at the wrong time, or on the wrong day, etc.) will get zero marks on the exam.\n\nAny request for reevaluation of a mid-term or an assignment must be made in writing within a week of its return. Note that requesting a re-grade will mean that you WHOLE assignment or exam will be re-graded.\nDue to paucity of grading hours, only one or two randomly selected questions will be graded in each assignment.\nThe lowest two assignments and labs will be dropped. There will be no make-up for missed assignments and labs, even if it is for a valid reason. The whole point of dropping the lowest two assignments/labs is to reduce the administrative overhead of keeping track of such missed assignments/labs.\n\n\nRight to submit in English or French written work that is to be graded.\n\nIn accord with McGill University’s Charter of Students’ Rights, students in this course have the right to submit in English or in French any written work that is to be graded.\n\nAcademic Integrity\n\nMcGill University values academic integrity. Therefore all students must understand the meaning and consequences of cheating, plagiarism and other academic offences under the Code of Student Conduct and Disciplinary Procedures (see McGill’s guide to academic honesty for more information).\nL’université McGill attache une haute importance à l’honnêteté académique. Il incombe par conséquent à tous les étudiants de comprendre ce que l’on entend par tricherie, plagiat et autres infractions académiques, ainsi que les conséquences que peuvent avoir de telles actions, selon le Code de conduite de l’étudiant et des procédures disciplinaires (pour de plus amples renseignements, veuillez consulter le guide pour l’honnêteté académique de McGill.)"
  },
  {
    "objectID": "index.html#course-delivery",
    "href": "index.html#course-delivery",
    "title": "Course Outline",
    "section": "",
    "text": "The course is taught in a “chalk and board” style; there will be no power point presentations. All students are expected to attend lectures and take notes. Partial notes on some of the material will be provided, but are not a substitute for the material covered in class.\n© Instructor-generated course materials (e.g., handouts, notes, summaries, exam questions) are protected by law and may not be copied or distributed in any form or in any medium without explicit permission of the instructor. Note that infringements of copyright can be subject to follow up by the University under the Code of Student Conduct and Disciplinary Procedures."
  },
  {
    "objectID": "index.html#additional-notes",
    "href": "index.html#additional-notes",
    "title": "Course Outline",
    "section": "",
    "text": "As the instructor of this course I endeavor to provide an inclusive learning environment. However, if you experience barriers to learning in this course, do not hesitate to discuss them with me or contact the office of Student Accessibility and Achievement.\nEnd-of-course evaluations are one of the ways that McGill works towards maintaining and improving the quality of courses and the student’s learning experience. You will be notified by e-mail when the evaluations are available. Please note that a minimum number of responses must be received for results to be available to students."
  },
  {
    "objectID": "conditional-expectation.html",
    "href": "conditional-expectation.html",
    "title": "Conditional probability and conditional expectation",
    "section": "",
    "text": "Conditional probability is perhaps the most important aspect of probability theory as it explains how to incorporate new information in a probability model. However, formally defining conditional probability is a bit intricate. In the notes, I will first provide an intuitive high-level explanation of conditional probabability. We will then do a deeper dive, trying to develop a bit more intuition about what is actually going on."
  },
  {
    "objectID": "conditional-expectation.html#conditioning-on-events",
    "href": "conditional-expectation.html#conditioning-on-events",
    "title": "Conditional probability and conditional expectation",
    "section": "1 Conditioning on events",
    "text": "1 Conditioning on events\n\nRecall that conditional probability for events is defined as follows: given a probability space \\((Ω, \\ALPHABET F, \\PR)\\) and events \\(A, B \\in \\ALPHABET F\\) such that \\(\\PR(B) &gt; 0\\), we have \\[\n\\PR(A \\mid B) = \\frac{\\PR(A \\cap B)}{\\PR(B)}.\n\\]\nBuilding on this definition, we can define the conditional CDF of a random variable \\(X\\) conditioned on an event \\(C\\) (such that \\(\\PR(C) &gt; 0\\)) as follows: \\[\nF_{X|C}(x \\mid C) = \\PR(X \\le x \\mid C) = \\frac{\\PR( \\{ X \\le x \\} \\cap C)}{\\PR(C)}.\n\\]\nAs we pointed out, conditional probabilities are probabilities, the conditional CDF defined above satisfies the properties of regular CDFs. In particular\n\n\\(0 \\le F_{X|C}(x\\mid C) \\le 1\\)\n\\(\\displaystyle \\lim_{x \\to -∞} F_{X|C}(x \\mid C) = 0\\)\n\\(\\displaystyle \\lim_{x \\to +∞} F_{X|C}(x \\mid C) = 1\\)\n\\(F_{X|C}(x \\mid C)\\) is non-decreasing function.\n\\(F_{X|C}(x \\mid C)\\) is right-continuous function.\n\nSince \\(F_{X|C}\\) is CDF, we can classify random variables conditioned on an event as discrete or continuous in the usual way. In particular\n\nIf \\(F_{X|C}\\) is piecewise constant, then \\(X\\) conditioned on \\(C\\) is a discrete random variable which takes values in a finite or countable subset \\(\\text{range}(X\\mid C) = \\{x_1, x_2, \\dots\\}\\) of \\(\\reals\\). Furthermore, \\(X\\) conditioned on \\(C\\) has a conditional PMF \\(p_{X|C} \\colon \\reals \\to [0,1]\\) defined as \\[\n  p_{X|C}(x\\mid C) = F_{X|C}(x\\mid C) - F_{X|C}(x^{-} \\mid C).\n\\]\nIf \\(F_{X|C}\\) is continuous, then \\(X\\) conditioned on \\(C\\) is a continuous random variable which has a conditional PDF \\(f_{X|C}\\) given by \\[\nf_{X|C}(x\\mid C) = \\frac{d}{dx} F_X(x \\mid C).\n\\]\nIf \\(F_{X|C}\\) is neither piecewise constant nor continuous, then \\(X\\) conditioned on \\(C\\) is a mixed random variable.\n\nTherefore, a random variable conditioned on an event behaves exactly like a regular random variable. We can define conditional expectation \\(\\EXP[X \\mid C]\\), conditional variance \\(\\VAR(X \\mid C)\\) in the obvious manner.\nAn immediate implication of the law of total probability is the following.\nIf \\(C_1, C_2, \\dots, C_n\\) is a partition of \\(Ω\\), then \\[\n  F_X(x) = \\sum_{i=1}^n F_{X|C_i}(x \\mid C_i) \\PR(C_i).\n\\] Furthermore, if \\(X\\) and \\(X\\) conditioned on \\(C\\) are both discrete, we have \\[\np_X(x) = \\sum_{i=1}^n p_{X|C_i}(x \\mid C_i) \\PR(C_i)\n\\] and if \\(X\\) and \\(X\\) conditioned on \\(C\\) are both continuous, we have \\[\n  f_X(x) = \\sum_{i=1}^n f_{X|C_i}(x \\mid C_i) \\PR(C_i).\n\\]\n\n\nExercise 1 Consider the following experiment. A fair coin is tossed. If the outcome is heads, \\(X\\) is a uniform \\([0,1]\\) random variable. If the outcome is tails, \\(X\\) is \\(\\text{Bernoulli}(p)\\) random variable. Find \\(F_X(x)\\).\n\n\nExample 1 (Memoryless property of geometric random variable) Let \\(X \\sim \\text{geometric}(p)\\) and \\(m,n\\) be positive integers. Compute \\[ \\PR(X &gt; n + m \\mid X &gt; m). \\]\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRecall that the PMF of a geometric random variable is \\[\nP_X(k) = p (1-p)^{k-1}, \\quad k \\in \\naturalnumbers.\n\\] Therefore, \\[\n\\PR(X &gt; m) = \\sum_{k = m + 1}^∞ P_X(k)\n= \\sum_{k=m+1}^{∞} p (1-p)^{k-1} = (1-p)^m.\n\\]\nNow consider \\[\\begin{align*}\n\\PR(X &gt; m + n \\mid X &gt; m) &=\n\\frac{ \\PR(\\{ X &gt; m + n \\} \\cap \\{X &gt; m \\}) } {\\PR(X &gt; m) }\n\\\\\n&=\n\\frac{ \\PR(X &gt; m + n ) } {\\PR(X &gt; m) } \\\\\n&= \\frac{(1-p)^{m+n}}{(1-p)^m} = (1-p)^n = \\PR(X &gt; n).\n\\end{align*}\\]\nThis is called the memoryless property of a geometric random variable.\n\n\n\n\nExample 2 (Memoryless property of exponential random variable) Let \\(X \\sim \\text{Exponential}(λ)\\) and \\(t,s\\) be positive reals. Compute \\[ \\PR(X &gt; t + s \\mid X &gt; t). \\]\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRecall that the PDF of an exponential random variable is \\[\nf_X(x) = λ e^{-λ x}, \\quad x \\ge 0.\n\\] Therefore, \\[\n\\PR(X &gt; t) = \\int_{t}^{∞} f_X(x)\\, dx = e^{-λ t}.\n\\]\nNow consider \\[\\begin{align*}\n\\PR(X &gt; t + s \\mid X &gt; t) &=\n\\frac{ \\PR(\\{ X &gt; t + s \\} \\cap \\{X &gt; t \\}) } {\\PR(X &gt; t) }\n\\\\\n&=\n\\frac{ \\PR(X &gt; t + s ) } {\\PR(X &gt; t) } \\\\\n&= \\frac{e^{-λ(t+s)}}{e^{-λt}} = e^{-λs} = \\PR(X &gt; s).\n\\end{align*}\\]\nThis is called the memoryless property of a exponential random variable."
  },
  {
    "objectID": "conditional-expectation.html#conditioning-on-random-variables",
    "href": "conditional-expectation.html#conditioning-on-random-variables",
    "title": "Conditional probability and conditional expectation",
    "section": "2 Conditioning on random variables",
    "text": "2 Conditioning on random variables\nWe first start with the case where we are conditioning on discrete random variables.\n\nIf \\(X\\) and \\(Y\\) are random variables defined on a common probability space and \\(Y\\) is discrete, then \\[F_{X|Y}(x \\mid y) = \\PR(X \\le x \\mid Y = y)\\] for any \\(y\\) such that \\(\\PR(Y = y) &gt; 0\\).\nIf \\(X\\) is also discrete, the conditional PMF \\(p_{X| Y}\\) is defined as \\[p_{X|Y}(x|y) = \\PR(X = x \\mid Y = y) = \\frac{p_{X,Y}(x,y)}{P_Y(y)}\\] for any \\(y\\) such that \\(\\PR(Y = y) &gt; 0\\).\nMoreover, we have that \\[ p_{X|Y}(x\\mid y) = F_{X|Y}(x\\mid y) - F_{X|Y}(x^{-}\\mid y). \\]\nThe above expression can be written differently to give the chain rule for random variables: \\[\n   P_{X,Y}(x,y) = P_{Y}(y) P_{X|Y}(x|y).\n\\]\nFor any event \\(B\\) in \\(\\mathscr B(\\reals)\\), the law of total probability may be written as \\[\\PR(X \\in B) = \\sum_{x \\in \\text{range}(X)} \\PR(X \\in B \\mid X = x) P_X(x). \\]\nIf \\(X\\) is independent of \\(Y\\), we have \\[\n   p_{X|Y}(x\\mid y) = p_X(x), \\quad \\forall x,y \\in \\reals.\n\\]\n\nWe now consider the case when we are conditioning on a continuous random variable.\n\nIf \\(Y\\) is continuous, \\(\\PR(Y = y) = 0\\) for all \\(y\\). We may think of \\[ F_{X|Y}(x\\mid y) = \\lim_{δ \\downarrow 0} \\PR(X \\le x \\mid y \\le Y \\le y + δ).\\]\nWhen \\(X\\) and \\(Y\\) are jointly continuous, we define the conditional PDF \\[ f_{X|Y}(x \\mid y) = \\frac{f_{X,Y}(x,y)}{f_Y(y)}. \\]\nNote that the conditional PDF cannot be interpreted in the same manner as the conditional PMF because it gives the impression that we are conditioning on a zero-probability event. However, we can view it as a limit as follows:\n\\[\\begin{align*}\n   F_{X|Y}(x\\mid y) &= \\lim_{δ \\downarrow 0} \\PR(X \\le x \\mid y \\le Y \\le y + δ) \\\\\n   &= \\lim_{δ \\downarrow 0} \\dfrac{\\PR(X \\le x, y \\le Y \\le y + δ)}{\\PR(y \\le Y \\le y + δ)} \\\\\n   &= \\lim_{δ \\downarrow 0} \\dfrac{\\int_{-∞}^x \\int_{y}^{y + δ} f_{X,Y}(u,v)\\, dv\\, du }{ \\int_{y}^{y+δ} f_Y(v)\\, dv }\n\\end{align*}\\] If \\(δ\\) is small, we can approximate \\[\n\\int_{y}^{y + δ} f_Y(v)\\, dv \\approx f_Y(y) \\cdot δ\n\\] and \\[\n\\int_{y}^{y + δ} f_{X,Y}(u,v) dv \\approx f_{X,Y}(u,y) \\cdot δ.\n\\] Substituting in the above equation, we get \\[\\begin{align*}\n   F_{X|Y}(x \\mid y) &\\approx \\lim_{δ \\downarrow 0}\n   \\dfrac{ \\int_{-∞}^x f_{X,Y}(u,y) δ du }{ f_Y(y) δ }\n   \\\\\n   &= \\int_{-∞}^x \\left[ \\frac{f_{X,Y}(u,y)}{f_Y(y)} \\right] du\n\\end{align*}\\]. Thus, when \\(X\\) and \\(Y\\) are jointly continuous, we have \\[\nf_{X|Y}(x\\mid y) = \\frac{d}{dx} F_{X|Y}(x \\mid y) =\n  \\dfrac{f_{X,Y}(x,y)}{f_Y(y)}.\n\\]\nThe formal definition of conditional densities requires some ideas from advanced probability theory, which we will not cover in this course. Nonetheless, I will try to explain the intuition behind the formal definitions in the next section.\nThe above expression may be written differently to give the chain rule for random variables: \\[ f_{X,Y}(x,y) = f_Y(y) f_{X|Y}(x \\mid y). \\]\nFor any event \\(B \\in \\mathscr B(\\reals)\\), the law of total probability may be written as \\[\n\\PR(X \\in B) = \\int_{-∞}^∞ \\PR(X \\in B \\mid Y = y) f_Y(y)\\, dy\n\\] An immediate implication of this is \\[\nF_X(x) = \\PR(X \\le x) = \\int_{-∞}^{∞} \\PR(X \\le x \\mid Y = y) f_Y(y)\\, dy\n= \\int_{-∞}^{∞} F_{X|Y}(x|y) f_Y(y)\\, dy.\n\\]\nIf \\(X\\) is independent of \\(Y\\), we have \\[\nf_{X|Y}(x\\mid y) = f_X(x), \\quad \\forall x, y \\in \\reals.\n\\]\nWe can show that conditional PMF and conditional PDF satisfy all the properties of PMFs and PDFs. Therefore, we can define conditional expectation \\(\\EXP[ g(X) \\mid Y = y ]\\) in terms of \\(p_{X|Y}\\) or \\(f_{X|Y}\\). We can similarly define conditional variance\n\n\nExample 3 Suppose \\(X\\) and \\(Y\\) are jointly continuous random variables with the joint PDF \\[\nf_{X,Y}(x,y) = \\frac{e^{-x/y} e^{-y}}{y}, \\quad 0 &lt; x &lt; ∞, 0 &lt; y &lt; ∞.\n\\] Find \\(f_{X|Y}\\)?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe first compute the marginal \\(f_Y(y)\\).\n\\[\\begin{align*}\nf_Y(y) &= \\int_{-∞}^{∞} f_{X,Y}(x,y) \\, dx \\\\\n&= \\int_{0}^{∞} \\frac{e^{-x/y} e^{-y}}{y} dx \\\\\n&= \\frac{e^{-y}}{y} \\int_{0}^∞ e^{-x/y} dx \\\\\n&= e^{-y}.\n\\end{align*}\\] Thus, \\[ f_{X|Y}(x \\mid y) = \\frac{f_{X,Y}(x,y)}{f_Y(y)}\n= \\frac{e^{-x/y}}{y}, \\quad 0 &lt; x &lt; ∞, 0 &lt; y &lt; ∞.\n\\]\n\n\n\n\nExample 4 Suppose \\(X \\sim \\text{Uniform}[0,1]\\) and given \\(X = x\\), \\(Y\\) is uniformly distributed on \\((0,x)\\). Find the PDF of \\(Y\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe will use the law of total probability. \\[\nF_Y(y) = \\int_{-∞}^{∞} F_{Y|X}(y \\mid x) f_X(x) \\, dx\n= \\int_{0}^1 F_{Y|X}(y \\mid x) \\, dx\n\\] where we have used the fact that \\(f_X(x) = 1\\) for \\(x \\in [0,1]\\). Now, we know that given \\(X = x\\), \\(Y \\sim \\text{uniform}[0,x]\\). Therefore, \\[\nf_{Y|X}(y\\mid x) = \\frac 1x, \\quad 0 &lt; y &lt; x.\n\\] Therefore, \\[\nF_{Y|X}(y \\mid x) = \\begin{cases}\n0 & y &lt; 0 \\\\\n\\dfrac{y}{x} & 0 &lt; y &lt; x \\\\\n1 & y \\ge x\n\\end{cases}\n\\]\nWe will compute \\(F_Y(y)\\) for the three cases separately.\n\nFor \\(y &lt; 0\\), \\[ F_Y(y) = \\int_{0}^1 F_{Y|X}(y|x) dx = 0.\\]\nFor \\(0 &lt; y &lt; 1\\), \\[ F_Y(y) = \\int_{0}^y 1\\, dx + \\int_{y}^1 \\frac{y}{x} \\, dx\n= y - y \\ln y. \\]\nFor \\(y &gt; 1\\), \\[ F_Y(y) = \\int_{0}^1 1 \\, dx = 1. \\]\n\nThus, \\[\nF_Y(y) = \\begin{cases}\n0 & y &lt; 0 \\\\\ny - y \\ln y & 0 \\le y &lt; 1 \\\\\n1 & y &gt; 1.\n\\end{cases}\n\\]\nHence, \\[\nf_Y(y) = \\frac{d F_{Y}(y)}{dy} = - \\ln y, \\quad 0 &lt; y &lt; 1.\n\\]"
  },
  {
    "objectID": "conditional-expectation.html#conditional-expectation",
    "href": "conditional-expectation.html#conditional-expectation",
    "title": "Conditional probability and conditional expectation",
    "section": "3 Conditional expectation",
    "text": "3 Conditional expectation\nDefine \\(ψ(y) = \\EXP[ X \\mid Y = y]\\). In particular, if \\(X\\) and \\(Y\\) are discrete, then \\[\nψ(y) = \\sum_{x \\in \\text{range}(X)} x p_{X|Y}(x|y)\n\\] and, if \\(X\\) and \\(Y\\) are continuous, then \\[\nψ(y) = \\int_{-∞}^{∞} x f_{X|Y}(x|y)\\, dx\n\\] Let \\(Z = ψ(Y)\\). Then \\(Z\\) is a random variable! This is a subtle point, and we will spend some time to develop an intuition of what this means.\n\n3.1 Conditioning on a \\(σ\\)-algebra\nThe key idea is conditioning on a \\(σ\\)-algebra. To avoid technical subtleties, we restrict to the discrete case.\n\nConsider a probability space \\((Ω, \\ALPHABET F, \\PR)\\) where \\(\\ALPHABET F\\) is a finite \\(σ\\)-algebra. Let \\(\\ALPHABET G\\) be a sub-\\(σ\\)-algebra of \\(\\ALPHABET F\\). In particular, we assume that there is a partition \\(\\{D_1, D_2, \\dots, D_m\\}\\) of \\(Ω\\) such that \\(\\ALPHABET G = 2^{\\{D_1, \\dots, D_m\\}}\\). The elements \\(D_1, \\dots, D_m\\) are called the atoms of the \\(σ\\)-algebra \\(\\ALPHABET G\\).\n\nTODO: Add example. 4x4 grid. partition for \\(\\ALPHABET G\\).\n\nWe define \\(\\PR(A \\mid \\ALPHABET G)\\) (which we will write as \\(\\EXP[\\IND_{A} \\mid \\ALPHABET G]\\) as \\[\n\\EXP[\\IND_{A} \\mid \\ALPHABET G](ω)\n= \\sum_{i=1}^m \\EXP[ \\IND_{A} \\mid D_i ] \\IND_{D_i}(ω).\n\\] Thus, on each \\(ω \\in D_i\\), the value of \\(\\EXP[I_{A} \\mid \\ALPHABET G]\\) is equal to \\(\\EXP[I_{A} \\mid D_i]\\).\nThis idea can be extended to any random variable instead of \\(\\IND_{A}\\), that is, for any random variable \\(X\\) \\[\n\\EXP[X \\mid \\ALPHABET G](ω)\n= \\sum_{i=1}^m \\EXP[ X \\mid D_i ] \\IND_{D_i}(ω).\n\\] Thus, on each \\(ω \\in D_i\\), the value of \\(\\EXP[X \\mid \\ALPHABET G]\\) is equal to \\(\\EXP[X \\mid D_i]\\).\nWhen \\(\\ALPHABET G = \\{\\emptyset, Ω\\}\\) is the trivial \\(σ\\)-algebra, \\[\\EXP[X \\mid \\{\\emptyset, Ω\\}] = \\EXP[X].\\]\nWhen \\(X = \\IND_{A}\\), \\(\\EXP[ \\IND_{A} \\mid \\ALPHABET G] = \\PR(A \\mid \\ALPHABET G)\\).\nIf \\(X_1\\) and \\(X_2\\) are joint random variables and \\(a_1\\) and \\(a_2\\) are constants, then \\[ \\EXP[ a_1 X_1 + a_2 X_2 \\mid \\ALPHABET G]\n= a_1 \\EXP[X_1 \\mid \\ALPHABET G] + a_2 \\EXP[X_2 \\mid \\ALPHABET G]. \\]\nIf \\(Y\\) is another random variable which is \\(\\ALPHABET G\\) measurable (i.e., \\(Y\\) takes constant values on the atoms of \\(\\ALPHABET G\\)), then \\[\n\\EXP[X Y \\mid \\ALPHABET G] = Y \\EXP[X \\mid \\ALPHABET G].\n\\]\n[The result can be proved pictorially.]\n\n\n\n3.2 Smoothing property of conditional expectation\nLet \\(\\ALPHABET H ⊂ \\ALPHABET G ⊂ \\ALPHABET F\\), where \\(⊂\\) means sub-\\(σ\\)-algebra. Let \\(\\{E_1, \\dots, E_k\\}\\) denote the partition corresponding to \\(\\ALPHABET H\\) and \\(\\{D_1, \\dots, D_m\\}\\) denote the partition corresponding to \\(\\ALPHABET G\\). The fact that \\(\\ALPHABET H\\) is a sub-\\(σ\\)-algebra of \\(\\ALPHABET G\\) means that each atom \\(E_i\\) of \\(\\ALPHABET H\\) is a union of atoms of \\(\\ALPHABET G\\) (i.e., \\(\\{D_1, \\dots, D_m\\}\\) is a refinement of the partition \\(\\{E_1, \\dots, E_k\\}\\)). Therefore, \\[\\begin{equation}\\tag{smoothing-property}\n\\bbox[5pt,border: 1px solid]\n{\\EXP[ \\EXP[ X \\mid \\ALPHABET G ] \\mid \\ALPHABET H ] =\n\\EXP[ X \\mid \\ALPHABET H].}\n\\end{equation}\\] This is known as the smoothing property of conditional expectation.\nA special case of the above property is that \\[\n\\EXP[ \\EXP[ X \\mid \\ALPHABET G] ] =\n\\EXP[ X ].\n\\] where we have taken \\(\\ALPHABET H = \\{\\emptyset, Ω\\}\\) as the trivial \\(σ\\)-algebra. Observe that the above definition is equivalent to the law of total probability!\n\n\n3.3 Conditioning on random variable\n\nNow suppose \\(Y\\) is a discrete random variable, then \\(\\PR(A \\mid Y)\\) and \\(\\EXP[X \\mid Y]\\) may be viewed as a short-hand notation for \\(\\PR(A \\mid σ(Y))\\) and \\(\\EXP[X \\mid σ(Y)]\\). Similar interpretations hold for conditioning on multiple random variables (or, equivalently, conditioning on random vectors).\nThe smoothing property of conditional expectation can then be stated as \\[\n\\EXP[ \\EXP[ X | Y_1, Y_2 ] Y_1 ] = \\EXP[ X | Y_1 ].\n\\]\nAn implication of the smoothing property is the following: for any (measurable) function \\(g \\colon \\reals \\to \\reals\\), \\[ \\EXP[ g(Y) \\EXP[ X \\mid Y] ] = \\EXP[ X g(Y) ]. \\]\n\n\n\nThis previous property is used for generalizing the definition of conditional expectation to continuous random variables. First, we consider conditioning wrt \\(σ\\)-algebra \\(\\ALPHABET G \\subset \\ALPHABET F\\), which is not necessarily finite (or countable).\nThen, for any non-negative1 random variable \\(X\\), \\(\\EXP[X \\mid \\ALPHABET G]\\) is defined as a \\(\\ALPHABET G\\)-measurable random variable that satisfies \\[ \\EXP[ \\IND_{A} \\EXP[ X \\mid \\ALPHABET G] ] = \\EXP[ X \\IND_{A} ] \\] for every \\(A \\in \\ALPHABET G\\).\n\n1 We start with non-negative random variables just to avoid the concerns with existence of expectation due to \\(∞ - ∞\\) nature. A similar definition works in general as long as we can rule out \\(∞ - ∞\\) case.\nIt can be shown that \\(\\EXP[X \\mid \\ALPHABET G]\\) exists and is unique up to sets of measure zero. Formally, one takes about a “version” of conditional expectation.\nThen \\(\\EXP[X \\mid Y]\\) for \\(Y\\) continuous may be viewed as \\(\\EXP[X \\mid σ(Y)]\\).\nThe formal definition of conditional expectation implies that if we take any Borel subsets \\(B_X\\) of \\(\\reals\\), then \\(\\PR(X \\in B_X \\mid Y)\\) is a (measurable) function \\(m(y)\\) that satisfies \\[\\begin{equation}\\label{eq:defn-cond}\n\\PR(X \\in B_X, Y \\in B_Y) = \\int_{B_Y} m(y) f_Y(y) dy\n\\end{equation}\\] for all Borel subsets \\(B_Y\\) of \\(\\reals\\).\nWe will show that \\[ m(y) = \\int_{B_X} \\frac{ f_{X,Y}(x,y) }{ f_{Y}(y) } \\, dx \\] satisfies \\(\\eqref{eq:defn-cond}\\). In particular, the RHS of \\(\\eqref{eq:defn-cond}\\) is \\[\n\\int_{B_Y} \\left[ \\int_{B_X} \\frac{ f_{X,Y}(x,y) }{ f_{Y}(y) } \\, dx \\right] f_Y(y) \\, dy\n= \\int_{B_Y} \\int_{B_X} f_{X,Y}(x,y) \\, dx \\, dy\n= \\PR(X \\in B_X, Y \\in B_X)\n\\] which equals the LHS of \\(\\eqref{eq:defn-cond}\\). This is why the conditional density is defined the way it is defined!\nFinally, it can be shown that \\(\\PR(A \\mid Y) \\coloneqq \\EXP[\\IND_{A} \\mid σ(Y)]\\), \\(A \\in \\ALPHABET F\\), satisfies the axioms of probability.Therefore, conditional probability satisfies all the properties of probability (and consequently, conditional expectations satisfy all the properties of expectations).\nNote that the definition of conditional expectation generalizes Bayes rule. In particular, for any (measurable) function \\(g \\colon \\reals \\to \\reals\\) we have \\[\\begin{align*}\n\\EXP[ g(X) \\mid Y = y ] &= \\int_{-∞}^∞ g(x) f_{X|Y}(x\\mid y) \\, dx\n\\\\\n&= \\int_{-∞}^∞ g(x) \\frac{f_{X,Y}(x,y)}{f_Y(y)} \\, dx \\\\\n&= \\frac{ \\displaystyle \\int_{-∞}^{∞} g(x) f_{X,Y}(x,y)\\, dx}\n   { f_Y(y)} \\\\\n&= \\frac{ \\displaystyle \\int_{-∞}^{∞} g(x) f_{X,Y}(x,y)\\, dx}\n   {\\displaystyle \\int_{-∞}^{∞} f_{X,Y}(x,y)\\, dx } \\\\\n&= \\frac{ \\displaystyle \\int_{-∞}^{∞} g(x) f_{Y|X}(y|x) f_X(x) \\, dx}\n   {\\displaystyle \\int_{-∞}^{∞} f_{Y|X}(y|x) f_X(x) \\, dx }. \\\\\n  \\end{align*}\\]\n\n\nExercise 2 Let \\(X\\) and \\(Y\\) be independent and identically distributed \\(\\text{Bernoulli}(p)\\) random variables.\n\nConsider the events \\(A_k = \\{ ω : X(ω) + Y(ω) = k\\}\\), \\(k \\in \\{0,1,2\\}\\). Find \\(\\PR(A_k \\mid X)\\).\nCompute \\(\\EXP[X + Y \\mid X]\\)."
  },
  {
    "objectID": "probability-spaces.html",
    "href": "probability-spaces.html",
    "title": "Introduction to Probability",
    "section": "",
    "text": "This is a graduate course on probability and random signals. I assume that everyone is familiar with the basics of undergraduate probability. For example, you should be able to answer the following questions:\n\nA fair 6-sided die is rolled twice. What is the probability that the sum of the rolls equals 7?\nA biased coin with \\(\\PR({\\rm heads}) = 3/4\\) is tossed 10 times. What is the probability of obtaining 3 consecutive heads?\n\nYou should also be familiar with the following concepts:\n\nRandom variables, probability distributions, and expectations\nConditional distributions and independent random variables\n\nSome of you might have also seen the following concepts\n\nLaw of large numbers\nCentral limit theorem\n\nIn this course, we will revisit these topics with a more formal approach. We start with a review of the basic concepts."
  },
  {
    "objectID": "probability-spaces.html#background",
    "href": "probability-spaces.html#background",
    "title": "Introduction to Probability",
    "section": "",
    "text": "This is a graduate course on probability and random signals. I assume that everyone is familiar with the basics of undergraduate probability. For example, you should be able to answer the following questions:\n\nA fair 6-sided die is rolled twice. What is the probability that the sum of the rolls equals 7?\nA biased coin with \\(\\PR({\\rm heads}) = 3/4\\) is tossed 10 times. What is the probability of obtaining 3 consecutive heads?\n\nYou should also be familiar with the following concepts:\n\nRandom variables, probability distributions, and expectations\nConditional distributions and independent random variables\n\nSome of you might have also seen the following concepts\n\nLaw of large numbers\nCentral limit theorem\n\nIn this course, we will revisit these topics with a more formal approach. We start with a review of the basic concepts."
  },
  {
    "objectID": "probability-spaces.html#review-of-set-theory",
    "href": "probability-spaces.html#review-of-set-theory",
    "title": "Introduction to Probability",
    "section": "2 Review of Set Theory",
    "text": "2 Review of Set Theory\n\n2.1 Basic set operations\nA set is a collection of objects. We say that a set \\(B\\) is a subset of set \\(A\\) (written as \\(B \\subseteq A\\)) if all elements of \\(B\\) are also elements of \\(A\\). We say that \\(B\\) is a proper subset (written \\(B \\subsetneq A\\)) if \\(B \\subseteq A\\) and \\(B \\neq A\\).\n\nExercise 1 Let \\(A = \\{1, 2, 3\\}\\). Find all subsets of \\(A\\).\n\nThe set of all subsets of \\(A\\) is also called the power set of \\(A\\) (denoted by \\(2^A\\)). The notation \\(2^A\\) represents that the power set of \\(A\\) contains \\(2^{|A|}\\) elements. For example, your answer to Exercise 1 must have \\(2^3 = 8\\) elements.\nGiven two sets \\(A\\) and \\(B\\), we define the set difference \\(A\\setminus B\\) to be all elements of \\(A\\) not in \\(B\\). Note that mathematically \\(A \\setminus B\\) is well defined even if \\(B \\not\\subseteq A\\). In particular \\[\nA \\setminus B = A \\setminus (A \\cap B).\n\\]\n\nExercise 2 Compute \\(A \\setminus B\\) for the following:\n\n\\(A = \\{1,2,3,4\\}\\) and \\(B = \\{1, 2\\}\\).\n\\(A = \\{1,2,3,4\\}\\) and \\(B = \\{1, 2, 5\\}\\).\n\n\nGiven a collection \\(\\{A_1, A_2, \\dots, A_n\\}\\) of sets, we define two operations:\n\nUnion \\(A_1 \\cup A_2  \\cup \\cdots \\cup A_n\\) as follows \\[\n  \\bigcup_{i=1}^n A_i = \\{ a: a \\in A_i \\text{ for some } i \\}.\n\\] This means that an element belongs to \\(A_1 \\cup A_2  \\cup \\cdots \\cup A_n\\) if it belongs to at least one of \\(A_1\\), \\(A_2\\), \\(\\ldots\\), \\(A_n\\).\nIntersection \\(A_1 \\cap A_2  \\cap \\cdots \\cap A_n\\) as follows \\[\n  \\bigcap_{i=1}^n A_i = \\{ a: a \\in A_i \\text{ for all } i \\}\n\\] This means that an element belongs to \\(A_1 \\cap A_2  \\cap \\cdots \\cap A_n\\) if it belongs to all of \\(A_1\\), \\(A_2\\), \\(\\ldots\\), \\(A_n\\).\n\nA collection \\(\\{A_1, A_2, \\dots, A_n\\}\\) is disjoint if for every \\(i \\neq j\\), \\(A_i \\cap A_j = \\emptyset\\), where \\(\\emptyset\\) denotes the empty set.\nGiven a universal set \\(Ω\\) and a collection \\(\\{B_1, B_2, \\dots, B_m\\}\\) of subsets of \\(Ω\\), we say that \\(\\{B_1, B_2, \\dots, B_m\\}\\) is a partition of \\(Ω\\) if \\(\\{B_1, B_2, \\dots, B_m\\}\\) are disjoint and their union equals \\(Ω\\).\n\n\n\n\n\n\n\n\nFigure 1: Example of a partition\n\n\n\n\nExample 1 Let \\(Ω = \\{1,2,3,4\\}\\). The following are partitions of \\(Ω\\):\n\n\\(\\{ \\{1\\}, \\{2\\}, \\{3\\}, \\{4\\} \\}\\).\n\\(\\{ \\{1, 2\\}, \\{3, 4\\} \\}\\).\n\\(\\{ \\{1\\}, \\{2, 3\\}, \\{4\\} \\}\\).\n\nThe follow are not partitions of \\(Ω\\) [Explain why?]\n\n\\(\\{ \\{1\\}, \\{2\\}, \\{3\\}, \\}\\).\n\\(\\{ \\{1, 2, 3\\}, \\{3, 4\\} \\}\\).\n\\(\\{ \\{1\\}, \\{2, 3\\}, \\{4, 5\\} \\}\\).\n\n\nIn most of our discussion, we will work with a pre-specified universal set \\(Ω\\). In this setting we use \\(A^c\\) (read as the complement of \\(A\\)) as a short hand for \\(Ω\\setminus A\\).\n\n\n\n\n\n\nPartitions are useful because they allow breaking up a set into disjoint pieces. In particular, suppose \\(\\{B_1, \\dots, B_m\\}\\) is a partition and \\(A\\) is any subset of \\(Ω\\).\nThen, \\[\nA = (A \\cap B_1) \\cup (A \\cap B_2) \\cup \\cdots \\cup (A \\cap B_m)\n\\] where each of the components is disjoint.\n\n\n\n\n\n2.2 Properties of set operations\n\nCommutative \\[A \\cup B = B \\cup A\n\\quad\\text{and}\\quad\nA \\cap B = B \\cap A\\]\nAssociative \\[A \\cup (B \\cup C)= (A \\cup B) \\cup C\n\\quad\\text{and}\\quad\nA \\cap (B \\cap C)= (A \\cap B) \\cap C\\]\nDistributive \\[A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cap C)\n\\quad\\text{and}\\quad\nA \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\]\nDe Morgan’s Law \\[(A \\cup B)^c = A^c \\cap B^\\cap\n\\quad\\text{and}\\quad\n(A \\cap B)^c = A^c \\cup B^c\\]\n\n\nExercise 3 Use distributive property to simplify:\n\n\\([1,4] \\cap ([0,2] \\cup [3,5])\\).\n\\([2,4] \\cup ([3,5] \\cap [1,4])\\).\n\n\n\n\n2.3 An algebra (or field) on sets\nGiven a universal set \\(Ω\\), a collection \\(\\ALPHABET F = \\{F_1, F_2, \\dots, F_m\\}\\) of subsets of \\(Ω\\) is called an algebra if it satisfies the following properties:\n\n\\(\\emptyset \\in \\ALPHABET F\\) and \\(Ω \\in \\ALPHABET F\\).\nClosed under complements: if \\(A \\in \\ALPHABET F\\) then \\(A^c \\in \\ALPHABET F\\).\nClosed under finite unions and finite intersections: if \\(A_1, \\dots, A_n \\in \\ALPHABET F\\), then \\[\nA_1 \\cup A_2 \\cup \\cdots \\cup A_n \\in \\ALPHABET F\n\\quad\\text{and}\\quad\nA_1 \\cap A_2 \\cap \\cdots \\cap A_n \\in \\ALPHABET F\n\\]\n\nWe will sometimes use the notation “\\((Ω,\\ALPHABET F)\\) is an algebra of sets” or “\\(\\ALPHABET F\\) is an algebra on \\(Ω\\)”. Some examples of algebras are as follows:\n\nThe smallest algebra associated with \\(Ω\\) is \\(\\{\\emptyset, Ω\\}\\).\nIf \\(A\\) is any subset of \\(Ω\\), then \\(\\{\\emptyset, A, A^c, Ω\\}\\) is an algebra.\nFor any set \\(Ω\\), the power-set \\(2^Ω\\) is an algebra on \\(Ω\\). As an illustration, check that the power set defined in Exercise 1 is an algebra.\n\nThese are all examples of a general principle: The power-set of any partition of a set is an algebra.\n\nIf the partition is \\(\\{Ω\\}\\), then the power-set \\(\\{ \\emptyset, Ω \\}\\) is an algebra.\nIf the partition is \\(\\{A, A^c\\}\\), then the power-set \\(\\{ \\emptyset, A, A^c, Ω\\}\\) is an algebra.\nIf the partition is the collection of all singleton elements of a set, then the power-set \\(2^Ω\\) is an algebra."
  },
  {
    "objectID": "probability-spaces.html#probability-space",
    "href": "probability-spaces.html#probability-space",
    "title": "Introduction to Probability",
    "section": "3 Probability Space",
    "text": "3 Probability Space\nProbability is a measure of uncertainty or our belief that a particular statement is true. In this course, we will not concern ourselves with how such a measure of uncertainty is constructed; rather focus on the mathematical properties that it should satisfy and the implications of these properties.\nMany everyday statements take the form: “The chance (or probability) of \\(A\\) is \\(p\\)”, where \\(A\\) is some event (such as “sun shining tomorrow”, “Team A winning a hockey game”, etc.) and \\(p\\) is a number (e.g., \\(1/8\\)) or an adjective describing quantity (e.g., “low”).\nTo mathematically model such statements, we need to model the sequence of events that may lead to the occurrence of \\(A\\): this is called a random experiment; the result of an experiment is called an outcome.\nIn general, the outcome of an experiment is not certain. We can only talk about the collection of possible outcomes. The collection of possible outcomes of an experiment is called the sample space and denoted by \\(Ω\\).\n\nExercise 4 What is the sample space for the toss of a coin?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(Ω = \\{ H, T \\}\\).\n\n\n\n\nExercise 5 What is the sample space for the roll of a (6-sided) die?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(Ω = \\{ 1,2,3,4,5,6 \\}\\).\n\n\n\nAn event is any subset of the sample space. If the outcome of the random experiment belongs to the event \\(A\\), we say that “the event \\(A\\) has occurred”. Some examples of events are:\n\nHead occurs in Exercise 4 (\\(A = \\{H\\}\\))\nBoth head and tail occur in Exercise 4 (\\(A = \\emptyset\\); this is an event that cannot happen, sometimes called the impossible event)\nAn even number is thrown in Exercise 5 (\\(A = \\{2,4,6\\}\\)).\n\nNote that events are subset of the sample space but not all subsets of a sample space may be events. The reasons are too complicated to explain, but the high-level explanation is that everything is okay for discrete sample spaces, but weird things can happen in continuous sample spaces.\nProbability (denoted by \\(\\PR\\)) is a function which assigns a number between \\(0\\) and \\(1\\) to every event. This number indicates what is the chance that the event occurs. Such a function should satisfy some axioms, which we will explain below.\nFirst, to define a function, we need to define it’s domain and range. Let’s denote the domain (i.e., the set of all events to which we can assign a probability) by \\(\\ALPHABET F\\). We expect probability to satisfy certain properties, which imposes constraints on the domain:\n\nProbability of an impossible event (e.g., getting both heads and tails when we toss a coin) should be zero. Thus, \\(\\emptyset \\in \\ALPHABET F\\).\nProbability of something happening (e.g., getting either a head or a tail when we toss a coin) should be one. Thus, \\(Ω \\in \\ALPHABET F\\).\nIf we assign probability to an event \\(A\\) then we should be able to assign probability to “\\(A\\) does not occur” i.e., \\(A^c\\). Thus, if \\(A \\in \\ALPHABET F\\) then \\(A^c \\in \\ALPHABET F\\).\nIf we can talk about probability of \\(A\\) and \\(B\\), then we should be able to talk about probability that either \\(A\\) or \\(B\\) occurs and both \\(A\\) and \\(B\\) occur. Thus, if \\(A, B \\in \\ALPHABET F\\), then \\(A \\cup B \\in \\ALPHABET F\\) and \\(A \\cap B \\in \\ALPHABET F\\).\n\nThus, the domain of \\(\\PR\\) must be an algebra! However, when we go beyond finite sample spaces, being an algebra is not sufficient. But we first provide some examples of probability for finite sample spaces.\n\nExample 2 Consider a six-sided die where \\(Ω = \\{1, 2, \\dots, 6 \\}\\), \\(\\ALPHABET F = 2^Ω\\) and \\(\\PR\\) is given by \\[\n\\PR(A) = \\sum_{ω \\in A} q(ω),\n\\quad \\forall A \\in \\ALPHABET F\n\\] where \\[\nq(1) = q(2) = q(3) = q(4) = q(5) = \\frac 2{15}\n\\quad\\text{and}\\quad\nq(6) = \\frac{1}{3}.\n\\]\nVerify that\n\n\\(\\PR(Ω) = 1\\)\n\\(\\PR(\\{3,4,5\\}) = \\frac{6}{15}\\).\n\\(\\PR(\\{1,3,4,5\\}) = \\frac{8}{15}\\).\n\n\nWe now come back to the fact that restricting the domain of \\(\\PR\\) to be an algebra is not sufficient as is illustrated by the following example.\n\nExample 3 A coin is tossed repeatedly until a head turns up. The sample space is \\(Ω = \\{ω_1, ω_2, \\dots\\}\\) where \\(ω_n\\) denotes the event that the first \\(n-1\\) tosses are tails followed by a head.\n\nSuppose we are interested in finding the probability of the event that the coin is tossed an even number of times, i.e., \\(A = \\{ω_2, ω_4, \\dots\\}\\). Note that \\(ω_2, ω_4, \\dots \\in \\ALPHABET F\\). However, \\(A\\) is a set. If we want to assign probability to \\(A\\) in terms of probability of \\(ω_n\\), we require \\(\\ALPHABET F\\) to be closed under countable unions. This motivates the following definition.\n\n\n\n\n\n\n\\(σ\\)-algebra\n\n\n\nGiven a universal set \\(Ω\\), a collection \\(\\ALPHABET F = \\{F_1, F_2, \\dots\\}\\) of subsets of \\(Ω\\) is called a \\(\\boldsymbol{σ}\\)-algebra if it satisfies the following properties:\n\n\\(\\emptyset \\in \\ALPHABET F\\) and \\(Ω \\in \\ALPHABET F\\).\nClosed under complements: if \\(A \\in \\ALPHABET F\\) then \\(A^c \\in \\ALPHABET F\\).\nClosed under countable unions: if \\(A_1, A_2, \\dots \\in \\ALPHABET F\\), then \\[\n\\bigcup_{n=1}^∞ A_n \\in \\ALPHABET F\n\\]\n\n\n\n\n\n\n\n\n\nThe distinction between algebras and \\(σ\\)-algebras is technical. The reason that we need to consider \\(σ\\)-algebras is to do with the definition of probability on continuous sample spaces. Take \\(Ω = [0,1]\\) and consider a random experiment where “any outcome is equally likely”. Intuitively we capture this feature by assuming that for any interval \\([a,b]\\) with \\(0 \\le a \\le b \\le 1\\), we have \\[\\begin{equation}\\label{eq:uniform}\n\\PR([a,b]) = b - a.\n\\end{equation}\\]\nWe have seen that if we want \\(\\PR\\) to be a meaningful measure, the domain \\(\\ALPHABET F\\) must at least be an algebra. We have also seen that the power-set \\(2^Ω\\) is always an algebra. So, it is tempting to take \\(\\ALPHABET F = 2^{[0,1]}\\). However, it turns out that \\(2^{[0,1]}\\) has includes some weird sets (technically, non-measurable sets) due to which we cannot define a function \\(\\PR\\) on \\(2^{[0,1]}\\) that satisfies \\(\\eqref{eq:uniform}\\).\nTo workaround this technical limitation, we revisit the minimum requirements that we need from the domain of \\(\\PR\\). Since we are interested in \\(\\PR([a,b])\\), \\(\\ALPHABET F\\) must contain intervals (and therefore all finite unions and intersections of intervals). Since we are working with continuous sample spaces, we also want \\(\\PR\\) to be continuous, i.e., for any sequence of sets \\(\\{A_n\\}_{n \\ge 1}\\), we want \\(\\PR(\\lim_{n \\to ∞} A_n) = \\lim_{n \\to ∞} \\PR(A_n)\\). It turns out that the additional requirement of continuity implies that \\(\\ALPHABET F\\) must be closed under countable unions as well. Thus, the domain \\(\\ALPHABET F\\) must at least be a \\(σ\\)-algebra.\nSo, we restrict to the simplest choice of the domain \\(\\ALPHABET F\\) needed for \\(\\eqref{eq:uniform}\\) and continuity to hold. For technical reasons, we need another property known as completeness. See Sec. 1.6 of the textbook.\n\n\n\n\n\n\n\n\n\n\\(σ\\)-algebra generated by a collection and Borel \\(σ\\)-algebra\n\n\n\nGiven collection \\(\\ALPHABET S\\) of subsets of \\(Ω\\), we have the following:\n\nThe power-set \\(2^Ω\\) contains \\(\\ALPHABET S\\). Therefore, there is at least one \\(σ\\)-algebra containing \\(\\ALPHABET S\\).\nIf \\(\\ALPHABET F_1\\) and \\(\\ALPHABET F_2\\) are \\(σ\\)-algebras containing \\(\\ALPHABET S\\), then \\(\\ALPHABET F_1 \\cap \\ALPHABET F_2\\) also contains \\(\\ALPHABET S\\).\n\nThus, if we take the intersection of all \\(σ\\)-algebras containing \\(\\ALPHABET S\\), we get the smallest \\(σ\\)-algebra containing \\(\\ALPHABET S\\), which is sometimes denoted by \\(σ(\\ALPHABET S)\\).\nOne commonly used \\(σ\\)-algebra is the Borel \\(σ\\)-algebra, which is defined as follows.1 Let \\(Ω\\) be a subset of \\(\\reals\\) and \\(\\ALPHABET S\\) be the collection of all open intervals in \\(Ω\\). Then \\(σ(\\ALPHABET S)\\) is called the “Borel \\(σ\\)-algebra on Ω” and often denoted by \\(\\mathscr{B}(Ω)\\).\n\n\n1 Borel \\(σ\\)-algebra is usually defined for any topological space. We restrict our definition to subsets of reals.\nDefinition 1 (Probability space) A probability space is a tuple \\((Ω, \\ALPHABET F, \\PR)\\) comprising of a set \\(Ω\\), a \\(σ\\)-algebra \\(\\ALPHABET F\\) on \\(Ω\\), and a function \\(\\PR \\colon \\ALPHABET F \\to [0,1]\\) that satisfies the following axioms of proability\n\nNon-negativity. \\(\\PR(A) \\ge 0\\).\nNormalization. \\(\\PR(Ω) = 1\\).\nCountable additivity. If \\(A_1, A_2, \\dots Ω\\) is a collection of disjoint events in \\(\\ALPHABET F\\), then, \\[\n\\PR\\biggl( \\bigcup_{n=1}^∞ A_n \\biggr) =\n\\sum_{n=1}^∞ \\PR(A_n).\n\\]\n\n\nSome immediate implications of the axioms of probability are the following.\n\nLemma 1 (Properties of probability measures)  \n\nProbability of complement. \\(\\PR(A^c) = 1 - \\PR(A)\\).\nMonotonicity. If \\(A \\subset B\\), then \\(\\PR(B) = \\PR(A) + \\PR(B \\setminus A) \\ge \\PR(A)\\).\nInclusion-exclusion. Given two events \\(A\\) and \\(B\\), \\[\n\\PR(A \\cup B) = \\PR(A) + \\PR(B) - \\PR(A \\cap B).\n\\]\nContinuity. Let \\(A_1, A_2, \\dots\\) be (weakly) increasing sequence of events, i.e., \\(A_1 \\subseteq A_2 \\subseteq A_3 \\subseteq \\cdots\\). Define \\[\n  A = \\lim_{n \\to ∞} A_n = \\bigcup_{n=1}^∞ A_n.\n\\] Then, \\[\n  \\PR(A) = \\lim_{n \\to ∞} \\PR(A_n).\n\\]\nSimilarly, let \\(B_1, B_2, \\dots\\) be (weakly) decreasing sequence of events, i.e., \\(B_1 \\supseteq B_2 \\supseteq B_3 \\supseteq \\cdots\\). Define \\[\n   B = \\lim_{n \\to ∞} B_n = \\bigcup_{n=1}^∞ B_n.\n\\] Then, \\[\n   \\PR(B) = \\lim_{n \\to ∞} \\PR(B_n).\n\\]\nUnion bound. For any sequence of events \\(\\{A_n\\}_{n \\ge 1}\\), we have \\[\n\\PR\\biggl( \\bigcup_{n=1}^{∞} A_n \\biggr) \\le\n\\sum_{n=1}^{∞} \\PR(A_n).\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe proof of parts (a)–(c) is elementary and left as an exercise. Part (d) is more technical and is essentially equivalent to countable additivity. See the textbook for a proof. Union bound is an immediate consequence of inclusion-exclusion and continuity.\n\n\n\n\nExample 4 Let \\(Ω = [0,1]\\), \\(\\ALPHABET F = \\mathscr B[0,1]\\), and \\(\\PR\\) be any probability measure on \\((Ω, \\ALPHABET F)\\). Take any \\(a \\in (0,1)\\).\n\nConsider \\(A_n = \\bigl[0, a - \\frac 1n \\bigr)\\). Then \\(A = \\lim_{n \\to ∞} A_n =  [0, a)\\).\nConsider \\(A_n = \\bigl[0, a - \\frac 1n \\bigr]\\). Then \\(A = \\lim_{n \\to ∞} A_n =  [0, a)\\).\nConsider \\(B_n = \\bigl[0, 1 + \\frac 1n \\bigr)\\). Then \\(B = \\lim_{n \\to ∞} B_n = [0,a]\\).\nConsider \\(B_n = \\bigl[0, 1 + \\frac 1n \\bigr]\\). Then \\(B = \\lim_{n \\to ∞} B_n = [0,a]\\).\n\nIn these examples, continuity implies that \\(\\PR(A) = \\lim_{n \\to ∞} \\PR(A_n)\\) and \\(\\PR(B) = \\lim_{n \\to ∞} \\PR(B_n)\\).\n\n\n\n\n\n\n\nSome terminology\n\n\n\n\nAn event \\(A\\) is called null if \\(\\PR(A) = 0\\). Null event should not be confused with impossible event \\(\\emptyset\\).\nWe say that \\(A\\) occurs almost surely (abbreviated to a.s.) if \\(\\PR(A) = 1\\).\n\n\n\n\nExample 5 Consider \\(Ω = [0,1]\\), \\(\\ALPHABET F = \\mathscr B([0,1])\\), and \\(\\PR\\) to be the uniform probability distribution on \\(Ω\\). Consider the event \\(A\\) that the outcome is a rational number. \\(A\\) is a countable set (because the set of rational numbers is countable). For any \\(x \\in A\\), \\(\\{x\\} \\in \\ALPHABET F\\), and \\(\\PR(\\{x\\}) = 0\\) (we can infer this from Example 4 by thinking of \\(\\{x\\}\\) as the limit of intervals \\(\\bigl[x, x+ \\frac 1n\\bigr]\\)). Thus, by countable additivity, \\(\\PR(A) = 0\\). Hence, \\(A\\) is null.\nThe above analysis implies that \\(\\PR(A^c) = 1\\), thus the event that the outcome is irrational occurs almost surely."
  },
  {
    "objectID": "probability-spaces.html#conditional-probability",
    "href": "probability-spaces.html#conditional-probability",
    "title": "Introduction to Probability",
    "section": "4 Conditional Probability",
    "text": "4 Conditional Probability\nConditional probabilities quantify the uncertainty of an event when it is known that another event has occurred\n\nDefinition 2 Let \\((Ω,\\ALPHABET F, \\PR)\\) be a probability space and \\(A, B \\in \\ALPHABET F\\) such that \\(\\PR(B) &gt; 0\\). Then, the conditional probability that \\(A\\) occurs given that \\(B\\) occurs is defined as \\[\n\\PR(A | B) = \\dfrac{ \\PR(A \\cap B) }{ \\PR(B) }.\n\\]\n\nThe notation \\(\\PR(A | B)\\) is read as “probability of \\(A\\) given \\(B\\)” or “probability of \\(A\\) conditioned on \\(B\\)”.\n\nExercise 6 Suppose we roll a fair six-sided die (a fair die means that all outcomes are equally likely). Consider the events \\(A\\) that the outcomes is prime and \\(B\\) that the outcome is a multiple of \\(3\\). Compute \\(\\PR(A | B)\\) and \\(\\PR(B | A)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe have \\(Ω = \\{1, 2, 3, 4, 5, 6\\}\\), \\(A = \\{2, 3, 5\\}\\), and \\(B = \\{3, 6\\}\\). Note that \\(\\PR(A) = \\frac 12\\) and \\(\\PR(B) = \\frac 13\\).\nThus, \\[ \\PR(A | B) = \\frac{ \\PR(A \\cap B) }{ \\PR(B) }\n= \\frac{ \\PR(\\{3\\}) }{ \\PR(\\{3,6\\}) }\n= \\frac{ \\ABS{\\{3\\}} }{ \\ABS{\\{3,6\\}} } = \\frac {1}{2}.\n\\] Similarly, \\[ \\PR(B | A) = \\frac{ \\PR(B \\cap A) }{ \\PR(A) }\n= \\frac{ \\PR(\\{3\\}) }{ \\PR(\\{2,3,5\\}) }\n= \\frac{ \\ABS{\\{3\\}} }{ \\ABS{\\{2,3,5\\}} } = \\frac {1}{3}.\n\\]\n\n\n\n\nExercise 7 Suppose we roll two fair six-sided dice. Consider the event \\(A\\) that the maximum of the two rolls is less than or equal to \\(8\\) and the event \\(B\\) that the minimum of the two rolls is greater than or equal to \\(6\\). Compute \\(\\PR(A|B)\\) and \\(\\PR(B|A)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNote that \\(Ω = \\{ 1, 2,3, 4, 5, 6\\}^2\\) and \\(\\PR\\) is uniform probability on all outcomes. The sets \\(A\\), \\(B\\), and \\(A \\cap B\\) are shown in Figure 2. Note that \\(\\PR(A) = \\PR(B) = \\frac{26}{36} = \\frac{13}{18}\\).\n\n\n\n\n\n\nFigure 2: The different events in Exercise 7\n\n\n\nThus, we have \\[\n\\PR(A|B) = \\frac{ \\PR(A \\cap B) } { \\PR(B) }\n= \\frac{ \\ABS{ A \\cap B} }{ \\ABS{B} }\n= \\frac{16}{26} = \\frac{8}{13}\n\\] and \\[\n\\PR(B|A) = \\frac{ \\PR(B \\cap A) } { \\PR(A) }\n= \\frac{ \\ABS{ B \\cap A} }{ \\ABS{A} }\n= \\frac{16}{26} = \\frac{8}{13}\n\\]\n\n\n\n\n\n\n\n\n\nConditional probabilities are probabilities\n\n\n\nConditional probabilities are legitimate probability measures on \\((Ω, \\ALPHABET F)\\). In particular, fix event \\(B\\) with \\(\\PR(B) &gt; 0\\). Then\n\n\\(\\PR(A \\mid B) \\ge 0\\).\n\\(\\PR(Ω \\mid B) = \\dfrac{\\PR(Ω \\cap B)}{\\PR(B)} = 1\\).\nFor disjoint events \\(A_1, A_2 \\in \\ALPHABET F\\), \\[\\PR(A_1 \\cup A_2 \\mid B) =\n\\frac{ \\PR( (A_1 \\cup A_2) \\cap B) }{ \\PR(B) } =\n\\frac{ \\PR( (A_1 \\cap B) \\cup (A_2 \\cap B) ) }{ \\PR(B) } =\n\\frac{ \\PR(A_1 \\cap B) + \\PR (A_2 \\cap B) }{ \\PR(B) } =\n\\PR(A_1 \\mid B) + \\PR(A_2 \\mid B)\\] where we have used the fact that \\((A_1 \\cap B)\\) and \\((A_2 \\cap B)\\) are disjoint.\n\n\n\n\nExercise 8 Given an event \\(B\\) with \\(\\PR(B) &gt; 0\\), show that\n\n\\(\\PR(A^c | B) = 1 - P(A|B)\\).\n\\(\\PR(A_1 \\cup A_2 | B) = \\PR(A_1 | B) + \\PR(A_2 | B) - \\PR(A_1 \\cap A_2 | B)\\).\nIf \\(A_1 \\subset A_2\\) then \\(\\PR(A_1 | B) \\le \\PR(A_2 | B)\\).\n\n\nThe definition of conditional probability gives rise to the chain rule.\n\nLemma 2 (Chain rule of probability) Let \\(A\\) and \\(B\\) be events in a probability space \\((Ω, \\ALPHABET F, \\PR)\\).\n\nIf \\(\\PR(B) &gt; 0\\), then \\(\\PR(A \\cap B) = \\PR(A | B) \\PR(B)\\).\nIf \\(\\PR(A) &gt; 0\\), then \\(\\PR(A \\cap B) = \\PR(B | A) \\PR(A)\\).\n\n\nCombining the chain rule with the basic properties of partitions, we get the law of total probability.\n\nLemma 3 (Law of total probability) Let \\(\\{B_1, B_2, \\dots, B_m\\}\\) be a partition of \\(Ω\\) such that \\(\\PR(B_i) &gt; 0\\) for all \\(i\\). Then, \\[\n\\PR(A) = \\sum_{i=1}^m \\PR(A \\cap B_i)\n= \\sum_{i=1}^m \\PR(A | B_i) \\PR(B_i).\n\\]\n\n\n\n\n\n\n\n\n\nFigure 3: Illustration of Law of total probability\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nConsider \\(m=2\\), in which case the result can be simplified as \\[\\PR(A) = \\PR(A|B)\\PR(B) + \\PR(A|B^c) \\PR(B^c).\\]\nTo prove this observe that \\[\\begin{equation}\\label{eq:two-step}\nA = A \\cap (B \\cup B^c) = (A \\cap B) \\cup (A \\cap B^c).\n\\end{equation}\\] The events \\(A \\cap B\\) and \\(A \\cap B^c\\) are disjoint. Therefore, by additivity, we have \\[\n\\PR(A) = \\PR(A \\cap B) + \\PR(A \\cap B^c).\n\\] Then, by the definition of conditional probability, we have \\(\\PR(A \\cap B) = \\PR(A|B) \\PR(B)\\) and \\(\\PR(A \\cap B^c) = \\PR(A|B^c) \\PR(B^c)\\). Substituting in the above, we get \\(\\eqref{eq:two-step}\\).\nThe argument for the general case is similar.\n\n\n\n\nExercise 9 There are two routes for a packet to be transmitted from a source to the destination.\n\nThe packet takes route \\(R_1\\) with probability \\(\\frac 34\\) and takes route \\(R_2\\) with probability \\(\\frac 14\\).\nOn route \\(R_1\\), the packet is dropped with probability \\(\\frac 13\\).\nOn route \\(R_2\\), the packet is dropped with probability \\(\\frac 14\\).\n\nFind the probability that the packet reaches the destination.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe start by defining some events: Let \\(R_1\\) denote the event that the packet took route \\(R_1\\) and \\(R_2\\) denote the event that the packet took route \\(R_2\\). Let \\(D\\) denote the event that the packet was dropped.\nThen, the information given in the question can be written as:\n\n\\(\\PR(R_1) = \\frac 34\\) and \\(\\PR(R_2) = \\frac 14\\).\n\\(\\PR(D | R_1) = \\frac 13\\). Thus, \\(\\PR(D^c | R_1) = 1 - \\PR(D | R_1) = \\frac 23\\).\n\\(\\PR(D | R_2) = \\frac 14\\). Thus, \\(\\PR(D^c | R_2) = 1 - \\PR(D | R_2) = \\frac 34\\).\n\nThen, by the law of total probability, we have \\[\\begin{align*}\n\\PR(D^c) &= \\PR(D^c | R_1) \\PR(R_1) + \\PR(D^c | R_2) \\PR(R_2) \\\\\n&= \\frac 34 \\frac 23 + \\frac 14 \\frac 34\n= \\frac {11}{16}.\n\\end{align*}\\]\n\n\n\n\nLemma 4 (Bayes rule) For any events \\(A, B \\in \\ALPHABET F\\) such that \\(\\PR(A), \\PR(B) &gt; 0\\), we have \\[\n\\PR(B|A) = \\dfrac{\\PR(A|B)\\PR(B)}{\\PR(A)}.\n\\]\nIn general, if \\(\\{B_1, B_2, \\dots, B_m\\}\\) is a partition of \\(Ω\\) such that \\(\\PR(B_i) &gt; 0\\) for all \\(i\\). Then, \\[\n\\PR(B_i|A) =\n\\dfrac{ \\PR(A|B_i) \\PR(B_i) }\n{\\displaystyle \\sum_{j=1}^m \\PR(A|B_j) \\PR(B_j)}\n\\] where we have used the law of total probability (Lemma 3) in the denominator.\n\n\nExercise 10 Consider the model of Exercise 9. Suppose we know that the packet was dropped. What is the probability that it was transmitted via route \\(R_1\\)?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRecall the events \\(R_1\\), \\(R_2\\), and \\(D\\) defined in the solution of Exercise 9. We were given that \\[\\PR(R_1) = \\frac 34, \\quad \\PR(R_2) = \\frac 14, \\quad\n\\PR(D|R_1) = \\frac 13, \\quad \\PR(D|R_2) = \\frac 14.\\] We had compute that \\[\n\\PR(D) = 1 - \\PR(D^c) = \\frac 5{16}.\n\\]\nThus, by Bayes rule, we have \\[\n\\PR(R_1 | D) = \\frac{ \\PR(D | R_1) \\PR(R_1) }{ \\PR(D) }\n= \\frac{ \\frac 13 \\frac 34 } { \\frac 5{16} } = \\frac 45.\n\\]"
  },
  {
    "objectID": "probability-spaces.html#independence",
    "href": "probability-spaces.html#independence",
    "title": "Introduction to Probability",
    "section": "5 Independence",
    "text": "5 Independence\nIn general, the knowledge that an event \\(B\\) has occurred changes the probability of event \\(A\\), since \\(\\PR(A)\\) is replaced by \\(\\PR(A|B)\\). If the knowledge that \\(B\\) has occurred does not does not change our belief about \\(A\\), i.e., when \\(\\PR(A|B) = \\PR(A)\\), we say “\\(A\\) and \\(B\\) are independent”. This leads to the following definition.\n\nDefinition 3 The events \\(A, B \\in \\ALPHABET F\\) are called independent if \\[\n\\PR(A|B) = \\PR(A)\n\\quad\\text{or}\\quad\n\\PR(B|A) = \\PR(B).\n\\] An alternative but equivalent definition is \\[\n\\PR(A \\cap B) = \\PR(A) \\PR(B).\n\\]\nWe will use the notation \\(A \\independent B\\) to denote that the events \\(A\\) and \\(B\\) are independent.\n\n\n\n\n\n\n\nIt is common for students to make the mistake and think that independence means \\(A \\cap B = \\emptyset\\). This is not true!\n\n\n\n\nExample 6 The events \\(A\\) and \\(B\\) defined in Exercise 6 are independent.\n\n\nExample 7 The events \\(A\\) and \\(B\\) defined in Exercise 7 are not independent.\n\n\nExercise 11 \\(A \\independent B\\) implies the following:\n\n\\(A \\independent B^c\\).\n\\(A^c \\independent B\\).\n\\(A^c \\independent B^c\\).\n\n\n\n\n\n\n\n\nIndependence of \\(σ\\)-algebras\n\n\n\nIn the discussion below, we assume that the probability space \\((Ω, \\ALPHABET F, \\PR)\\) is fixed.\n\nTwo sub-\\(σ\\)-algebras \\(\\ALPHABET F_1\\) and \\(\\ALPHABET F_2\\) of \\(\\ALPHABET F\\) are said to be independent if every event \\(A_1 \\in \\ALPHABET F_1\\) is independent of every event \\(A_2 \\in \\ALPHABET F_2\\).\nFor any event \\(A\\), let \\(σ(A)\\) denote the smallest \\(σ\\)-algebra containing \\(A\\), i.e., \\(σ(A) = \\{\\emptyset, A, A^c, Ω\\}\\).\nExercise 11 implies that independence of \\(A\\) and \\(B\\) implies the independence of \\(σ(A)\\) and \\(σ(B)\\). The reverse implication is trivially true. Thus, independence of events is equivalent to the independence of the smallest \\(σ\\)-algebra containing those events.\n\n\n\n\nDefinition 4 A family of events \\(\\{A_1, A_2, \\dots, A_n\\}\\) is called independent (sometimes mutually independent if for all non-empty subset of indices \\(\\{k_1, \\dots, k_m\\} \\subset \\{1,\\dots,n\\}\\), we have \\[\n\\PR\\bigl( A_{k_1} \\cap A_{k_2} \\cap \\cdots \\cap A_{k_m} \\bigr)\n= \\PR(A_{k_1}) \\PR(A_{k_2}) \\cdots \\PR(A_{k_m}).\n\\]\n\n\nExercise 12 Three bits are transmitted over a noisy channel. For each bit, the probability of correct reception is \\(λ\\). The error events for the three transmissions are mutually independent. Find the probability that two bits are received correctly.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFor \\(i \\in \\{1, 2, 3\\}\\), let\n\n\\(E_i\\) denote the event that bit \\(i\\) is received incorrectly\n\\(C_i\\) denote the event that bit \\(i\\) is received correctly\n\nMoreover let \\(S\\) denote the event that two bits are received correctly. Then, \\[\nS = (C_1 \\cap C_2 \\cap E_3) \\cup (C_1 \\cap E_2 \\cap C_3)\n\\cap (E_1 \\cap C_2 \\cap C_3).\n\\] Note that the three events in the right hand side are disjoint. Thus, \\[\\begin{align*}\n\\PR(S) &=\n\\PR(C_1 \\cap C_2 \\cap E_3) +  \\PR(C_1 \\cap E_2 \\cap C_3) +\n\\PR(E_1 \\cap C_2 \\cap C_3) \\\\\n&=\n\\PR(C_1)\\PR(C_2)\\PR(E_3) +  \\PR(C_1)\\PR(E_2)\\PR(C_3) +\n\\PR(E_1)\\PR(C_2)\\PR(C_3) \\\\\n&= 3 (1-λ) λ^2.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nPairwise independence vs independence\n\n\n\nA family of events \\(\\{A_1, A_2, \\dots, A_n\\}\\) is pairwise independent if for every \\(i,j \\in \\{1, \\dots, n\\}\\), \\(i \\neq j\\), we have \\[ \\PR(A_i \\cap A_j) = \\PR(A_i) \\PR(A_j). \\]\nPairwise independence is weaker than Independence. For instance, three events \\(A\\), \\(B\\), and \\(C\\) are pairwise independent if \\[\n\\PR(A \\cap B) = \\PR(A) \\PR(B),\n\\quad\n\\PR(B \\cap C) = \\PR(B) \\PR(C),\n\\quad\\text{and}\\quad\n\\PR(C \\cap A) = \\PR(C) \\PR(A).\n\\] For independence, in addition to the above, we also need \\[ \\PR(A \\cap B \\cap C) = \\PR(A)\\PR(B) \\PR(C). \\]\nThe following example illustrates shows that independence is stronger than pairwise independence. Consider an urn with \\(M\\) red balls and \\(M\\) blue balls. Two balls are drawn at random, one at a time, with replacement. Consider the following events:\n\n\\(A\\) is the event that the first ball is red.\n\\(B\\) is the event that the second ball is blue.\n\\(C\\) is the event that both balls are of the same color.\n\nObserve that\n\n\\(A \\cap B\\) is the event that the first is red and second is blue.\n\\(B \\cap C\\) is the event that both balls are blue.\n\\(C \\cap A\\) is the event that both balls are red.\n\\(A \\cap B \\cap C = \\emptyset\\)\n\nTherefore,\n\n\\(\\PR(A) = \\PR(B) = \\PR(C) = \\frac 14\\).\n\\(\\PR(A \\cap B) = \\PR(B \\cap C) = \\PR(C \\cap A) = \\frac 14\\).\n\\(\\PR(A \\cap B \\cap C) = \\emptyset\\).\n\nThus, \\(A\\), \\(B\\), \\(C\\) are pairwise independent but not independent."
  },
  {
    "objectID": "probability-spaces.html#product-spaces",
    "href": "probability-spaces.html#product-spaces",
    "title": "Introduction to Probability",
    "section": "6 Product spaces",
    "text": "6 Product spaces\nSo far, we have restricted attention to the outcome of one experiment. It is also possible to construct probability models which combine the outcome of two independent experiments, e.g., suppose we toss a coin and also roll a die. Let \\((Ω_1, \\ALPHABET F_1, \\PR_1)\\) and \\((Ω_2, \\ALPHABET F_2, \\PR_2)\\) be the probability spaces associated with the two experiments? What is the probability space \\((Ω, \\ALPHABET F, \\PR)\\) of the joint experiments?\nThe sample space should obviously be \\(Ω = Ω_1 \\times Ω_2\\). When \\(\\ALPHABET F_1\\) and \\(\\ALPHABET F_2\\) are finite, then we can simply define \\(\\ALPHABET F = \\ALPHABET F_1 \\times \\ALPHABET F_2\\) and for any \\(A = (A_1, A_2) \\in \\ALPHABET F\\), \\(\\PR(A)\\) to be \\(\\PR(A_1) \\PR(A_2)\\). You would have implicitly consutrcted such product spaces when dealing with joint experiments (like the coin toss and die roll example above) in your undergrad courses.\nHowever, things are a bit more complicated when \\(\\ALPHABET F_1\\) and \\(\\ALPHABET F_2\\) are not finite. The difficulty is that \\(\\ALPHABET F_1 \\times \\ALPHABET F_2\\) is not a \\(σ\\)-algebra. So, take \\(\\ALPHABET F\\) to be \\(σ(\\ALPHABET F_1 \\times \\ALPHABET F_2)\\) (which is the smallest \\(σ\\)-algebra comtaining \\(\\ALPHABET F_1 \\times \\ALPHABET F_2\\)) and define \\(\\PR\\) to be the extension of \\(\\PR_1 \\times \\PR_2\\) from \\(\\ALPHABET F_1 \\times \\ALPHABET F_2\\) to \\(σ(\\ALPHABET F_1 \\times \\ALPHABET F_2)\\) (one can show that such an extension exists). Such product space is often written as \\[\n(Ω, \\ALPHABET F, \\PR) = (Ω_1 \\times Ω_2, \\ALPHABET F_1 \\otimes \\ALPHABET F_2, \\PR_1 \\otimes \\PR_2). \\]\nWe will not worry too much about the technical details of such product spaces, but will use the above notation at times in the course."
  },
  {
    "objectID": "moment-generating-functions.html",
    "href": "moment-generating-functions.html",
    "title": "Moment Generating Functions",
    "section": "",
    "text": "The moment generating function (MGF) of a random variable \\(X\\) is defined as \\[\nM_X(s) = \\EXP[e^{sX}]\n\\] provided the expectation exists.\n\nWhen \\(X\\) is discrete, we have \\[ M_X(s) = \\sum_{x \\in \\text{range}(X)} e^{sx} p_X(x). \\]\nWhen \\(X\\) is continuous, we have \\[ M_X(s) = \\int_{-∞}^∞ e^{sx} f_X(x) \\, dx. \\]\n\n\n\n\n\n\n\nRelationship to Laplace transforms\n\n\n\nAlthough most texts (including the textbook) restrict \\(s\\) to be real, my personal view is that one should really interpret \\(s\\) as a complex number. If we do so, then we have the following:\n\n\\(M_X(-s)\\) is the Laplace transform of the PDF.\n\\(M_X(-j ω)\\) is the Fourier transform of the PDF, which is called the characteristic function of \\(X\\).\n\nTherefore, we can recover the PDF by taking the inverse Laplace transform of MGF. Thus, specifying the MGF of a random variable is equivalent to specifying the PDF.\nHistorically, MGF is defined for \\(s \\in \\reals\\) and there are distributions (e.g., Cauchy) for which MGF does not exist for any \\(s \\neq 0\\). In avoid such situations, one uses the characteristic function because the characteristic function always exists. However, if we view the domain of MGF to be \\(\\mathbb{C}\\), then there is no need for a distinction between MGF and characteristic function.\n\n\n\nExample 1 Suppose \\(X\\) is a random variable which takes values \\(\\{0, 1, 2\\}\\) with probabilities \\(\\{\\frac 12, \\frac 13, \\frac 16\\}\\). Then, \\[\\begin{align*}\nM_X(s) &= \\EXP[e^{sX}] \\\\\n&= \\frac 12 e^{s 0} + \\frac 13 e^{s 1} + \\frac 16 e^{s 2} \\\\\n&= \\frac 12 + \\frac 13 e^{s} + \\frac 16 e^{2s}.\n\\end{align*}\\]\n\n\nExample 2 Find the MGF of a Poisson random variable with parameter \\(λ\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\\begin{align*}\nM_X(s) &= \\EXP[e^{sX}] = \\sum_{k=0}^{∞}e^{ks} \\frac{λ^k e^{-λ}}{k!} \\\\\n&= e^{-λ} \\sum_{k=0}^{∞} \\frac{(λe^s)^k}{k!} \\\\\n&= e^{-λ} e^{λ e^{s}}.\n\\end{align*}\\]\n\n\n\n\nExample 3 Find the MGF of an exponential random variable with parameter \\(λ\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\\begin{align*}\nM_X(s) &= \\EXP[e^{sX}] \\\\\n&= \\int_{0}^∞ e^{sx} λ e^{-λx} \\, dx \\\\\n&= λ \\int_{0}^∞ e^{(s-λ)x} \\, dx \\\\\n&= \\frac{λ}{λ-s}.\n\\end{align*}\\]\nNote that we could have looked up this result from the Laplace transform tables which show that \\[\ne^{at} \\xleftrightarrow{\\hskip 0.5em \\mathcal{L}\\hskip 0.5em } \\frac{1}{s-a}\n\\]\n\n\n\nThe MGF of common random variables is shown in Table 1.\n\n\n\nTable 1: MGF of common random vables\n\n\n\n\n\n\n\n\n\n\nRandom variable\nParameter(s)\nMGF\n\n\n\n\nBernoulli\n\\(p\\)\n\\(1 - p + p e^s\\)\n\n\nBinomial\n\\((n,p)\\)\n\\((1-p + p e^s)^n\\)\n\n\nGeometric\n\\(p\\)\n\\(\\dfrac{p e^s}{1 - (1-p)e^s}\\)\n\n\nPoisson\n\\(λ\\)\n\\(\\exp(λ e^s - 1)\\)\n\n\nUniform\n\\((a,b)\\)\n\\(\\dfrac{e^{sb} - e^{sa}}{s(b-a)}\\)\n\n\nExponential\n\\(λ\\)\n\\(\\dfrac{λ}{λ-s}\\)\n\n\nGaussian\n\\((μ,σ)\\)\n\\(\\exp\\bigl(μ s + \\frac 12 σ^2 s^2 \\bigr)\\)\n\n\n\n\n\n\nIf there exist a neighborhood around origin where \\(M_X(s)\\) is well-defined. Then, we can use the MGF to “generate the moments” of \\(X\\) as follows:\n\n\\(M_X(0) = 1\\)\n\\(\\dfrac{d}{ds} M_X(s) \\biggr|_{s=0} = \\EXP[X]\\).\n\\(\\dfrac{d^2}{ds^2} M_X(s) \\biggr|_{s=0} = \\EXP[X^2]\\).\nand in general \\(\\dfrac{d^k}{ds^k} M_X(s) \\biggr|_{s=0} = \\EXP[X^k]\\).\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe first property follows from definition: \\[\nM_X(0) = \\EXP[e^{0 X}] = \\EXP[1] = 1.\n\\]\nFor the general derivative, we have \\[\\begin{align*}\n\\frac{d^k}{ds^k} M_X(s)\n&= \\int_{-∞}^∞ \\frac{d^k}{ds^k} e^{sx} f_X(x) \\, dx \\\\\n&= \\int_{-∞}^∞ x^k e^{sx} f_X(x) \\, dx.\n\\end{align*}\\]\nTherefore \\[\n\\frac{d^k}{ds^k} M_X(s) \\biggr|_{s=0} = \\int_{-∞}^∞ x^k f_X(x) \\, dx.\n\\]\n\n\n\n\nExample 4 Use the MGF of Bernoulli to find its first all the moments of \\(X\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFrom Table 1, we see that \\[ M_X(s) = 1 - p + p e^{s}. \\] Therefore,\n\n\\(\\dfrac{d}{ds} M_X(s) = p e^s\\).\n\\(\\dfrac{d^2}{ds^2} M_X(s) = p e^s\\).\nand in general \\(\\dfrac{d^k}{ds^k} M_X(s) = p e^s\\).\n\nThus,\n\n\\(\\EXP[X] = \\dfrac{d}{ds} M_X(s) \\biggr|_{s=0} = p\\).\n\\(\\EXP[X^2] = \\dfrac{d^2}{ds^2} M_X(s) \\biggr|_{s=0} = p\\).\nand in general \\(\\EXP[X^k] = \\dfrac{d^k}{ds^k} M_X(s) \\biggr|_{s=0} = p\\)."
  },
  {
    "objectID": "moment-generating-functions.html#moment-generating-functions",
    "href": "moment-generating-functions.html#moment-generating-functions",
    "title": "Moment Generating Functions",
    "section": "",
    "text": "The moment generating function (MGF) of a random variable \\(X\\) is defined as \\[\nM_X(s) = \\EXP[e^{sX}]\n\\] provided the expectation exists.\n\nWhen \\(X\\) is discrete, we have \\[ M_X(s) = \\sum_{x \\in \\text{range}(X)} e^{sx} p_X(x). \\]\nWhen \\(X\\) is continuous, we have \\[ M_X(s) = \\int_{-∞}^∞ e^{sx} f_X(x) \\, dx. \\]\n\n\n\n\n\n\n\nRelationship to Laplace transforms\n\n\n\nAlthough most texts (including the textbook) restrict \\(s\\) to be real, my personal view is that one should really interpret \\(s\\) as a complex number. If we do so, then we have the following:\n\n\\(M_X(-s)\\) is the Laplace transform of the PDF.\n\\(M_X(-j ω)\\) is the Fourier transform of the PDF, which is called the characteristic function of \\(X\\).\n\nTherefore, we can recover the PDF by taking the inverse Laplace transform of MGF. Thus, specifying the MGF of a random variable is equivalent to specifying the PDF.\nHistorically, MGF is defined for \\(s \\in \\reals\\) and there are distributions (e.g., Cauchy) for which MGF does not exist for any \\(s \\neq 0\\). In avoid such situations, one uses the characteristic function because the characteristic function always exists. However, if we view the domain of MGF to be \\(\\mathbb{C}\\), then there is no need for a distinction between MGF and characteristic function.\n\n\n\nExample 1 Suppose \\(X\\) is a random variable which takes values \\(\\{0, 1, 2\\}\\) with probabilities \\(\\{\\frac 12, \\frac 13, \\frac 16\\}\\). Then, \\[\\begin{align*}\nM_X(s) &= \\EXP[e^{sX}] \\\\\n&= \\frac 12 e^{s 0} + \\frac 13 e^{s 1} + \\frac 16 e^{s 2} \\\\\n&= \\frac 12 + \\frac 13 e^{s} + \\frac 16 e^{2s}.\n\\end{align*}\\]\n\n\nExample 2 Find the MGF of a Poisson random variable with parameter \\(λ\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\\begin{align*}\nM_X(s) &= \\EXP[e^{sX}] = \\sum_{k=0}^{∞}e^{ks} \\frac{λ^k e^{-λ}}{k!} \\\\\n&= e^{-λ} \\sum_{k=0}^{∞} \\frac{(λe^s)^k}{k!} \\\\\n&= e^{-λ} e^{λ e^{s}}.\n\\end{align*}\\]\n\n\n\n\nExample 3 Find the MGF of an exponential random variable with parameter \\(λ\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\\begin{align*}\nM_X(s) &= \\EXP[e^{sX}] \\\\\n&= \\int_{0}^∞ e^{sx} λ e^{-λx} \\, dx \\\\\n&= λ \\int_{0}^∞ e^{(s-λ)x} \\, dx \\\\\n&= \\frac{λ}{λ-s}.\n\\end{align*}\\]\nNote that we could have looked up this result from the Laplace transform tables which show that \\[\ne^{at} \\xleftrightarrow{\\hskip 0.5em \\mathcal{L}\\hskip 0.5em } \\frac{1}{s-a}\n\\]\n\n\n\nThe MGF of common random variables is shown in Table 1.\n\n\n\nTable 1: MGF of common random vables\n\n\n\n\n\n\n\n\n\n\nRandom variable\nParameter(s)\nMGF\n\n\n\n\nBernoulli\n\\(p\\)\n\\(1 - p + p e^s\\)\n\n\nBinomial\n\\((n,p)\\)\n\\((1-p + p e^s)^n\\)\n\n\nGeometric\n\\(p\\)\n\\(\\dfrac{p e^s}{1 - (1-p)e^s}\\)\n\n\nPoisson\n\\(λ\\)\n\\(\\exp(λ e^s - 1)\\)\n\n\nUniform\n\\((a,b)\\)\n\\(\\dfrac{e^{sb} - e^{sa}}{s(b-a)}\\)\n\n\nExponential\n\\(λ\\)\n\\(\\dfrac{λ}{λ-s}\\)\n\n\nGaussian\n\\((μ,σ)\\)\n\\(\\exp\\bigl(μ s + \\frac 12 σ^2 s^2 \\bigr)\\)\n\n\n\n\n\n\nIf there exist a neighborhood around origin where \\(M_X(s)\\) is well-defined. Then, we can use the MGF to “generate the moments” of \\(X\\) as follows:\n\n\\(M_X(0) = 1\\)\n\\(\\dfrac{d}{ds} M_X(s) \\biggr|_{s=0} = \\EXP[X]\\).\n\\(\\dfrac{d^2}{ds^2} M_X(s) \\biggr|_{s=0} = \\EXP[X^2]\\).\nand in general \\(\\dfrac{d^k}{ds^k} M_X(s) \\biggr|_{s=0} = \\EXP[X^k]\\).\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nThe first property follows from definition: \\[\nM_X(0) = \\EXP[e^{0 X}] = \\EXP[1] = 1.\n\\]\nFor the general derivative, we have \\[\\begin{align*}\n\\frac{d^k}{ds^k} M_X(s)\n&= \\int_{-∞}^∞ \\frac{d^k}{ds^k} e^{sx} f_X(x) \\, dx \\\\\n&= \\int_{-∞}^∞ x^k e^{sx} f_X(x) \\, dx.\n\\end{align*}\\]\nTherefore \\[\n\\frac{d^k}{ds^k} M_X(s) \\biggr|_{s=0} = \\int_{-∞}^∞ x^k f_X(x) \\, dx.\n\\]\n\n\n\n\nExample 4 Use the MGF of Bernoulli to find its first all the moments of \\(X\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFrom Table 1, we see that \\[ M_X(s) = 1 - p + p e^{s}. \\] Therefore,\n\n\\(\\dfrac{d}{ds} M_X(s) = p e^s\\).\n\\(\\dfrac{d^2}{ds^2} M_X(s) = p e^s\\).\nand in general \\(\\dfrac{d^k}{ds^k} M_X(s) = p e^s\\).\n\nThus,\n\n\\(\\EXP[X] = \\dfrac{d}{ds} M_X(s) \\biggr|_{s=0} = p\\).\n\\(\\EXP[X^2] = \\dfrac{d^2}{ds^2} M_X(s) \\biggr|_{s=0} = p\\).\nand in general \\(\\EXP[X^k] = \\dfrac{d^k}{ds^k} M_X(s) \\biggr|_{s=0} = p\\)."
  }
]