---
title: Random variables 
---

In many situations, we are not directly interested in the outcome of a random experiment, but a consequence of the outcome. Such consequences may be thought of as a function of the outcome. When they are real-valued, such functions of the outcome are called **random variables**.

:::{#exm-coin-toss}
Suppose a fair coin is tossed twice. Thus, $Ω = \{ HH, HT, TH, TT \}$, $\ALPHABET F = 2^Ω$, and $\PR$ is such that all outcomes are equally likely. For an $ω \in Ω$, let $X(ω)$ denote the number of heads. Thus,
$$
X(HH) = 2, \quad X(HT) = 1, \quad X(TH) = 1, \quad X(TT) = 0.
$$
:::

The random variable $X \colon Ω \to \reals$ induces a probability measure on $\reals$. Formally, to define such a probability measure, we need an associated $σ$-algebra on $\reals$. As discussed in [last lecture](probability-spaces.qmd#Borel-algebra), the commonly used $σ$-algebra on reals is the Borel $σ$-algebra, $\mathscr{B}(\reals)$. For everything to be consistent, we require the function $X$ to satisfy a property known as **measurability**.

:::{#def-measurability}
A **random variable** is a function $X \colon Ω \to \reals$ with the property that for every $x \in \reals$ the event $A(x) \coloneqq \{ω \in Ω : X(ω) \le x \} \in \ALPHABET F$. Such functions are said to be **$\ALPHABET F/\mathscr{B}(\reals)$-measurable**.

The **cumulative distribution function (CDF)** of a random variable $X$ is the function $F \colon \reals \to [0,1]$ given by
$$
F(x) \coloneqq \PR(A(x)) = \PR(\{ ω \in Ω : X(ω) \le x \}).
$$
:::

:::{.callout-note}
### Some comments on notation

1. The standard notation in probability theory is to use uppercase letters such as $X$, $Y$, $Z$, etc. to denote random variables and the corresponding lowercase letters $x$, $y$, $z$, etc. to denote the possible numerical values of these variables. 

2. Events such as $\{ω \in Ω : X(ω) \le x \}$ are commonly abbreviated as $\{ω : X(ω) \le x \}$ or $\{X \le x\}$. Thus, we have
   
   - $\PR(X \le x) = \PR(\{ω \in Ω : X(ω) \le x \})$.
   - $\PR(X = x) = \PR(\{ω \in Ω : X(ω) = x \})$.
   - $\PR(x < X \le y) = \PR(\{ω \in Ω : x < X(ω) \le y \})$.
   - For any (Borel) subset $B$ of $\reals$, 
     $\PR(X \in B) = \PR(\{ω \in Ω : X(ω) \in B \})$.

3. When we need to emphasize the dependence of the CDF on the random variable, we use the notation $F_X$, etc. 
:::

For instance, for @exm-coin-toss, the CDF is given by 
$$
F_X(x) = \begin{cases}
0, & \hbox{if } x < 0,  \\
\frac 14, & \hbox{if } 0 \le x < 1, \\
\tfrac 34, & \hbox{if } 1 \le x < 2,\\
1, &\hbox{if } 2 \le x. 
\end{cases}$$

:::{#exm-constant}
### Constant random variables

The simplest random variable takes a constant value on the whole domain $Ω$, i.e., 
$$
X(ω) = c, \quad \forall ω \in Ω
$$
where $c$ is a constant. The CDF $F(x) = \PR(X \le x)$ is the step function
$$
F(x) = \begin{cases}
0, & x < c \\
1, & x \ge c.
\end{cases}
$$

Slightly more generally, we say that $X$ is _almost surely_ a constant if there exists a $c \in \reals$ such that $\PR(X=c) = 1$.
:::

:::{#exm-bernoulli}
### Bernoulli random variable
A Bernoulli random variable takes two possible values: value $0$ with probability $1-p$ and value $1$ with probability $p$. It's CDF is given by
$$
F(x) = \begin{cases}
0, & x < 0 \\
1 - p, & 0 \le x < 1 \\
1, & x \ge 1.
\end{cases}
$$
:::

:::{#exm-indicator-functions}
### Indicator functions
Let $A$ be an event. Define the _indicator of event $A$_, denoted by $\IND_{A} \colon Ω \to \reals$, as 
$$ \IND_{A}(ω) = \begin{cases}
    1, & \hbox{if } ω \in A \\
    0, & \hbox{otherwise }
\end{cases}.$$
Observe that $\IND_A$ is a Bernoulli random variable which takes values $1$ and $0$ with probabilities $\PR(A)$ and $1 - \PR(A)$. 
:::

:::{#lem-properties-of-CDFs}
### Properties of CDFs

1. $\PR(X > x) = 1 - F(x)$. 

2. $\PR(x < X \le y) = F(y) - F(x)$.

3. $\lim_{x \to -∞} F(x) = 0$ and $\lim_{x \to +∞} F(x) = 1$.

4. CDFs are non-decreasing, i.e., if $x < y$, then $F(x) \le F(y)$.

5. CDFs are right continuous, i.e., $\lim_{h \downarrow 0}F(x+h) = F(x)$.

6. $\PR(X = x) = F(x) - F(x^{-})$, where $F(x^{-})$ is defined as $\lim_{h \downarrow 0} F(x - h)$
:::


:::{.callout-note collapse="true"}
#### Proof

1. By definition, $\{X > x\}^c = Ω\setminus \{X \le x\}$. Thus,
   $$\PR(X > x) = 1 - \PR(X \le x) = 1 - F(x).$$

2. $$\PR(x < X \le y) = \PR(X \le y) - \PR(X \le x) = F(y) - F(x).$$
   [See assignment 1 for the first equality.]

3. Define the increasing sequence of events $A_n = \{ X \le n\}$, $n \in \naturalnumbers$. By continuity of probability, we have
   \begin{align*}
     &\quad & \PR\biggl( \bigcup_{n=1}^{∞} A_n \biggr) 
     & = \lim_{n \to ∞} \PR(A_n) \\
     \implies && \PR(\{X < ∞\}) &= \lim_{n \to ∞} \PR(X \le n) \\
     \implies && \PR(Ω) &= \lim_{n \to ∞} F(n) \\
     \implies && 1 &= \lim_{n \to ∞} F(n).
   \end{align*}

      The reverse argument is similar where we consider the decreasing sequence of events $B_n = \{ X_n \le -n \}$, $n \in \naturalnumbers$. Then, by continuity of probability, we have
      \begin{align*}
        &\quad & \PR\biggl( \bigcap_{n=1}^{∞} B_n \biggr) 
        & = \lim_{n \to ∞} \PR(B_n) \\
        \implies && \PR(\{X < -∞\}) &= \lim_{n \to ∞} \PR(X \le -n) \\
        \implies && \PR(\emptyset) &= \lim_{n \to ∞} F(-n) \\
        \implies && 0 &= \lim_{n \to ∞} F(-n).
      \end{align*}

4. Recall that 
   \begin{align*}
      F(x) &= \PR(X \le x) \\
      F(y) &= \PR(X \le y) 
   \end{align*}
   Observe that since $x < y$, we have $\{X \le x\} \subseteq \{X \le y\}$. Hence, by monotonicity of probability, we have
   $$\PR(X \le x) \le \PR(X \le y),$$
   which proves the result.

5.  Consider the decreasing sequence of sets:
    $$ A_n = \{ X \le x + \tfrac 1n \}, \quad n \in \naturalnumbers. $$
    Then, by continuity of probability, we have
    \begin{align*}
      &\quad & \PR\biggl( \bigcap_{i=1}^{∞} A_n \biggr) 
      & = \lim_{n \to ∞} \PR(A_n) \\
      \implies && \PR(X \le x) &= \lim_{n \to ∞} \PR(X \le x + \tfrac 1n ) \\
      \implies && F(x) &= \lim_{n \to ∞} F(x + \tfrac 1n).
    \end{align*}
      
6. Define the decreasing sequence of sets
   $$ A_n = \biggl\{ x - \frac 1n < X \le x \biggr\}, 
   \quad n \in \naturalnumbers.$$
   Observe that by the previous property
   $$\PR(A_n) = F(x) - F(x - \tfrac 1n).$$
   Since $A_n$ is a decreasing sequence of sets, we have
   \begin{align*}
   & \quad & 
   \PR\biggl( \bigcap_{n=1}^∞ A_n \biggr) 
   &= \lim_{n \to ∞} \PR(A_n) \\
   \implies && \PR(X = x) &= F(x) - \lim_{n \to ∞} F(x - \tfrac 1n) \\
   &&& = F(x) - F(x^{-}). 
   \end{align*}
:::

:::{#exr-CDF-expressions}
For $x < y$, express the following in terms of the CDF:

1. $\PR(x \le X \le y)$.
2. $\PR(x \le X < y)$.

:::


## Classification of random variables

There are three types of random variables

1. A random variable $X$ is said to be **discrete** if it takes values in a finite or countable subset $\text{range}(X) \coloneqq \{x_1, x_2, \dots\}$ of $\reals$. A discrete random variable has a **probability mass function (PMF)** $p \colon \reals \to [0,1]$ which satisfies the following properties:

    - $p(x) = \PR(X = x) = F(x) - F(x^{-})$.
    - $F(x) = \sum_{x_n : x_n \le x} p(x_n).$

   [Thus, for a discrete random variable, the CDF is a piecewise constant function]{.text-primary}

     <!-- TODO: Add figure -->

2. A random variable $X$ is called **continuous** if there exists an integrable function $f \colon \reals \to [0, ∞)$ called the **probability denisity function** such that the CDF can be written as
    $$
    F(x) = \int_{-∞}^x f(x) dx.
    $$

   [Thus, for a continuous random variable, the CDF is a continuous function]{.text-primary}

     <!-- TODO: Add figure -->

3. A random variable is called **mixed** if it is neither discrete nor continuous. [For a mixed random variable, the CDF has has jumps at a finite or countable infinite number of points and it is continuous over one or many intervals.]{.text-primary}


      As an example, consider the following random experiment. A fair coin is tossed: if the outcome is heads, then $X \sim \text{Bernoulli}(0.5)$; if the outcome is tails; then $X \sim \text{Uniform}[0,1]$. Thus (from the law of total probability), the CDF of $X$ is
      $$
      F_X(x) = \begin{cases}
      0, & \hbox{if } x < 0 \\
      \frac 14 & \hbox{if } x = 0 \\
      \frac 14 + \frac x2 & \hbox{if } 0 < x < 1 \\
      1 & \hbox{if } x \ge 1.
      \end{cases}.
      $$

:::{.callout-tip}

### $σ$-algebra generated by random variables

A discrete random variable creates a partition of the sample space. In particular, suppose $X$ is a random variable and $\{x_1, x_2, \dots\}$ is the range of $X$. Define
$$A_n = \{ω \in Ω : X(ω) = x_n \} = X^{-1}(x_n)$$
Then, $\{A_1, A_2, \dots \}$ is a partition of $Ω$. 

:::{.callout-note collapse="true"}
### Proof that it is a partition

To show that $\{A_1, A_2, \dots \}$ forms a partition, we need to establish two properties:

1. $A_i \cap A_j = \emptyset$.

2. $\bigcup_{i=1}^∞ A_i = Ω$.

The details are left as an exercise.
:::

The power-set of $\{A_1, A_2, \dots\}$ is called the **$σ$-algebra generated by $X$** and denoted by $σ(X)$. This $σ$-algebra captures the crux of measurability. As an illustration, let's reconsider @exm-coin-toss. In this case, the range of $X$ is $\{0, 1, 2\}$. The partition corresponding to $σ(X)$ is shown in @fig-sigma-X.

![Illustration of $σ(X)$ for @exm-coin-toss](TODO){#fig-sigma-X}
:::

:::{#lem-properties-of-PMFs-PDFs}
### Properties of PMFs and PDFs

- **Properties of PMFs**

  1. For a discrete random variable, 
     $\sum_{x \in \text{range}(X)}p(x) = 1$.

  2. For any event $A \in \ALPHABET F$, $\PR(X \in A) = \sum_{x \in \text{range}(X) \cap A} p(x)$. 

- **Properties of PDFs**

  1. For a continuous random variable, 
     $\int_{-∞}^{∞} f(x)\, dx = 1$.

  2. For any event $A \in \ALPHABET F$, $\PR(X \in A) = \int_{x \in A} f(x)\,dx$. 

  3. The PDF is the derivative of CDF:
   $$
   f_X(x) = \frac{d}{dx} F_X(x).
   $$
:::

### Some examples of discrete random variables

We now consider some other examples of discrete random variables

:::{#exm-Binomial}
#### Binomial random variable

A Binomial random variable is the sum of intendant and identically Bernoulli random variables (we will prove this fact later). For example, if a biased coin (with $\PR(H) = p$) is tossed $n$ times, then the number of heads is a _binomial random variable with parameters $n$ and $p$_, which is denoted by $\text{Binomial}(n,p)$. For such a random variable,
$$
p_X(k) = \binom n k p^k (1-p)^{n-k}, \quad 0 \le k \le n.
$$
:::

:::{#exm-Geometric}
#### Geometric random variable

A geometric random variable is the number of trails in i.i.d.\ Bernoulli random variables. For example, if a biased coin (with $\PR(H) = p$) is tossed repeated, the number of tosses needed for the first head is a geometric random variable with parameter $p \in (0,1)$_, which is denoted by $\text{Geo}(p)$. For such a random variable,
$$
p_X(k) = (1-p)^{k-1} p, \quad k \in \integers_{> 0}.
$$
:::


:::{#exm-Poisson}
#### Poisson random variable

Poisson random variables model many different phenomenon ranging from photoelectric effect in photonics to inter-packet arrival times in computer networks. A random variable is said to _Poisson random variable with parameter $λ > 0$_, which is denoted by $\text{Poisson}(λ)$, if
$$
p_X(k) = \frac{λ^k}{k!} e^{-λ}, \quad k \in \integers_{\ge 0}.
$$
:::


:::{#exm-Uniform-discrete}
#### Uniform random variable

A random variable is said to have a (discrete) uniform distribution over a discrete set $\ALPHABET S$ if 
$$p_X(k) = \frac 1{\ABS{\ALPHABET S}}, \quad k \in \ALPHABET S.$$
:::

### Some examples of continuous random variables

:::{#exm-Uniform-continuous}
#### Uniform random variable

A random variable is said to have a (continuous) uniform distribution over an interval $[a, b]$, where $a < b$ if
$$f(x) = \frac 1{b - a}, \quad x \in [a,b].$$
:::

:::{#exm-exponential}
#### Exponential random variable

A random variable is said to have an exponential distribution with parameter $λ > 0$, which is denoted by $\text{exp}(λ)$ if 
$$f(x) = λ e^{-λ x}, \quad x \ge 0.$$
:::

:::{#exm-Gaussian}
#### Gaussian random variable

A random variable is said to have a Gaussian distribution with mean $μ$ and standard deviation $σ > 0$, which is denoted by $\mathcal N(μ, σ^2)$ if 
$$f(x) = \frac 1{\sqrt{2 π}\, σ}
\exp\left( -\frac {(x-μ)^2}{2 σ^2} \right),
\quad x \in \reals.$$
:::

## Expectation of random variables

Suppose we generate $N$ i.i.d. (independent and identically distributed) samples $\{s_1, s_2, \dots, s_N\}$ of a random variable $X$ and compute the average:
$$ m = \frac 1N \sum_{n=1}^N s_n. $$
When $X$ is discrete and takes values $\{x_1, x_2, \dots, x_n\}$, we expect that the number of times we obtain a value $x_i$ is approximately $Np(x_i)$ when $N$ is large. Thus,
$$ m \approx \frac 1N \sum_{i=1}^n x_i \, N p(x_i)  = \sum_{i=1}^n x_i p(x_i). $$

This quantity is called the **expectation** or the **expected value** or the **mean value** of the random variable $X$ and denoted by $\EXP[X]$. 

:::{#def-expectation}
The **expectation** of a random variable $X$ is defined as follows:

- when $X$ is discrete and takes values $\{x_1, x_2, \dots, x_n \}$, then
  $$\EXP[X] = \sum_{i=1}^n x_i p(x_i).$$

- when $X$ is continuous, then
  $$\EXP[X] = \int_{-∞}^{∞} x f(x)\, dx. $$

  [Thus, we can think of the expected value as the center of mass of the PDF.]{.text-primary}
:::

:::{.callout-warning}
#### Does the summation or integration exist?

When $X$ takes countably or uncountably infinite values, we need to be a bit more precise by what we mean by the summation (or the integration) formula above. In particular, we do not want the answer to depend on the order in which we do the summation or the integration (i.e., we do not want $∞ - ∞$ situation). This means that the sum or the integral should be [:_absolutely convergent_](https://en.wikipedia.org/wiki/Absolute_convergence). Such random variables are called **integrable random variables**. 

Formally, expectation is defined only for integrable random variables. 

To illustrate why this is important, consider a discrete random variable defined over $\integers\setminus\{0\}$ where
$$
p(n) = p(-n) = \frac {1}{2C n^2}, \quad n \in \naturalnumbers 
$$
where $C$ is a normalizing constant given by
$$
C = \sum_{n=1}^∞ \frac 1{n^2} = \frac{π^2}{6}.
$$
Then, observe that
\begin{align*}
\EXP[X] &= \sum_{n=1}^∞ \frac{n}{2 C n^2}
+ \sum_{n=-∞}^{-1} \frac{n}{2 C n^2} \\
&= \frac 1{2C} \sum_{n=1}^∞ \frac{1}{n}
+ \frac 1{2C} \sum_{n=-∞}^{-1} \frac{1}{n} \\
&= \frac{∞}{2C} - \frac{∞}{2C}
\end{align*}
which is undefined.

The concern here is that the summation is **undefined**. Mathematically, we are okay when the summation is infinity. For example, consider another random variable $Y$ defined over $\naturalnumbers$ for which
$$
p(n) = \frac {1}{C n^2}, \quad n \in \naturalnumbers 
$$
where $C$ is as defined above. This is called the **Zipf** distribution. By following an argument same as above, we see that
$$\EXP[Y] = ∞.$$
:::

:::{#exm-coin-toss-mean}
Find the mean of $X$ defined in @exm-coin-toss.
:::
:::{.callout-note collapse="true"}
#### Solution
$$
\EXP[X] = \frac 14 \cdot 0 + \frac 12 \cdot 1 + \frac 14 \cdot 2 = 1.
$$
:::

:::{#exr-mean-common}
Find the expected value of the random variables with the following distributions:

- $\text{Bernoulli}(p)$.
- $\text{Binomial}(n,p)$.
- $\text{Geo}(p)$.
- $\text{Poisson}(λ)$.
- $\text{Uniform}[a,b]$.
- $\text{Exp}(λ)$.

:::

:::{#lem-expectation}
For any (measurable) function $g \colon \reals \to \reals$, we have

- when $X$ is discrete and takes values $\{x_1, x_2, \dots, x_n \}$, then
  $$\EXP[g(X)] = \sum_{i=1}^n g(x_i) p(x_i).$$

- when $X$ is continuous, then
  $$\EXP[g(X)] = \int_{-∞}^{∞} g(x) f(x)\, dx. $$

Both expressions are defined only when the sum/integral is absolutely convergent. 
:::

:::{.callout-note collapse="true"}
#### How to avoid a proof

This result is sometimes called ***the law of the unconscious statistician (LOTUS).** One typically shows this result by defining a new random variable $Y = g(X)$, computing its PMF/PDF $f_Y$ and then using the definition in @def-expectation. 

A simpler proof is to define expectation by @lem-expectation for any (measurable) function $g$. Then the definition of @def-expectation falls off as a special case for $g(x) = x$. No proofs needed!
:::

:::{#exr-expectation}
Suppose $X \sim \text{Unif}[-1,1]$. Compute $\EXP[X^2]$.
:::

:::{#lem-expectation-properties}
### Properties of expectation

1. **Linearity.** For any (measurable) functions $g$ and $h$
   $$\EXP[g(X) + h(X)] = \EXP[ g(X)] + \EXP[ h(X) ]. $$
   As a special case, for a constant $c$, 
   $$\EXP[X + c] = \EXP[X] + c.$$

2. **Scaling.** For any constant $c$, 
   $$\EXP[cX] = c\EXP[X].$$

3. **Bounds.** If $a \le X(ω) \le b$ for all $ω \in Ω$, then
   $$ a \le \EXP[X] \le b. $$

4. **Indicator of events.** For any (Borel) subset $B$ of $\reals$, we have
   $$\EXP[ \IND_{\{ X \in B \}}] = \PR(X \in B). $$
:::


1. A continuous random variable is said to be symmetric if $f_X(-x) = f_X(x)$ for all $x \in \reals$. A symmetric random variable has mean $0$.

2. A continuous random variable is said to be symmetric around $m$ if $f(m - x) = f(m + x)$, for all $x \in \reals$. The mean of such a random variable is $m$.


### Higher moments

1. The $m$-th **moment**, $m \ge 1$ of a random variable $X$ is defined as $\EXP[X^m]$. 

2. The $m$-th **central moment** is defined as $\EXP[(X - μ)^m]$, where $μ = \EXP[X]$. 

3. For second central moment (i.e., $m=2$) is called **variance**. The variance satisfies the following:
   $$\VAR(X) = \EXP[X^2] - (\EXP[X])^2.$$

4. The positive square root of variance is called the **standard deviation.** Variance is often denoted by $σ^2$ and the standard deviation by $σ$. 

:::{#exm-coin-toss-variance}
Find the variance of $X$ defined in @exm-coin-toss.
:::
:::{.callout-note collapse="true"}
#### Solution
We first compute
$$
\EXP[X^2] = \frac 14 \cdot 0^2 + \frac 12 \cdot 1^2 + \frac 14 \cdot 2^2 = \frac 32.
$$
Therefore,
$$
\VAR(X) = \EXP[X^2] - \EXP[X]^2 = \frac 32 - 1 = \frac 12.
$$
:::

:::{#lem-variance-properties}
#### Properties of variance

1. **Scaling.** For any constant $c$,
   $$\VAR(cX) = c^2 \VAR(X).$$

2. **Shift invariance.** For any constant $c$,
   $$\VAR(X + c) = \VAR(X).$$
:::

The mean and variance of common random variables is show in @tbl-mean-variance

| **Random variable** | **Parameter(s)** | **Mean** | **Variance** |
|:---------------:|:------------:|:----:|:--------:|
| Bernoulli       | $p$          | $p$  | $p(1-p)$ |
| Binomial        | $(n,p)$      | $np$ | $np(1-p)$|
| Geometric       | $p$          | $\dfrac 1p$ | $\dfrac{1-p}{p}$ |
| Poisson         | $λ$          | $λ$  | $λ$      |
| Uniform         | $(a,b)$      | $\frac 12 (a+b)$ | $\frac 1{12}(b-a)^2$ |
| Exponential     | $λ$          | $\dfrac 1 λ$ | $\dfrac 1{λ^2}$ |
| Gaussian        | $(μ,σ)$      | $μ$  | $σ^2$ |

: Mean and variance of common random variables {#tbl-mean-variance}

